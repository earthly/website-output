<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://earthly.dev/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://earthly.dev/blog/" rel="alternate" type="text/html" /><updated>2021-06-17T08:28:03-04:00</updated><id>https://earthly.dev/blog/feed.xml</id><title type="html">Earthly Blog</title><subtitle>Build automation for the container era.</subtitle><entry><title type="html">Git Branching Strategies and The Greek Revival</title><link href="https://earthly.dev/blog/git-branching/" rel="alternate" type="text/html" title="Git Branching Strategies and The Greek Revival" /><published>2021-06-16T00:00:00-04:00</published><updated>2021-06-16T00:00:00-04:00</updated><id>https://earthly.dev/blog/git-branching</id><content type="html" xml:base="https://earthly.dev/blog/git-branching/">&lt;p&gt;Some modern development practices are easiest to understand from a historical perspective: things started a certain way, and then steps were added or removed as conditions changed. Git branching, for example, is like that.&lt;/p&gt;
&lt;p&gt;I’m going to explain various git branching strategies with a story. We will start with something straightforward and add complexity as we go. Eventually, we will end up back simple again.&lt;/p&gt;
&lt;p&gt;I hope that explaining things this way will give you a deeper understanding of when to use specific branching and merging strategies. So instead of telling you how to cherry-pick a bug fix into a hotfix branch using gitflow work, I can describe the conditions that would lead to adopting that process. Once you understand the whys, the hows will be easier.&lt;/p&gt;
&lt;h2 id=&quot;ashelysoft-2006&quot;&gt;AshelySoft 2006&lt;/h2&gt;
&lt;p&gt;The year is 2006, and Ashely Protagonist starts a software business. She builds and sells an eCommerce solution she wrote in PHP. It’s just her building and selling it, but she uses a new source control solution called git to store her software. She starts with trunk-based development.&lt;/p&gt;
&lt;h2 id=&quot;trunk-based-development&quot;&gt;Trunk Based Development&lt;/h2&gt;
&lt;p&gt;Trunk-based development is working on the main, or trunk branch. Ashely commits her code right into the main branch on her local machine and, when she has complete a feature, she pushes her code to the source control server.&lt;/p&gt;
&lt;p&gt;Customers pay for her software, and she emails them a link to the current version as an archive file using &lt;a href=&quot;https://git-scm.com/docs/git-archive&quot;&gt;git archive&lt;/a&gt;. She is a PHP developer, so she whips up a simple PHP script that returns the git archive for the branch requested.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/git-branching/email2-800-c3cecc459.webp 800w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/git-branching/email2-800-2d6f208ff.png 800w&quot; type=&quot;image/png&quot;&gt;&lt;img src=&quot;/blog/generated/assets/images/git-branching/email2-800-2d6f208ff.png&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;figcaption&gt;
Simple Release Distribution
&lt;/figcaption&gt;
&lt;p&gt;Her customers then install her software on their web servers, where they use it to run their eCommerce businesses.&lt;/p&gt;
&lt;section id=&quot;mainline-development&quot; class=&quot;notice--info&quot;&gt;
&lt;h2&gt;MainLine Development&lt;/h2&gt;
&lt;h3 id=&quot;ℹ️-fun-fact-trunk-vs.-main&quot;&gt;ℹ️ Fun Fact: Trunk VS. Main&lt;/h3&gt;
&lt;p&gt;If Ashely had chosen subversion or CVS, which were more prevalent in 2006, she would have called her branch &lt;code&gt;trunk&lt;/code&gt; because every branch is branched off the trunk like a real-world tree. This is where the term trunk-based development comes from. However, Ashely uses &lt;code&gt;main&lt;/code&gt;, so she may prefer the term mainline development. It’s the same thing, just a different name.&lt;/p&gt;
&lt;/section&gt;
&lt;h2 id=&quot;release-branches&quot;&gt;Release Branches&lt;/h2&gt;
&lt;p&gt;Ashely’s business succeeds. She acquires many more customers and hires more developers and a customer-support person. Support becomes problematic, though, as some customers are very slow to upgrade, and it’s unclear what version any given customer is on. Additionally, customers can’t keep up with the latest version when every commit is a new version, and there are no version numbers.&lt;/p&gt;
&lt;p&gt;So she decides to batch up the changes into monthly releases and create a new release branch for each revision. Of course, she could use tags for these releases, but branches and tags are pretty similar, and she already has her release script in place.&lt;/p&gt;
&lt;p&gt;Now her support people can ask customers what version they are on. If it’s more than two releases back, they ask them to upgrade. That is, AshelySoft only supports the current release and the two previous versions.&lt;/p&gt;
&lt;section id=&quot;cutting-a-releaase&quot; class=&quot;notice--info&quot;&gt;
&lt;h2&gt;Cutting a Releaase&lt;/h2&gt;
&lt;p&gt;There was a time before modern source control when creating a release branch was an expensive process that had to be planned. “Cutting a Release” was the name for this process, which involved locking down the source and starting the lengthy process of ‘cutting a release branch off the trunk’. People still use the phrase today.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Well, the performance was so bad that when they wanted to cut a branch, they would announce it ahead of time. They would schedule the branching because you didn’t want anybody else committing while you were branching, because that would totally screw things up. Right? And I said,”Okay, Friday at 2:00 PM, we’re going to cut the branch.&quot; Then all activity would stop, access to the server would be cut off.&quot;&lt;/p&gt;
&lt;p&gt;And it would take 45 minutes to cut this branch. And then you’d say, “Okay, we’ve opened up the branch. Everybody can start working again.”&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://corecursive.com/software-that-doesnt-suck-with-jim-blandy/&quot;&gt;Jim Blandy&lt;/a&gt; creator of Subversion&lt;/p&gt;
&lt;/blockquote&gt;
&lt;/section&gt;
&lt;h2 id=&quot;hot-fixes-and-the-multiverse&quot;&gt;Hot Fixes and The Multiverse&lt;/h2&gt;
&lt;p&gt;This is all working great. Ashely starts scaling the development team, and they start shipping more features. Unfortunately, while each monthly release now contains more cool new features, more regressions and bugs start slipping into the releases as well.&lt;/p&gt;
&lt;p&gt;Some customers respond to this by not upgrading right away. If they are well-served by the current product, they can stay two releases back and get active support while giving the latest release time to stabilize. Bugs do show up in the old versions, though, and this is where things get interesting.&lt;/p&gt;
&lt;p&gt;Up until now, time, as viewed by AshelySoft’s source control, moves forward in a single line. There is one &lt;code&gt;main&lt;/code&gt; branch that represents one linear release timeline. But now, when bugs are found, they need to be addressed in multiple versions of the product. And you can’t simply ask people to upgrade because they are still on a supported version, and they are correctly worried about the quality of the latest release. They want the version they have plus the bug fixes, with no new development.&lt;/p&gt;
&lt;p&gt;You are now in the hot fixing multiverse. AshelySoft has to fix bugs in the latest version and all other active versions. Each release is a separate timeline where active development ceased at the release date, but bugs continued to be fixed.&lt;/p&gt;
&lt;p&gt;If you’ve seen any time travel movies, you probably realize that this can get complex. What if a bug fix to back release introduces a bug of its own? Thankfully AshelySoft is only supporting two active versions back and only supporting them for a couple of months. Suppose they were supporting back versions for several years. In that case, they might find themselves spending more and more time maintaining all these versions, and the various versions would slowly drift away from each other.&lt;/p&gt;
&lt;p&gt;Nevertheless, release branches are an enormous help for AshelySoft. They help customers stay on a version that works for them, while AshelySoft can still push new features. However, it does increase the amount of effort that fixing bugs requires, and dealing with that will lead to Ashelysoft’s next innovation.&lt;/p&gt;
&lt;h2 id=&quot;the-develop-branch&quot;&gt;The &lt;code&gt;develop&lt;/code&gt; Branch&lt;/h2&gt;
&lt;p&gt;The cost of shipping bugs has now increased for AshelySoft. In the worse case, a bug isn’t discovered until it’s in all active versions of the software and the code between versions has changed enough that the fix is slightly different in each version, tripling the bug fix cost.&lt;/p&gt;
&lt;p&gt;Fortunately, a solution for this does exist: Continuing with our time travel/multiverse analogy, we need to travel back in time and stop the bug before our releases branches off the main timeline. Unfortunately, AshelySoft does not have access to literal time travel machines, but Ashely has a more straightforward idea: Catch the bugs before they are released.&lt;/p&gt;
&lt;h2 id=&quot;gitflow-to-the-rescue&quot;&gt;GitFlow To The Rescue&lt;/h2&gt;
&lt;p&gt;A popular branching method called &lt;a href=&quot;https://nvie.com/posts/a-successful-git-branching-model/&quot;&gt;GitFlow&lt;/a&gt; has excellent suggestions for achieving this: you create a &lt;code&gt;develop&lt;/code&gt; branch. So now all new work goes into &lt;code&gt;develop,&lt;/code&gt; and instead of 4 weeks of development in each release, you spend the last week stabilizing &lt;code&gt;develop&lt;/code&gt;. You make sure &lt;code&gt;develop&lt;/code&gt; has no bugs as best you can, and when it seems stable, you merge it into main and then cut a release branch off main.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“We consider origin/develop to be the main branch where the source code of HEAD always reflects a state with the latest delivered development changes for the next release. Some would call this the”integration branch“. This is where any automatic nightly builds are built from.”&lt;/p&gt;
&lt;p&gt;“When the source code in the develop branch reaches a stable point and is ready to be released, all of the changes should be merged back into master somehow and then tagged with a release number.”&lt;/p&gt;
&lt;p&gt;GitFlow Explanation&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This whole process adds more overhead to the branching and release process, but it’s a fixed cost overhead, and it saves a lot of HotFixing bugs on release branches. AshelySoft, following the git-flow model, also adds a &lt;a href=&quot;/blog/continuous-integration&quot;&gt;continuous integration&lt;/a&gt; service. When new code shows up in &lt;code&gt;develop&lt;/code&gt;, &lt;a href=&quot;/blog/unit-vs-integration&quot;&gt;automated tests&lt;/a&gt; are run.&lt;/p&gt;
&lt;p&gt;This setup, git-flow and CI on develop branch, with release branches and hot fixing serves AshelySoft for several years. However, it is a complicated process. Thankfully, from here on out, AshelySoft’s process will only get simpler. The first thing that helps to simplify things is &lt;code&gt;The Cloud&lt;/code&gt;™️.&lt;/p&gt;
&lt;h2 id=&quot;the-cloud&quot;&gt;The Cloud&lt;/h2&gt;
&lt;p&gt;AshelySoft customers want to run an eCommerce store. However, they don’t want to run a web server. After repeatedly getting this feedback, Ashely shifts the company to be a SAAS product company. It takes some extensive work, but AshelySoft eCommerce becomes a multi-tenant eCommerce platform. No more &lt;code&gt;git archive&lt;/code&gt; releases. Now the release process is deploying the latest version of the main branch onto the production server.&lt;/p&gt;
&lt;p&gt;There are downsides to this SAAS model. AshelySoft now owns the uptime of all their customers, and this is eCommerce, so real money is lost when things go down. But, the customers are willing to pay more for AshelySoft to worry about these problems. They no longer have to support multi releases at a time - no more hot fixing bugs back into old versions, no more multiverse of drifting branches to update, and no more release branches. To make this work, AshelySoft works off a simple rule: &lt;code&gt;main&lt;/code&gt; must be releasable. Before anyone can merge &lt;code&gt;develop&lt;/code&gt; into &lt;code&gt;main&lt;/code&gt; they must make sure the continuous integration build is passing, and if they find problems that the CI process missed, they do their best to make sure CI will catch it in the future.&lt;/p&gt;
&lt;h2 id=&quot;github-flow&quot;&gt;GitHub Flow&lt;/h2&gt;
&lt;p&gt;Around this time, GitHub private repositories appear, and AshelySoft moves from their own git hosting to GitHub and starts following a Pull Request process. Instead of pushing code straight into &lt;code&gt;develop&lt;/code&gt; and then ensuring they didn’t break the build, developers now create pull-requests. Other team members review the pull-requests, and the continuous integration service runs its suite of tests right on the PR. As a result, the speed of getting code into &lt;code&gt;develop&lt;/code&gt; has decreased, but with each PR being manually reviewed and automatically tested, the quality of code that makes it into the &lt;code&gt;develop&lt;/code&gt; branch is way up.&lt;/p&gt;
&lt;h2 id=&quot;death-to-develop&quot;&gt;Death to &lt;code&gt;develop&lt;/code&gt;&lt;/h2&gt;
&lt;p&gt;With the quality of &lt;code&gt;develop&lt;/code&gt; now increased, AshelySoft can increase its release velocity. They even adopt a continuous deployment model where a merge into &lt;code&gt;main&lt;/code&gt; causes the software to be automatically deployed. From there, they move to a &lt;a href=&quot;/blog/deployment-strategies/#canary-deployment&quot;&gt;Canary deployment model&lt;/a&gt; where a new release is tested on a small portion of web traffic before it’s fully deployed. Once a PR is merged, Ashely just has to merge &lt;code&gt;develop&lt;/code&gt; into &lt;code&gt;main&lt;/code&gt; to perform a release.&lt;/p&gt;
&lt;p&gt;But what is the point of having &lt;code&gt;develop&lt;/code&gt; and merging it into &lt;code&gt;main&lt;/code&gt;? It was introduced to prevent the release of bugs by giving the software time to ‘integrate’, but AshelySoft is doing all the integration as part of the PR process. So they drop the &lt;code&gt;develop&lt;/code&gt; branch.&lt;/p&gt;
&lt;p&gt;Ashely has come a long way but sometimes what is old is new again. She is now back to doing trunk-based or mainline development. Just like when she built the first version: features go into &lt;code&gt;main&lt;/code&gt;, and the HEAD of &lt;code&gt;main&lt;/code&gt; is constantly released.&lt;/p&gt;
&lt;h2 id=&quot;lessons-learned&quot;&gt;Lessons Learned&lt;/h2&gt;
&lt;p&gt;There is a lot about git merging strategies, continuous integration, and deployment that doesn’t seem to make sense without going through a long journey like Ashely’s.&lt;/p&gt;
&lt;p&gt;For instance, calling software that builds and tests code a continuous integration process only makes sense when you understand what non-continuous integration was. It was spending time manually testing the upcoming release for days or even weeks before feeling confident enough to release it.&lt;/p&gt;
&lt;p&gt;Ashely’s story is fictional, and history didn’t necessarily unfold this way for all or even most software shops, but I think it’s helpful to understand where we are coming from and how cloud and SAAS workflows influence branching models.&lt;/p&gt;
&lt;p&gt;Some software always had an extensive review process, and much software will never be cloud-based and will continue to deal with release branches and backporting fixes. But some software has moved to the cloud and yet hasn’t embraced the simplified workflows that cloud deployment can enable.&lt;/p&gt;
&lt;h2 id=&quot;appendix-develop-and-the-greek-revival-style&quot;&gt;Appendix: Develop and The Greek Revival Style&lt;/h2&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/git-branching/greek-columns-550-93c2aaf0b.webp 550w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/git-branching/greek-columns-550-9fd39c02f.jpg 550w&quot; type=&quot;image/jpeg&quot;&gt;&lt;img src=&quot;/blog/generated/assets/images/git-branching/greek-columns-550-9fd39c02f.jpg&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;The Parthenon was built in ancient Greece using columns of marble. These columns of marble held it up.&lt;/p&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/git-branching/greek-revival-800-bc37602f4.webp 800w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/git-branching/greek-revival-800-ce1d10ab6.jpg 800w&quot; type=&quot;image/jpeg&quot;&gt;&lt;img src=&quot;/blog/generated/assets/images/git-branching/greek-revival-800-ce1d10ab6.jpg&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;This is a greek-revival style house. These columns are not about function but form – they are unnecessary and were chosen for aesthetic purposes.&lt;/p&gt;
&lt;p&gt;If you don’t need to maintain and support multiple versions of your software and it only runs on your servers, then you might have a purely decorative &lt;code&gt;develop&lt;/code&gt; branch. You may be using a git branching model that is very effective for a software lifecycle that you yourself are not in fact practicing. Those might not be load-bearing functional columns – you might be copying the visual appearance of the ancients without understanding the purpose they had in mind.&lt;/p&gt;
&lt;p&gt;The creator of GitFlow offers similar thoughts:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Web apps are typically continuously delivered, not rolled back, and you don’t have to support multiple versions of the software running in the wild.&lt;/p&gt;
&lt;p&gt;If your team is doing continuous delivery of software, I would suggest to adopt a much simpler workflow (like GitHub flow) instead of trying to shoehorn git-flow into your team.&lt;/p&gt;
&lt;p&gt;Vincent Driessen Gitflow Creator&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The closer you can stay to trunk-based or mainline development, the less overhead you will have and the smaller the batches you’ll be able to release.&lt;/p&gt;</content><author><name>Adam Gordon Bell</name></author><category term="Tutorials" /><summary type="html">Some modern development practices are easiest to understand from a historical perspective: things started a certain way, and then steps were added or removed as conditions changed. Git branching, for example, is like that.</summary></entry><entry><title type="html">Incident Management Metrics and Key Performance Indicators</title><link href="https://earthly.dev/blog/incident-management-metrics/" rel="alternate" type="text/html" title="Incident Management Metrics and Key Performance Indicators" /><published>2021-06-11T00:00:00-04:00</published><updated>2021-06-11T00:00:00-04:00</updated><id>https://earthly.dev/blog/incident-management-metrics</id><content type="html" xml:base="https://earthly.dev/blog/incident-management-metrics/">&lt;!-- markdownlint-disable MD024 --&gt;
&lt;p&gt;In 2008, I got my first job at a software-as-a-service company. We built learning management software and ran it on servers in the small data center connected to our office.&lt;/p&gt;
&lt;p&gt;We released new software onto these production servers monthly and measured quality by counting bugs per release. We also had account managers who kept us informed of how many large clients seemed upset about the last release.&lt;/p&gt;
&lt;p&gt;Occasionally, when something went wrong, we would do a stability release and spend a month only fixing bugs. &lt;a href=&quot;/blog/unit-vs-integration&quot;&gt;Testing&lt;/a&gt; was not a part of our build process but a part of our team: every feature team had quality assurance people who tested each feature before it was released.&lt;/p&gt;
&lt;p&gt;This wasn’t that long ago, but cloud software development has matured a lot since this time. Incident management has become standard practice, and many great metrics and Key Performance Indicators (KPIs) exist for measuring release quality. Let’s review some of them.&lt;/p&gt;
&lt;h2 id=&quot;mtbf-mean-time-between-failures&quot;&gt;MTBF: Mean Time Between Failures&lt;/h2&gt;
&lt;p&gt;When software is being released only once a month, on a fixed timeline, with extensive manual testing, counting the number of bugs might work. But once you start releasing many times per week or per day, this won’t work, and another way to measure software quality is required.&lt;/p&gt;
&lt;p&gt;Mean time between failures is a metric from the field of &lt;a href=&quot;/blog/achieving-repeatability&quot;&gt;reliability&lt;/a&gt; engineering. Calculating it is simple: it is time over the number of failures that occurred during that time. If in the last 30 days you have had two production incidents, then the mean time between failure is 15 days.&lt;/p&gt;
&lt;section id=&quot;calculating-mtbf&quot; class=&quot;notice--big--primary&quot;&gt;
&lt;h3&gt;Calculating MTBF&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Incidents in last 30 days&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;#1&lt;/td&gt;
&lt;td&gt;Jan 3rd&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;#2&lt;/td&gt;
&lt;td&gt;Jan 25&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;dl&gt;
&lt;dt&gt;Mean Time Between Failures =&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;30 days / 2 Incidents = 15 days&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/section&gt;
&lt;h2 id=&quot;mttr-mean-time-to-recovery&quot;&gt;MTTR: Mean Time To Recovery&lt;/h2&gt;
&lt;p&gt;Something funny happens when you start releasing more frequently. You may end up with a higher count of issues in production, but resolving them will happen much faster. If each change is released separately using a continuous delivery model, then recovering gets easier – often, all that is required is hitting a rollback button.&lt;/p&gt;
&lt;p&gt;If you are measuring MTBF, your software may be getting much better, but your numbers will be getting worse. Enter mean time to recovery. Mean time to recovery is just what it sounds like: you start a timer when the incident begins and stop it when production is healthy again - even a simple rollback counts. Average this number across incidents, and you have MTTR. You now have a metric that captures the health of your incidence response process.&lt;/p&gt;
&lt;section id=&quot;calculating-mean-time-to-recovery&quot; class=&quot;notice--big--primary&quot;&gt;
&lt;h3&gt;Calculating Mean Time To Recovery&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Incident #1&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Reported&lt;/td&gt;
&lt;td&gt;10:00 AM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Recovered&lt;/td&gt;
&lt;td&gt;12:00 PM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Recovery Time&lt;/td&gt;
&lt;td&gt;2 Hours&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Incident #2&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Reported&lt;/td&gt;
&lt;td&gt;10:00 AM&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Recovered&lt;/td&gt;
&lt;td&gt;2 days later at 10:00 am&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Recovery Time&lt;/td&gt;
&lt;td&gt;48 Hours&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;dl&gt;
&lt;dt&gt;Mean Time To Recovery =&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;2 hour + 48 hours / 2 failures = 25 hours&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/section&gt;
&lt;h2 id=&quot;mttre-mean-time-to-resolve&quot;&gt;MTTRe: Mean Time To Resolve&lt;/h2&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;ℹ️ Acronyms Collision Alert&lt;/p&gt;
&lt;p&gt;Mean Time To Resolve, MTTRe, differs from Mean Time To Recover, MTTR, but some resources use MTTR for both. To avoid confusion, ensure you are using the correct terminology for your metric.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Rolling back to address an incident is a great idea: it’s often the quickest way to get things back in a good place. But there are other types of incidents. Imagine your application deadlocks every once in a while, and you have to restart it to unlock. You may have an excellent mean time to recovery, but you’ve never actually addressed the root cause. This is what MTTRe measures, not the time to get the service back up and running but to resolve the root cause and ensure the problem never happens again.&lt;/p&gt;
&lt;p&gt;The never-happens-again part is hard to achieve but vital. If you are responding quickly but never getting to the root cause, you will be living in a stressful world of constant fire fighting. However, if you are resolving the root cause of each incident, then quality will increase over time.&lt;/p&gt;
&lt;section id=&quot;calculating-mean-time-to-resolve&quot; class=&quot;notice--big--primary&quot;&gt;
&lt;h3&gt;Calculating Mean Time To Resolve&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Incident #3&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Reported&lt;/td&gt;
&lt;td&gt;day 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Addressed&lt;/td&gt;
&lt;td&gt;day 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Root Cause Analysis&lt;/td&gt;
&lt;td&gt;day 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Root Cause Addressed&lt;/td&gt;
&lt;td&gt;day 31&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;strong&gt;Resolve Time&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;30 days&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Incident #4&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Reported&lt;/td&gt;
&lt;td&gt;day 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Addressed&lt;/td&gt;
&lt;td&gt;day 1&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Root Cause Analysis&lt;/td&gt;
&lt;td&gt;day 2&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Root Cause Addressed&lt;/td&gt;
&lt;td&gt;day 11&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;&lt;strong&gt;Resolve Time&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;10 days&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;dl&gt;
&lt;dt&gt;Mean Time To Resolve =&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;30 days + 10 days / 2 incidents = 20 days&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/section&gt;
&lt;h2 id=&quot;mtta-mean-time-to-acknowledge&quot;&gt;MTTA: Mean Time To Acknowledge&lt;/h2&gt;
&lt;p&gt;An essential part of good incident management is an on-call rotation. You need someone around to respond to incidents when they occur. Our previous metrics would be unable to differentiate between an incident that took 3 hours to recover from and one that was recoverable in 5 minutes but took two hours and 55 minutes to be acknowledged.&lt;/p&gt;
&lt;p&gt;MTTA highlights this difference. It is a metric for measuring the responsiveness of the on-call person to any alerts.&lt;/p&gt;
&lt;section id=&quot;calculating-mean-time-to-acknowledge&quot; class=&quot;notice--big--primary&quot;&gt;
&lt;h3&gt;️Calculating Mean Time To Acknowledge&lt;/h3&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Incident #5&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Reported&lt;/td&gt;
&lt;td&gt;10 am&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Acknowledged&lt;/td&gt;
&lt;td&gt;10: 05 am&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Recovered&lt;/td&gt;
&lt;td&gt;12:00 pm&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;strong&gt;Acknowledge Time&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;5 minutes&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Incident #6&lt;/th&gt;
&lt;th&gt;&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Reported&lt;/td&gt;
&lt;td&gt;10 am&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Acknowledged&lt;/td&gt;
&lt;td&gt;11: 55 am&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Recovered&lt;/td&gt;
&lt;td&gt;12:00 pm&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;&lt;strong&gt;Acknowledge Time&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;115 minutes&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;dl&gt;
&lt;dt&gt;Mean Time To Acknowledge =&lt;/dt&gt;
&lt;dd&gt;&lt;p&gt;5 minutes + 115 minutes / 2 incidents = 60 minutes&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/section&gt;
&lt;h2 id=&quot;summary&quot;&gt;Summary&lt;/h2&gt;
&lt;p&gt;There are many ways to measure the quality of your software as a service product. MTBF, MTTR, MTTRe, and MTTA can each offer a different lens for viewing your software release life cycle. As you improve your SDLC, find ways to collect aggregate metrics like these and choose one or two to target for improvement.&lt;/p&gt;
&lt;p&gt;Invest in improving these metrics and you’ll make up for it in time saved fighting fires. Also focusing on aggregate metrics can be an effective way to move the discussion from blame about specific incidents to a higher-level debate around changing the process to better support the company’s goals.&lt;/p&gt;
&lt;p&gt;If your build pipeline is taking more than 15 minutes and therefore negatively affecting your metrics, then take a look at Earthly’s &lt;a href=&quot;http://earthly.dev/&quot;&gt;free and open build tool&lt;/a&gt;.&lt;/p&gt;</content><author><name>Adam Gordon Bell</name></author><category term="Tutorial" /><summary type="html">In 2008, I got my first job at a software-as-a-service company. We built learning management software and ran it on servers in the small data center connected to our office.</summary></entry><entry><title type="html">Deployment Strategies</title><link href="https://earthly.dev/blog/deployment-strategies/" rel="alternate" type="text/html" title="Deployment Strategies" /><published>2021-06-10T00:00:00-04:00</published><updated>2021-06-10T00:00:00-04:00</updated><id>https://earthly.dev/blog/deployment-strategies</id><content type="html" xml:base="https://earthly.dev/blog/deployment-strategies/">&lt;p&gt;There are many ways to deploy applications to a production server environment, and the terminology around deploy strategies is often confusing. In this short guide, I’ll review software deployment options starting from the most basic and straightforward and moving towards the more complex.&lt;/p&gt;
&lt;h2 id=&quot;recreate-deployment-strategy&quot;&gt;Recreate Deployment Strategy&lt;/h2&gt;
&lt;p&gt;This is the most straightforward deployment strategy. It’s been the default strategy in enterprise IT for a long time and works well when updates are very infrequent and maintenance windows plentiful. You stop the old service and then start up the new service. During the teardown and spin-up process, the service is down.&lt;/p&gt;
&lt;p&gt;In a software-as-a-service world, with frequent updates, this strategy can really only work with the use of queues and async messaging architectures. For example, when upgrading a service that sends email, the mail will queue in an outbox waiting for the upgraded version to start up.&lt;/p&gt;
&lt;section id=&quot;pros&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Pros&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Easy&lt;/li&gt;
&lt;li&gt;Works excellent with queues and async message buffers&lt;/li&gt;
&lt;li&gt;Never need to run more than one version of the service in parallel&lt;/li&gt;
&lt;/ul&gt;
&lt;section id=&quot;cons&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Cons&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Downtime to upgrade&lt;/li&gt;
&lt;li&gt;Downtime to rollback&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;rolling-update-deployment-strategy&quot;&gt;Rolling Update Deployment Strategy&lt;/h2&gt;
&lt;p&gt;The recreate strategy above assumes you only have one instance of your service running at a time. But if you have several with a load balancer in front, you can improve the downtime story with a rolling update strategy. You start an instance of the new version, and once it’s up, gracefully terminate one instance of the old version. Then continue this pattern until only new versions of the service are running. This strategy is ubiquitous in &lt;a href=&quot;/blog/building-on-kubernetes-ingress&quot;&gt;Kubernetes&lt;/a&gt; and other containerized production environments.&lt;/p&gt;
&lt;section id=&quot;pros-1&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Pros&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Easy on Kubernetes&lt;/li&gt;
&lt;li&gt;No Downtime on upgrade&lt;/li&gt;
&lt;/ul&gt;
&lt;section id=&quot;cons-1&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Cons&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Multiple versions of same service active during the overlap&lt;/li&gt;
&lt;li&gt;No warm rollback services&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;blue-green-deployment&quot;&gt;Blue-Green Deployment&lt;/h2&gt;
&lt;p&gt;A blue-green deployment requires a bit more resources: you need two identical production environments and a load balancer. One of these environments always receives 100% of the traffic while the other version sits idle. Updates are deployed to inactive version, and once it is successfully upgraded, traffic is switched over to it. These two environments are named blue and green, respectively, and traffic alternates back and forth from green to blue and then blue to green and so on. This means that the previously deployed version is always running on the idle environment, which simplifies rollbacks.&lt;/p&gt;
&lt;section id=&quot;pros-2&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Pros&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Eliminates upgrade downtime&lt;/li&gt;
&lt;li&gt;Very quick rollbacks&lt;/li&gt;
&lt;/ul&gt;
&lt;section id=&quot;cons-2&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Cons:&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;More Resources&lt;/li&gt;
&lt;li&gt;More Deployment complexity&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;canary-deployment&quot;&gt;Canary Deployment&lt;/h2&gt;
&lt;p&gt;A canary deployment strategy looks a lot like a blue-green deployment – a new version of the service starts up parallel to the existing version – with a slight improvement made: instead of switching all traffic over to the new version, only a percentage of traffic is initially sent. This traffic is the canary in the coal mine. Canaries were used in mining to measure air quality. The miners would bring a canary with them as they traveled down into the mine. If there was an air quality problem, the canary would die before the miners and act as an early warning signal.&lt;/p&gt;
&lt;p&gt;In the same way, a canary deployment does not prevent downtime, but limits its impact by giving an early warning. It limits access to the new version to a subset of users. If &lt;a href=&quot;/blog/incident-management-metrics&quot;&gt;metrics&lt;/a&gt; indicate that the new service is not responding well to this fraction of requests, then the roll-out can be aborted, lessening its impact. If everything looks OK, request volume is slowly ramped up until its being entirely served by the new version.&lt;/p&gt;
&lt;p&gt;Depending on how the canary traffic is chosen, a downside to this approach is that a specific subset of users may experience most of the production issues.&lt;/p&gt;
&lt;section id=&quot;pros-3&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Pros&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Catch Problems Early&lt;/li&gt;
&lt;/ul&gt;
&lt;section id=&quot;cons-3&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Cons&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Deployment complexity&lt;/li&gt;
&lt;li&gt;Canary users bear the brunt of production issues&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&quot;shadow-deployment&quot;&gt;Shadow Deployment&lt;/h2&gt;
&lt;p&gt;If the problems a canary deployment finds can genuinely be found with metrics alone, and if the cost of incidents is very high, then a shadow or mirrored deployment is worth considering.&lt;/p&gt;
&lt;p&gt;In a shadow deployment, the new version of the service is started, and all traffic is mirrored by the load balancer. That is, requests are sent to the current version and the new version, but all responses come only from the existing stable version. In this way, you can monitor the latest version under load without any possibility of customer impact. This strategy is sometimes called a mirrored canary deployment.&lt;/p&gt;
&lt;p&gt;The cost of this approach is in the implementation. A service mesh like Istio is probably needed to perform the actual request mirroring, and it gets more complex from there. If a new version of a user service backed by a relational database was shadow deployed, all users might be created twice, leading to untold ramifications. To embrace a shadow or mirrored deployment strategy, you have to think about the implications of duplicated requests, and any non-idempotent actions on downstream services may need to be mocked.&lt;/p&gt;
&lt;section id=&quot;pros-4&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Pros&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Catch production problems without custom impact&lt;/li&gt;
&lt;/ul&gt;
&lt;section id=&quot;cons-4&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Cons&lt;/h3&gt;
&lt;/section&gt;
&lt;ul&gt;
&lt;li&gt;Deployment complexity&lt;/li&gt;
&lt;li&gt;Architectural complexity&lt;/li&gt;
&lt;/ul&gt;
&lt;section id=&quot;summary&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h2&gt;Summary&lt;/h2&gt;
&lt;/section&gt;
&lt;p&gt;There are many deployment methods, from the very simple to the very complex. The deployment strategy the works best for any given situation depends on many factors. When choosing a deployment strategy balancing the cost of downtime versus the cost of deployment complexity is essential.&lt;/p&gt;
&lt;p&gt;If there are other deployment strategies or other continuous deployment terms you would like to see covered, please reach out to us on &lt;a href=&quot;https://twitter.com/earthlytech&quot;&gt;Twitter&lt;/a&gt; or via &lt;a href=&quot;adam@earthly.dev&quot;&gt;email&lt;/a&gt;.&lt;/p&gt;</content><author><name>Adam Gordon Bell</name></author><category term="Tutorial" /><summary type="html">There are many ways to deploy applications to a production server environment, and the terminology around deploy strategies is often confusing. In this short guide, I’ll review software deployment options starting from the most basic and straightforward and moving towards the more complex.</summary></entry><entry><title type="html">Don’t Feed the Thought Leaders</title><link href="https://earthly.dev/blog/thought-leaders/" rel="alternate" type="text/html" title="Don’t Feed the Thought Leaders" /><published>2021-06-09T00:00:00-04:00</published><updated>2021-06-09T00:00:00-04:00</updated><id>https://earthly.dev/blog/thought-leaders</id><content type="html" xml:base="https://earthly.dev/blog/thought-leaders/">&lt;p&gt;Here is a somewhat fictionalized personal story. I’ve changed the names of the people and the technology used.&lt;/p&gt;
&lt;h2 id=&quot;raising-objections&quot;&gt;Raising Objections&lt;/h2&gt;
&lt;p&gt;I was a new engineering manager whose team was starting a new small but ambitious project at a SAAS company. The company had several hundred developers, and the project was approved. A design document and development plan existed, a working prototype had been created, and several talented people were executing the plan. All that was left to do, from my perspective, was to ‘reach alignment.’&lt;/p&gt;
&lt;p&gt;I’m not sure if reaching alignment is a universal term that I was previously unfamiliar with or if it’s company-specific. But for this project, it worked like this: The project was approved, but there were all kinds of people vaguely horizontal to me in the organization who could ‘raise objections’ about it.&lt;/p&gt;
&lt;p&gt;Raising objections is a process where you tell someone above me, my boss or my boss’s boss, or so on, that you have concerns about the project’s success. An easy way to report concerns can be an excellent idea. If the SRE manager heard we were using bongoDB and had dealt with bongoDB data loss in the past, then there is no better time to speak than at the beginning of the project. And because the head of engineering doesn’t want to spend time mediating discussions about database preferences, or whatever the latest concerns are, part of my job was to make sure there were no objections to be raised.&lt;/p&gt;
&lt;h2 id=&quot;seeking-alignment&quot;&gt;Seeking Alignment&lt;/h2&gt;
&lt;p&gt;Preventing the raising of objections was called ‘reaching alignment.’ I find the people who might have concerns or advice, get feedback from them, and work with the developers on the team to adjust the plan based on that. It ends up feeling a lot like the office episode where Andy and Kevin must meet with the heads of every company in the office park to reach a decision about the parking spaces.&lt;/p&gt;
&lt;div class=&quot;wide&quot;&gt;
&lt;p&gt;&lt;img width=&quot;1200px&quot; src=&quot;/blog/generated/assets/images/thought-leaders/4-families-800-6e897ae5d.png&quot; srcset=&quot;/blog/generated/assets/images/thought-leaders/4-families-400-6e897ae5d.png 400w, /blog/generated/assets/images/thought-leaders/4-families-600-6e897ae5d.png 600w, /blog/generated/assets/images/thought-leaders/4-families-800-6e897ae5d.png 800w, /blog/generated/assets/images/thought-leaders/4-families-1000-6e897ae5d.png 1000w&quot;&gt;&lt;/p&gt;
&lt;figcaption&gt;
Everybody has advice about how to build your project
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;p&gt;At its worse, the conversations tended to go something like this:&lt;/p&gt;
&lt;h3 id=&quot;the-quality-person-meeting&quot;&gt;The Quality Person Meeting&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Adam:&lt;/strong&gt; You’ve had a chance to read the design doc. What are your thoughts?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Quality Person:&lt;/strong&gt; There is nothing in here about unit-test coverage, and taking a look at your other services, they are below the 80% level we set as an H2 goal. Can you add a unit-testing strategy to the plan and set a specific coverage goal?&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;the-data-person-meeting&quot;&gt;The Data Person Meeting&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Adam:&lt;/strong&gt; You’ve had a chance to read the design doc. What are your thoughts?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Person:&lt;/strong&gt; We are currently migrating all data in Important-Project-A from springy search to beetleDB, and it is a multi-year project. All new projects should follow this, so the effort doesn’t need to be repeated.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Adam:&lt;/strong&gt; We weren’t going to use springy search, just a relational database. So I think we should be good.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Data Person:&lt;/strong&gt; BeetleDB is relational database equivalent, so I would recommend using that so that you can scale.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;the-micro-services-person&quot;&gt;The Micro-Services Person&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;strong&gt;Adam:&lt;/strong&gt; You’ve had a chance to read the design doc. What are your thoughts?&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Micro-Services Person:&lt;/strong&gt; I would recommend separating the read-side from the write-side. Put them in separate services so that they can be scaled independently. That was our number one secret to scaling when I was at warble: the finer grain the services, the easier they are to scale.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;I think you get the idea. If we adapt to all the feedback, then we will avoid the pitfalls of the recent past. But also, the scope of the project will drastically grow, and the project will likely never get completed. It’s like a &lt;a href=&quot;https://en.wikipedia.org/wiki/Second-system_effect&quot;&gt;second-system effect&lt;/a&gt; but brought forward in time.&lt;/p&gt;
&lt;h2 id=&quot;the-solution&quot;&gt;The Solution&lt;/h2&gt;
&lt;div class=&quot;align-right&quot;&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/hearnoevil-245-19bb12389.webp 245w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/hearnoevil-245-bd3ff66f7.png 245w&quot; type=&quot;image/png&quot;&gt;&lt;img width=&quot;200px&quot; src=&quot;/blog/generated/assets/images/thought-leaders/hearnoevil-320-bd3ff66f7.png&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;figcaption&gt;
The Solution
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;p&gt;Thankfully, not all the advice I received was bad. One person, in particular, asked very pointed questions about the problems be solved and identified some potential blind spots in our plan. They also offered a great tip for dealing with advice that didn’t seem relevant to the project’s success: Create an extended product roadmap and put those items at least a year off into the future “and as long as they don’t seem relevant, you can just keep pushing them into the future.” Perversely this plan made everyone happy – everyone’s feedback is on the roadmap, and now it’s all just a question of priorities.&lt;/p&gt;
&lt;p&gt;With that bureaucratic judo trick, the project got off the ground. But the experience stayed with me. What made some advice valuable and some advice problematic? Was there some general principle behind expert advice?&lt;/p&gt;
&lt;h2 id=&quot;contingent-advice&quot;&gt;Contingent Advice&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;“All bad advice is alike, but all good advice is unique to the problem at hand.” ― Leo Tolstoy misquoted&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The problem with all the bad advice was that it was unrelated to the problem we were trying to solve. The unit-testing person will always be advocating for more unit tests. The distributed database person will always want things to go into their favorite database.&lt;/p&gt;
&lt;p&gt;It’s sort of like Minh’s cooking advice from King of The Hill: She tastes something and then says, “Add Nutmeg”. When would nutmeg not be a good fit? Doesn’t all advice need to be contingent?&lt;/p&gt;
&lt;div class=&quot;align-right&quot;&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/nutmeg-245-7afff0714.webp 245w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/nutmeg-245-821cf96ec.png 245w&quot; type=&quot;image/png&quot;&gt;&lt;img width=&quot;400px&quot; src=&quot;/blog/generated/assets/images/thought-leaders/nutmeg-800-821cf96ec.png&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;figcaption&gt;
The solution to every problem can’t be the same
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;p&gt;Uncontingent advice is what I think of when I hear the term thought-leader - someone has a single solution that seems to fit every problem. Whatever problem you face, the answer is test-driven-development or stream-architectures or being-really-truly-agile.&lt;/p&gt;
&lt;p&gt;I get frustrated by advice like that but is it wrong? Unit testing, streaming architectures, agile are all good things. I don’t write code in a test-driven style, but I did try it out a bit when it was the hot-thing™, and I learned a lot from the process. All of the thought-leaders are trying to move the industry forward. Still, there is some evidence that noncontingent, one-big-idea advice is less valuable than more nuanced, complicated advice.&lt;/p&gt;
&lt;h2 id=&quot;decision-making-research&quot;&gt;Decision-Making Research&lt;/h2&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/fork-800-2b7fa89b7.webp 800w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/fork-800-16d07ab07.png 800w&quot; type=&quot;image/png&quot;&gt;&lt;img src=&quot;/blog/generated/assets/images/thought-leaders/fork-800-16d07ab07.png&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;One way to think about advice is as a prediction. Advocating for TDD can be viewed as a prediction that if you don’t write tests before you write code, your project will be less well-designed and harder to maintain. Stream-Process-All-Things similarly predicts that if you approach a problem as one of streams you’ll get a better result than if you didn’t. Obviously, not all advice is tied to specific and explicit predictions, and many thought-leaders would object to the idea that just because they are always talking about a thing, that is the most critical thing in every case. But I do think it’s fair to say that if your proposed solution is always a variation of “use the actor system to model concurrency” or “you need a stronger allegiance to SOLID principles” then you believe those solutions would strongly increase desired project outcomes.&lt;/p&gt;
&lt;h2 id=&quot;tetlocks-hedgehogs&quot;&gt;Tetlock’s Hedgehogs&lt;/h2&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/hedgehog-800-a1ac11be4.webp 800w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/hedgehog-800-e849e8e15.png 800w&quot; type=&quot;image/png&quot;&gt;&lt;img width=&quot;1200px&quot; src=&quot;/blog/generated/assets/images/thought-leaders/hedgehog-800-e849e8e15.png&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;It turns out that &lt;a href=&quot;https://scholar.google.com/citations?user=CJjf6H0AAAAJ&amp;amp;hl=en&quot;&gt;Philip E. Tetlock&lt;/a&gt; from the University of Pennsylvania, who has been studying the judgment and decision making of experts for most of his career, has something to say about those types of predictions. And Tetlock is an expert on experts: his &lt;a href=&quot;https://en.wikipedia.org/wiki/The_Good_Judgment_Project&quot;&gt;Good Judgement Project&lt;/a&gt; was able to beat CIA analysts by 30% at predicting geo-political events. And the intelligence officers had access to classified information.&lt;/p&gt;
&lt;p&gt;Tetlock’s earliest work was the study of political experts. He solicited political advice and predictions from 284 experts between 1984 and 2004, and once enough time had passed to determine the accuracy of their forecasts, he scored the results. Political punditry is different from tech thought-leadership – none of my advice-givers were explicitly predicting a project outcome – but I think his findings have a lot to teach us.&lt;/p&gt;
&lt;p&gt;He found that experts could be split into two broad categories, the first of which he called Hedgehogs. A Hedgehog had one big idea like free-market capitalism (or nordic model capitalism or demand-side economics), which they used as a lens to look at many issues. They applied this big idea to every situation, which resulted in noncontingent and straightforward advice. You always need more freedom, nutmeg, and unit tests. Hedgehogs are “Confident forecasters”.&lt;/p&gt;
&lt;h2 id=&quot;the-foxes&quot;&gt;The Foxes&lt;/h2&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/foxes-800-5560f7120.webp 800w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/foxes-800-b46ad7089.png 800w&quot; type=&quot;image/png&quot;&gt;&lt;img width=&quot;1200px&quot; src=&quot;/blog/generated/assets/images/thought-leaders/foxes-800-b46ad7089.png&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;When all the predictions were added up and scored, hedgehogs lost out to his second category: Foxes. Foxes were the opposite of hedgehogs. They had complicated advice and were skeptical of even their own predictions. Tetlock also found that foxes were less likely to be famous because contingent advice is harder to explain in a sound bite.&lt;/p&gt;
&lt;p&gt;Hedgehogs with predictions about the 2003 Iraq war existed on both sides of the political spectrum. They had theories based on over-arching political philosophy, but the best predictors of the outcomes were foxes who had in-depth knowledge of the region, not big theories.&lt;/p&gt;
&lt;h3 id=&quot;ignore-universal-solutions&quot;&gt;Ignore Universal Solutions&lt;/h3&gt;
&lt;p&gt;&lt;picture&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/tools-800-1ce3fc773.webp 800w&quot; type=&quot;image/webp&quot;&gt;&lt;source srcset=&quot;/blog/generated/assets/images/thought-leaders/tools-800-af0026ab3.png 800w&quot; type=&quot;image/png&quot;&gt;&lt;img width=&quot;1200px&quot; src=&quot;/blog/generated/assets/images/thought-leaders/tools-800-af0026ab3.png&quot;&gt;&lt;/picture&gt;&lt;/p&gt;
&lt;p&gt;Tetlock’s &lt;a href=&quot;https://longnow.org/seminars/02007/jan/26/why-foxes-are-better-forecasters-than-hedgehogs/&quot;&gt;talk&lt;/a&gt; on this is subtitled “Ignore Confident Forecasters,” which I think is an excellent summary of his findings.&lt;/p&gt;
&lt;p&gt;Software development is full of confident forecasters. We are a pretty new field, and yet everyone seems so sure that they have the best solution to whatever problem is at hand. I’d like to hear more people saying things like, “in this specific context, test-coverage seem like an important metric,” or “StopLang is great if you can afford the GC, but if you can’t, then you should look at IronOre.” A great tool is not a universal tool it’s a tool well suited to a specific problem.&lt;/p&gt;
&lt;p&gt;The more universal a solution someone claims to have to whatever software engineering problem exists, and the more confident they are that it is a fully generalized solution, the more you should question them. The more specific and contingent the advice - the more someone says ‘it depends’ or ‘YourSQL works well in a read-heavy context with the following constraints’ the more likely they are to be leading you in the right direction. At least that’s what I have found.&lt;/p&gt;
&lt;p&gt;Here at Earthly, we’ve been talking to a lot of people about how they build software and doing a lot of writing. When meeting with someone or &lt;a href=&quot;/blog/unit-vs-integration&quot;&gt;writing down advice&lt;/a&gt;, I try to keep in mind Tetlock’s findings. I really think &lt;a href=&quot;https://earthly.dev&quot;&gt;repeatable builds&lt;/a&gt; are important, but if it’s my solution to every problem, then I think I’m probably falling into the same trap. So this post is my reminder to myself: Don’t be a &lt;del&gt;hedgehog&lt;/del&gt; thought-leader.&lt;/p&gt;</content><author><name>Adam Gordon Bell</name></author><category term="Articles" /><summary type="html">Here is a somewhat fictionalized personal story. I’ve changed the names of the people and the technology used.</summary></entry><entry><title type="html">Using Autotools to Configure, Make, and Install a Program</title><link href="https://earthly.dev/blog/autoconf/" rel="alternate" type="text/html" title="Using Autotools to Configure, Make, and Install a Program" /><published>2021-06-08T00:00:00-04:00</published><updated>2021-06-08T00:00:00-04:00</updated><id>https://earthly.dev/blog/autoconf</id><content type="html" xml:base="https://earthly.dev/blog/autoconf/">&lt;p&gt;&lt;a href=&quot;https://www.gnu.org/software/automake/manual/html_node/Autotools-Introduction.html&quot;&gt;Autotools&lt;/a&gt; is one of the most widely adopted code packaging and shipping tools available to developers on Linux. While there are alternatives, such as &lt;a href=&quot;https://cmake.org/&quot;&gt;CMake&lt;/a&gt;, &lt;a href=&quot;https://scons.org/&quot;&gt;SCons&lt;/a&gt;, and &lt;a href=&quot;https://www.boost.org/doc/libs/1_43_0/doc/html/jam/usage.html&quot;&gt;BJam&lt;/a&gt;, they don’t quite match Autotools in ease of use, power, and versability.&lt;/p&gt;
&lt;p&gt;At its base, Autotools can help make your application more portable, give it the versatility to be installed on many different systems, and can automatically procure scripts to check where elements are, like the compiler for your program. In this article, you will learn how to use Autotools to package up an application and ship it.&lt;/p&gt;
&lt;h2 id=&quot;components-of-autotools&quot;&gt;Components of Autotools&lt;/h2&gt;
&lt;p&gt;Autotools is made up of three unique components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;autoconf&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;automake&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;aclocal&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using these tools, you will create two files, &lt;code&gt;configure&lt;/code&gt; and &lt;code&gt;Makefile.in&lt;/code&gt;. These files are present in any project shipped using Autotools and are usually quite large and complex. Luckily, you don’t have to write them yourself—instead you’ll be writing the files &lt;code&gt;configure.ac&lt;/code&gt; and &lt;code&gt;Makefile.am&lt;/code&gt;, which will automatically generate the files you need.&lt;/p&gt;
&lt;h3 id=&quot;autoconf&quot;&gt;Autoconf&lt;/h3&gt;
&lt;p&gt;Autoconf is written in &lt;a href=&quot;https://www.gnu.org/software/autoconf/manual/autoconf-2.60/html_node/Programming-in-M4sh.html&quot;&gt;M4sh&lt;/a&gt;, using &lt;code&gt;m4&lt;/code&gt; macros. If you’ve heard of this before, then great! If you haven’t, no worries. &lt;code&gt;m4sh&lt;/code&gt; provides some macros you can use when creating your &lt;code&gt;configure.ac&lt;/code&gt; script and are part of why you can generate a massive &lt;code&gt;configure&lt;/code&gt; script without having to write too much actual code.&lt;/p&gt;
&lt;p&gt;The way it works is that you create a &lt;code&gt;configure.ac&lt;/code&gt; script in which you define various settings like release name, version, which compiler to use, and where it should output files. Once you’ve written your script, you run it through &lt;code&gt;autoconf&lt;/code&gt; to create your final &lt;code&gt;configure&lt;/code&gt; script. The purpose of &lt;code&gt;autoconf&lt;/code&gt; is to collect information from your system to populate the &lt;code&gt;Makefile.in&lt;/code&gt; template, which is created using &lt;code&gt;automake&lt;/code&gt;.&lt;/p&gt;
&lt;h3 id=&quot;automake&quot;&gt;Automake&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;Makefile.am&lt;/code&gt; script creates &lt;code&gt;Makefile.in&lt;/code&gt;. The principles behind this are the same as with &lt;code&gt;configure.ac&lt;/code&gt;: write a simple script in order to create a complex file. Automake is the component you’ll use to create the Makefile, a template that can then be populated with &lt;code&gt;autoconf&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Automake does so using variables and &lt;a href=&quot;http://www.fifi.org/doc/autobook/html/autobook_37.html&quot;&gt;primaries&lt;/a&gt;. An example of such a primary is &lt;code&gt;bin_PROGRAMS = helloworld&lt;/code&gt;, where the primary is the &lt;code&gt;_PROGRAMS&lt;/code&gt; suffix. This primary gives &lt;code&gt;automake&lt;/code&gt; some knowledge about your program, like where you want the produced binary to be installed.&lt;/p&gt;
&lt;p&gt;In this case, you’re telling &lt;code&gt;automake&lt;/code&gt; to install the &lt;code&gt;helloworld&lt;/code&gt; binary in the path defined by the &lt;code&gt;bindir&lt;/code&gt;. You may notice we didn’t define a &lt;code&gt;bindir&lt;/code&gt; variable, because that variable is built into &lt;code&gt;automake&lt;/code&gt; and is typically the default binary directory of your system.&lt;/p&gt;
&lt;p&gt;Other examples of primaries are &lt;code&gt;_SCRIPTS&lt;/code&gt;, which you can use when you want a script, rather than a binary to be installed somewhere, and &lt;code&gt;_DATA&lt;/code&gt;, when you have extra data files you want included in your installation. There are many more that you will find once you start using Autotools and figure out what your needs are.&lt;/p&gt;
&lt;p&gt;One last thing to mention is that although &lt;code&gt;Makefile.in&lt;/code&gt; is special in that it contains all of these primaries, it’s still a regular Makefile. Meaning you can write your own custom make targets if you want. For example, if you want to have a custom &lt;code&gt;clean&lt;/code&gt; target that deletes specific files, you can do so easily.&lt;/p&gt;
&lt;h3 id=&quot;aclocal&quot;&gt;Aclocal&lt;/h3&gt;
&lt;p&gt;This is the smallest component in the Autotools suite, but it’s very important. You learned in the previous section that &lt;code&gt;autoconf&lt;/code&gt; uses &lt;code&gt;m4&lt;/code&gt; macros to be configured. But where do these &lt;code&gt;m4&lt;/code&gt; macros come from? They’re generated by running the &lt;code&gt;aclocal&lt;/code&gt; command. Simple as that. If you don’t run &lt;code&gt;aclocal&lt;/code&gt; before running &lt;code&gt;autoconf&lt;/code&gt;, you’ll get an error complaining about missing macros.&lt;/p&gt;
&lt;h2 id=&quot;using-autotools&quot;&gt;Using Autotools&lt;/h2&gt;
&lt;p&gt;Now that you know the basic principles of how the Autotools suite is put together, it’s time to see it all in action and create a small C program that you can compile and ship.&lt;/p&gt;
&lt;h3 id=&quot;writing-the-source-program&quot;&gt;Writing the Source Program&lt;/h3&gt;
&lt;p&gt;The first thing you need is the program you want to compile and ship. Autotools is compatible with many different projects and languages, but for this example you’ll be working in &lt;code&gt;C&lt;/code&gt;, which is most commonly used. If you’re not familiar with &lt;code&gt;C&lt;/code&gt;, don’t worry, it’s very simple. Here’s your sample code:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode c&quot;&gt;&lt;code class=&quot;sourceCode c&quot;&gt;&lt;span id=&quot;cb1-1&quot;&gt;&lt;a href=&quot;#cb1-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;pp&quot;&gt;#include &lt;/span&gt;&lt;span class=&quot;im&quot;&gt;&amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-2&quot;&gt;&lt;a href=&quot;#cb1-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-3&quot;&gt;&lt;a href=&quot;#cb1-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-4&quot;&gt;&lt;a href=&quot;#cb1-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;main&lt;span class=&quot;op&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;int&lt;/span&gt; argc&lt;span class=&quot;op&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;char&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;*&lt;/span&gt; argv&lt;span class=&quot;op&quot;&gt;[])&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-5&quot;&gt;&lt;a href=&quot;#cb1-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;op&quot;&gt;{&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-6&quot;&gt;&lt;a href=&quot;#cb1-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  printf&lt;span class=&quot;op&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;Hello World&lt;/span&gt;&lt;span class=&quot;sc&quot;&gt;\n&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;);&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-7&quot;&gt;&lt;a href=&quot;#cb1-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;cf&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;dv&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-8&quot;&gt;&lt;a href=&quot;#cb1-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;op&quot;&gt;}&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;As you can see, it simply includes a standard in/standard out library and then prints &lt;code&gt;Hello World\n&lt;/code&gt;. Let’s start with&lt;code&gt;autoconf&lt;/code&gt; to configure this project.&lt;/p&gt;
&lt;h3 id=&quot;configuring-configure.ac&quot;&gt;Configuring configure.ac&lt;/h3&gt;
&lt;p&gt;When writing your &lt;code&gt;configure.ac&lt;/code&gt; file, there are a lot of options to choose from. You can get very specific about how you want your script to be configured, but some configurations need to be set. The first of these is &lt;code&gt;AC_INIT&lt;/code&gt;. This tells &lt;code&gt;autoconf&lt;/code&gt; what the name of your application is, what version it is, and who’s the maintainer. For this example, you’ll write:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb2-1&quot;&gt;&lt;a href=&quot;#cb2-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;AC_INIT&lt;/span&gt;&lt;span class=&quot;er&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;ex&quot;&gt;[helloworld],&lt;/span&gt; [0.1], [maintainer@example.com]&lt;span class=&quot;kw&quot;&gt;)&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;While &lt;code&gt;autoconf&lt;/code&gt; is generally used alongside &lt;code&gt;automake&lt;/code&gt;, it’s not necessary, so you need to initialize that by writing:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb3-1&quot;&gt;&lt;a href=&quot;#cb3-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;AM_INIT_AUTOMAKE&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Now that the generic options are initialized, you can get more specific with what you want. You need to specify what compiler you want the &lt;code&gt;configure&lt;/code&gt; script to use. You do this by writing:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb4&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb4-1&quot;&gt;&lt;a href=&quot;#cb4-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;AC_PROG_CC&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will tell the &lt;code&gt;configure&lt;/code&gt; script to look for a &lt;code&gt;C&lt;/code&gt; &lt;a href=&quot;/blog/compiling-containers-dockerfiles-llvm-and-buildkit&quot;&gt;compiler&lt;/a&gt;. For other applications, you may need more dependencies to build your program. By using the &lt;code&gt;AC_PATH_PROG&lt;/code&gt; macro, you can make &lt;code&gt;autoconf&lt;/code&gt; look for specific programs in a user’s &lt;code&gt;PATH&lt;/code&gt;. At this point, there are only two steps needed to finish your basic &lt;code&gt;configure.ac&lt;/code&gt; script:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;AC_CONFIG_FILES([Makefile])
AC_OUTPUT&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;code&gt;AC_CONFIG_FILES&lt;/code&gt; tells &lt;code&gt;autoconf&lt;/code&gt; that it should find a file called &lt;code&gt;Makefile.in&lt;/code&gt; and replace placeholders according to what we’ve specified. This can be things like version or maintainer. &lt;code&gt;AC_OUTPUT&lt;/code&gt; is the last thing you want to put in your &lt;code&gt;configure.ac&lt;/code&gt; script, as it tells &lt;code&gt;autoconf&lt;/code&gt; to output the final &lt;code&gt;configure&lt;/code&gt; script. In the end, your &lt;code&gt;configure.ac&lt;/code&gt; file should contain the following:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;AC_INIT([helloworld], [0.1], [maintainer@example.com])
AM_INIT_AUTOMAKE
AC_PROG_CC
AC_CONFIG_FILES([Makefile])
AC_OUTPUT&lt;/code&gt;&lt;/pre&gt;
&lt;h3 id=&quot;making-the-makefile&quot;&gt;Making the Makefile&lt;/h3&gt;
&lt;p&gt;When using &lt;code&gt;automake&lt;/code&gt;, you’ll have to adhere to a set of standards. One of these is that source files for a project are located in the &lt;code&gt;src&lt;/code&gt; folder. In this project, you have a single &lt;code&gt;main.c&lt;/code&gt; file in our root directory, so you need to tell &lt;code&gt;automake&lt;/code&gt; that:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb7&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb7-1&quot;&gt;&lt;a href=&quot;#cb7-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;AUTOMAKE_OPTIONS&lt;/span&gt; = foreign&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You need to tell &lt;code&gt;automake&lt;/code&gt; what you want your compiled binary to be called. In this case, you want it to be called &lt;code&gt;helloworld&lt;/code&gt;, so write the following:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb8&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb8-1&quot;&gt;&lt;a href=&quot;#cb8-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;bin_PROGRAMS&lt;/span&gt; = helloworld&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Only one thing left, and that is to tell &lt;code&gt;automake&lt;/code&gt; what files are needed to compile your application. Do this by writing:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb9&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb9-1&quot;&gt;&lt;a href=&quot;#cb9-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;helloworld_SOURCES&lt;/span&gt; = main.c&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Notice how the first part is the name of your application followed by the &lt;code&gt;SOURCES&lt;/code&gt; primary. Now &lt;code&gt;automake&lt;/code&gt; knows all that it needs to know, and your &lt;code&gt;Makefile.am&lt;/code&gt; is ready to use.&lt;/p&gt;
&lt;h3 id=&quot;creating-final-scripts&quot;&gt;Creating Final Scripts&lt;/h3&gt;
&lt;p&gt;Once you’ve written your &lt;code&gt;configure.ac&lt;/code&gt; and &lt;code&gt;Makefile.am&lt;/code&gt;, it’s relatively straightforward to distribute your application. Remember to start by running &lt;code&gt;aclocal&lt;/code&gt; so you can run &lt;code&gt;autoconf&lt;/code&gt;. Once you’ve run &lt;code&gt;autoconf&lt;/code&gt;, you can run &lt;code&gt;automake --add-missing&lt;/code&gt; to build your &lt;code&gt;Makefile.in&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;The reason for the &lt;code&gt;--add-missing&lt;/code&gt; flag is to tell &lt;code&gt;automake&lt;/code&gt; to automatically generate all of the additional files required, as usually you need more than just &lt;code&gt;Makefile.am&lt;/code&gt; and would have to manually enter in the other files.&lt;/p&gt;
&lt;p&gt;At this point, you have all you need to distribute your program. Before moving on on, here’s a short recap showing the commands you should’ve run by now:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb10&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb10-1&quot;&gt;&lt;a href=&quot;#cb10-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;aclocal&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb10-2&quot;&gt;&lt;a href=&quot;#cb10-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;autoconf&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb10-3&quot;&gt;&lt;a href=&quot;#cb10-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;automake&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--add-missing&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;distributing-the-program&quot;&gt;Distributing the Program&lt;/h3&gt;
&lt;p&gt;Distributing your application can seem like a daunting task, but Autotools makes it super easy. All you have to do is run &lt;code&gt;make dist&lt;/code&gt; after you’ve run the configure scripts above. This will produce a tarball, which you can then ship to your customers.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Now you’re able to use Autotools to compile and distribute your application, and you’re able to do it in a way that ensures it’s portable across a variety of systems. From here, you can start looking into automating this procedure and other ways to integrate Autotools directly into your daily development.&lt;/p&gt;
&lt;p&gt;The great advantage of using something like Autotools is that you’ll be using a system that has been in place for many years, is well-documented, and widely used. Many developers are comfortable installing applications using what Autotools produces, so it can make your application much more familiar and accessible.&lt;/p&gt;
&lt;p&gt;If your project becomes more complex and autotools maintenance becomes a burden, &lt;a href=&quot;https://earthly.dev/&quot;&gt;earthly&lt;/a&gt; is a great solution for containerized builds.&lt;/p&gt;</content><author><name>Kasper Siig</name></author><category term="Tutorial" /><summary type="html">Autotools is one of the most widely adopted code packaging and shipping tools available to developers on Linux. While there are alternatives, such as CMake, SCons, and BJam, they don’t quite match Autotools in ease of use, power, and versability.</summary></entry><entry><title type="html">Achieving Repeatability in Continuous Integration</title><link href="https://earthly.dev/blog/achieving-repeatability/" rel="alternate" type="text/html" title="Achieving Repeatability in Continuous Integration" /><published>2021-06-01T00:00:00-04:00</published><updated>2021-06-01T00:00:00-04:00</updated><id>https://earthly.dev/blog/achieving-repeatability</id><content type="html" xml:base="https://earthly.dev/blog/achieving-repeatability/">&lt;blockquote&gt;
&lt;p&gt;In software engineering, continuous integration is the practice of merging all developers’ working copies to a shared mainline several times a day. Grady Booch first proposed the term CI in his 1991 method, although he did not advocate integrating several times a day. —&lt;a href=&quot;https://en.wikipedia.org/wiki/Continuous_integration&quot; title=&quot;Wikipedia article on continuous integration&quot;&gt;Wikipedia&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Continuous Integration (CI) and continuous delivery (CD) are some of the best practices that any DevOps team can implement. You could argue that they’re necessary for teams looking to ship quality products fast and with confidence.&lt;/p&gt;
&lt;p&gt;CI and CD are two pieces of a whole, the former dealing with the task to automate the process of building, testing, and integrating new features and code changes into the codebase mainline; and the latter dealing with automating the process of delivering the changes to the defined environments.&lt;/p&gt;
&lt;p&gt;The implementation of both methodologies is often referred to as a &lt;strong&gt;CI/CD pipeline&lt;/strong&gt;; it is worth noting that both for CI and CD, the operating principles and coding philosophy are equally as important as the technical aspect of the implementation.&lt;/p&gt;
&lt;p&gt;CI’s technical goal is to provide consistent and automated results to build, package, and test applications. This repeatable flow and process allows teams to commit and merge changes more frequently, thus reducing the risk of conflicts or getting stuck in &lt;strong&gt;Integration Hell&lt;/strong&gt;.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Integration Hell refers to the point in production when members on a delivery team integrate their individual code. In traditional software development environments, this integration process is rarely smooth and seamless, instead resulting in hours or perhaps days of fixing the code so that it can finally integrate. Continuous Integration (CI) aims to avoid this completely by enabling and encouraging team members to integrate frequently (e.g., hourly, or at least daily). —&lt;a href=&quot;https://www.solutionsiq.com/agile-glossary/integration-hell/&quot; title=&quot;Accenture | SolutionsIQ&amp;#39;s definition of Integration Hell&quot;&gt;SolutionsIQ&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This article focuses on the concepts, tools, and best practices that will allow you to achieve a high degree of repeatability and consistency on your CI/CD pipeline.&lt;/p&gt;
&lt;h2 id=&quot;ci-repeatability-principles&quot;&gt;CI Repeatability Principles&lt;/h2&gt;
&lt;p&gt;One of the critical aspects of a successful and healthy CI pipeline is having repeatable builds, which guarantee consistent and reliable results. Four fundamental principles are essential to observe to achieve repeatability:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Reliability&lt;/li&gt;
&lt;li&gt;Reproducibility&lt;/li&gt;
&lt;li&gt;Reusability&lt;/li&gt;
&lt;li&gt;Speed&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;reliability&quot;&gt;Reliability&lt;/h3&gt;
&lt;p&gt;Reliability in continuous integration comes from knowing that the systems involved in testing the application are both available and capable of performing the complete set of tests that we need. This also means that the system has to produce consistent builds.&lt;/p&gt;
&lt;p&gt;Reliability gives the confidence to deliver shippable working code at any time during the application lifetime.&lt;/p&gt;
&lt;h3 id=&quot;reproducibility&quot;&gt;Reproducibility&lt;/h3&gt;
&lt;p&gt;CI infrastructure and pipelines can be—and more often than not, are—software assets on their own. The work done to create and implement CI runners and pipelines for our software projects can also be built, tested, and packaged just like any other software build.&lt;/p&gt;
&lt;p&gt;Examples of this are containerizing the environments used to run your test suites, including dependencies such as a database or ancillary applications for the end-to-end test suites.&lt;/p&gt;
&lt;p&gt;Treating the CI pipelines as another software project also allows the development team to reproduce the same results from the CI pipeline locally and shorten the feedback loop.&lt;/p&gt;
&lt;h3 id=&quot;reusability&quot;&gt;Reusability&lt;/h3&gt;
&lt;p&gt;With reproducible builds, we can achieve reusability, meaning that the same tools and process can be used in more than one project. Having a system in which we are not building a special custom CI pipeline for each project allows us to find patterns that we can apply to many projects.&lt;/p&gt;
&lt;p&gt;The type of reusable resources greatly varies depending on the type of applications and tests on each organization, from simple reusable scripts to containerized environments.&lt;/p&gt;
&lt;h3 id=&quot;speed&quot;&gt;Speed&lt;/h3&gt;
&lt;p&gt;One of the primary benefits of a good and effective CI process is the feedback loop it provides to the developers working on a project. Feedback loops start losing their value and &lt;a href=&quot;https://martinfowler.com/articles/developer-effectiveness.html&quot; title=&quot;Tim Cochran&amp;#39;s article on maximizing developer effectiveness at MartinFowler.com&quot;&gt;detract from developer effectiveness as they get slower&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We need to consider several factors when building a support CI pipeline, from the underlying hardware and test runners to the structure of the unit tests themselves as a larger unit. Integration tests do add to the overall testing time, and it’s important to keep that time short to make the value of the tests high.&lt;/p&gt;
&lt;h2 id=&quot;best-practices&quot;&gt;Best Practices&lt;/h2&gt;
&lt;p&gt;Now that we understand why &lt;strong&gt;reusability&lt;/strong&gt;, &lt;strong&gt;reproducibility&lt;/strong&gt;, &lt;strong&gt;reliability&lt;/strong&gt;, and &lt;strong&gt;speed&lt;/strong&gt; are important for building repeatable and effective continuous integration pipelines, let’s talk about specific practices and processes that can help achieve them.&lt;/p&gt;
&lt;h3 id=&quot;test-automation-and-coverage&quot;&gt;Test Automation and Coverage&lt;/h3&gt;
&lt;p&gt;To leverage the full value of continuous integration, you will need to automate all your tests and make sure they run for every change made to the repository. It’s also advisable to leverage the following:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Unit tests&lt;/strong&gt; to verify the behavior of small methods and functions&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Integration tests&lt;/strong&gt; to make sure multiple components work together&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Acceptance tests&lt;/strong&gt; to cover behavior required on the business specifications&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;End-to-end tests&lt;/strong&gt; to validate the behavior of the application as a whole from the user perspective&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&quot;adopting-continuous-integration&quot;&gt;Adopting Continuous Integration&lt;/h3&gt;
&lt;p&gt;While automation and observability of our pipelines are important, the cultural aspects of working with continuous integration and ensuring that the team adopts the continuous integration principles are equally as important.&lt;/p&gt;
&lt;h4 id=&quot;integrate-early-and-often&quot;&gt;Integrate Early and Often&lt;/h4&gt;
&lt;p&gt;A crucial cultural aspect of continuous integration is building the habit and cadence of the team committing their code every day and multiple times per day. By pushing their code frequently, developers can quickly find conflicts between two changes and also become aware of other work.&lt;/p&gt;
&lt;p&gt;Additionally, pushing their commits often allows developers to get feedback from the full CI pipeline running and allow them to identify defects in the code much sooner.&lt;/p&gt;
&lt;p&gt;The rule of thumb is that developers should commit their code every day, whether it is to the mainline branch on a feature branch. The more frequently you commit, the less opportunity there will be for conflict, errors, or broken tests, significantly increasing the team’s speed.&lt;/p&gt;
&lt;h4 id=&quot;fail-early-and-fail-fast&quot;&gt;Fail Early and Fail Fast&lt;/h4&gt;
&lt;p&gt;The whole point of continuous integration is providing rapid feedback. Nothing is more frustrating than a build that takes hours to complete, only to fail because of errors in some of the initial test suites.&lt;/p&gt;
&lt;p&gt;It is possible that due to the size of the application, the complete set of tests (unit, integration, end-to-end) might take a while to run. To help things go smoothly, you should consider the following processes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Breaking tests into groups (per module, per domain, and so forth) and running them in parallel&lt;/li&gt;
&lt;li&gt;Run critical path tests first (core or fundamental logic)&lt;/li&gt;
&lt;li&gt;Fail and stop the entire build if critical tests fail&lt;/li&gt;
&lt;li&gt;Integrate with notifications systems (Slack, email) to let developers know as soon things fail&lt;/li&gt;
&lt;/ul&gt;
&lt;h4 id=&quot;make-it-visible&quot;&gt;Make It Visible&lt;/h4&gt;
&lt;p&gt;A core tenet of continuous integration is communication, so you want to ensure that everyone can easily see the state of the system and the changes that have been made to it.&lt;/p&gt;
&lt;p&gt;Information such as the states of integration branches and the state of the mainline build become a priority. Back in the day, engineering teams would go as far as hooking up physical traffic lights to signal the state of the mainline branch.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/blog/assets/images/achieving-repeatability/anBo2up.png&quot; alt=&quot;Semaphore CI&quot; /&gt;&lt;figcaption aria-hidden=&quot;true&quot;&gt;Semaphore CI&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;p&gt;Nowadays, with cloud solutions being more prevalent and deeply integrated with source control systems, it’s much easier to give all developers a high degree of visibility. A perfect example is CI pipelines with &lt;a href=&quot;https://github.com/features/actions&quot; title=&quot;GitHub Actions workflow automation&quot;&gt;GitHub Actions&lt;/a&gt;, which provides feedback directly on pull requests and allows you to visualize the state of a pipeline at every given step.&lt;/p&gt;
&lt;figure&gt;
&lt;img src=&quot;/blog/assets/images/achieving-repeatability/twM26E6.png&quot; alt=&quot;Github Actions CI&quot; /&gt;&lt;figcaption aria-hidden=&quot;true&quot;&gt;Github Actions CI&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;h4 id=&quot;fix-broken-builds-immediately&quot;&gt;Fix Broken Builds Immediately&lt;/h4&gt;
&lt;p&gt;A crucial part of implementing continuous integrations is that if the mainline build fails, it needs to be fixed right away. One of the key points of working with CI is having a trusted, stable code base to develop against.&lt;/p&gt;
&lt;p&gt;The mainline build breaking is not necessarily a bad thing on its own. Still, it might highlight gaps in how the team works, like people not being careful enough about updating and building locally before committing.&lt;/p&gt;
&lt;p&gt;The fastest way to fix a broken build is to roll back to the last known good commit and review what happened. By all means, we should avoid debugging on the broken mainline; this becomes especially true when multiple teams are working on the same code base.&lt;/p&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;Continuous integration reduces risk by eliminating long integration efforts and reducing the feedback loops. To recap, there are many advantages to implementing continuous integration in your teams:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allows identifying bugs and software defects faster&lt;/li&gt;
&lt;li&gt;Reduces the feedback loop for engineers&lt;/li&gt;
&lt;li&gt;Removes blind spots that can occur with deferred integration&lt;/li&gt;
&lt;li&gt;Improves communication and velocity of the engineering teams&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To achieve repeatability in a CI/CD pipeline, it’s essential to keep in mind the following principles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Reliable&lt;/strong&gt; continuous integration environments help us avoid slowing down the feedback loops for the developers and maintain &lt;strong&gt;speed&lt;/strong&gt; of development.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reproducible&lt;/strong&gt; builds give our developers confidence to keep momentum and keep building with confidence.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reusability&lt;/strong&gt; allows us to leverage the tools, patterns, and environments for continuous integration across projects.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Speed&lt;/strong&gt; reduces the feedback cycle for developers, allowing them to ship more features in a shorter time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Finally, having continuous integration and continuous delivery removes one of the biggest barriers to implementing &lt;strong&gt;continuous deployment&lt;/strong&gt;. Continuous deployment extends this flow and enables fully automated deployments into production.&lt;/p&gt;
&lt;p&gt;The combination of continuous integration, continuous delivery, and continuous deployment allows teams to ship features faster and get them in front of customers faster, shortening the feedback loop and increasing value generation.&lt;/p&gt;
&lt;p&gt;For anyone looking to learn more about continuous integration, I highly recommend &lt;a href=&quot;https://martinfowler.com/&quot;&gt;Martin Fowler’s&lt;/a&gt; book &lt;a href=&quot;https://www.martinfowler.com/books/duvall.html&quot; title=&quot;Continuous Integration by Martin Fowler&quot;&gt;Continuous Integration&lt;/a&gt;.&lt;/p&gt;</content><author><name>Allan MacGregor</name></author><category term="Tutorials" /><summary type="html">In software engineering, continuous integration is the practice of merging all developers’ working copies to a shared mainline several times a day. Grady Booch first proposed the term CI in his 1991 method, although he did not advocate integrating several times a day. —Wikipedia</summary></entry><entry><title type="html">Creating and hosting your own deb packages and apt repo</title><link href="https://earthly.dev/blog/creating-and-hosting-your-own-deb-packages-and-apt-repo/" rel="alternate" type="text/html" title="Creating and hosting your own deb packages and apt repo" /><published>2021-06-01T00:00:00-04:00</published><updated>2021-06-01T00:00:00-04:00</updated><id>https://earthly.dev/blog/creating-and-hosting-your-own-deb-packages-and-apt-repo</id><content type="html" xml:base="https://earthly.dev/blog/creating-and-hosting-your-own-deb-packages-and-apt-repo/">&lt;!-- markdownlint-disable MD032 --&gt;
&lt;p&gt;As an Ubuntu user, I find myself typing &lt;code&gt;apt install ...&lt;/code&gt; frequently as a way to install software on my system. But what if I wanted to distribute my code to others via an apt repository? In this post I’ll cover how to 1) create a deb package, 2) create an apt repo, 3) signing that apt repo with a PGP key, and 4) putting it all together with some tests. &lt;!-- markdownlint-enable MD032 --&gt;&lt;/p&gt;
&lt;h2 id=&quot;prerequisites&quot;&gt;Prerequisites&lt;/h2&gt;
&lt;p&gt;This tutorial assumes you are using ubuntu, and that the following packages are installed:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb1-1&quot;&gt;&lt;a href=&quot;#cb1-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; apt-get install &lt;span class=&quot;at&quot;&gt;-y&lt;/span&gt; gcc dpkg-dev gpg&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h2 id=&quot;step-0-creating-a-simple-hello-world-program&quot;&gt;Step 0: creating a simple hello world program&lt;/h2&gt;
&lt;p&gt;Before getting started with packaging, let’s create a basic hello world program under &lt;code&gt;~/example/hello-world-program&lt;/code&gt;. To do this, you can copy and paste the following commands into your terminal:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb2-1&quot;&gt;&lt;a href=&quot;#cb2-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-p&lt;/span&gt; ~/example/hello-world-program&lt;/span&gt;
&lt;span id=&quot;cb2-2&quot;&gt;&lt;a href=&quot;#cb2-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-3&quot;&gt;&lt;a href=&quot;#cb2-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;#39;#include &amp;lt;stdio.h&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-4&quot;&gt;&lt;a href=&quot;#cb2-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;int main() {&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-5&quot;&gt;&lt;a href=&quot;#cb2-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;    printf(&amp;quot;hello packaged world\n&amp;quot;);&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-6&quot;&gt;&lt;a href=&quot;#cb2-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;    return 0;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb2-7&quot;&gt;&lt;a href=&quot;#cb2-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;}&amp;#39;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; ~/example/hello-world-program/hello.c&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then, you can compile it with:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb3-1&quot;&gt;&lt;a href=&quot;#cb3-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;cd&lt;/span&gt; ~/example/hello-world-program&lt;/span&gt;
&lt;span id=&quot;cb3-2&quot;&gt;&lt;a href=&quot;#cb3-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;gcc&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-o&lt;/span&gt; hello-world hello.c&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;There’s no technical reason for picking C for this example – the language doesn’t matter. It’s the binary we will be distributing in our deb package.&lt;/p&gt;
&lt;h2 id=&quot;step-1-creating-a-deb-package&quot;&gt;Step 1: Creating a deb package&lt;/h2&gt;
&lt;p&gt;Debian, and Debian-based linux distributions use &lt;code&gt;.deb&lt;/code&gt; packages to package and distribute programs. To start we will create a directory in the form:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;&amp;lt;package-name&amp;gt;_&amp;lt;version&amp;gt;-&amp;lt;release-number&amp;gt;_&amp;lt;architecture&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;where the&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;package-name&lt;/code&gt; is the name of our package, &lt;code&gt;hello-world&lt;/code&gt; in our case,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;version&lt;/code&gt; is the version of the software, &lt;code&gt;0.0.1&lt;/code&gt; in our case,&lt;/li&gt;
&lt;li&gt;&lt;code&gt;release-number&lt;/code&gt; is used to track different releases of the same software version; it’s usually set to &lt;code&gt;1&lt;/code&gt;, but hypothetically if there was an error in the packaging (e.g. a file was missed, or the description had an error in it, or a post-install script was wrong), this number would be increased to track the change, and&lt;/li&gt;
&lt;li&gt;&lt;code&gt;architecture&lt;/code&gt; is the target architecture of the platform, &lt;code&gt;amd64&lt;/code&gt; in this example; however if your package is architecture-independent (e.g. a python script), then you can set this to &lt;code&gt;all&lt;/code&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;Theoretically, the directory doesn’t have to follow this naming convention; however some of the tools we will use later in the tutorial require this directory naming convention.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;So for this example, we’ll create the directory with:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb5&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb5-1&quot;&gt;&lt;a href=&quot;#cb5-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-p&lt;/span&gt; ~/example/hello-world_0.0.1-1_amd64&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This directory will be the root of the package. Since we want our &lt;code&gt;hello-world&lt;/code&gt; binary to be installed system wide, we’ll have to store it under &lt;code&gt;usr/bin/hello-world&lt;/code&gt; with the following commands:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb6&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb6-1&quot;&gt;&lt;a href=&quot;#cb6-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;cd&lt;/span&gt; ~/example/hello-world_0.0.1-1_amd64&lt;/span&gt;
&lt;span id=&quot;cb6-2&quot;&gt;&lt;a href=&quot;#cb6-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-p&lt;/span&gt; usr/bin&lt;/span&gt;
&lt;span id=&quot;cb6-3&quot;&gt;&lt;a href=&quot;#cb6-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;cp&lt;/span&gt; ~/example/hello-world-program/hello-world usr/bin/.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Each package requires a &lt;code&gt;control&lt;/code&gt; file which needs to be located under the &lt;code&gt;DEBIAN&lt;/code&gt; directory. You can copy and paste the following to create one:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb7&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb7-1&quot;&gt;&lt;a href=&quot;#cb7-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-p&lt;/span&gt; ~/example/hello-world_0.0.1-1_amd64/DEBIAN&lt;/span&gt;
&lt;span id=&quot;cb7-2&quot;&gt;&lt;a href=&quot;#cb7-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-3&quot;&gt;&lt;a href=&quot;#cb7-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;Package: hello-world&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-4&quot;&gt;&lt;a href=&quot;#cb7-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Version: 0.0.1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-5&quot;&gt;&lt;a href=&quot;#cb7-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Maintainer: example &amp;lt;example@example.com&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-6&quot;&gt;&lt;a href=&quot;#cb7-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Depends: libc6&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-7&quot;&gt;&lt;a href=&quot;#cb7-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Architecture: amd64&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-8&quot;&gt;&lt;a href=&quot;#cb7-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Homepage: http://example.com&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-9&quot;&gt;&lt;a href=&quot;#cb7-9&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Description: A program that prints hello&amp;quot;&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;\&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb7-10&quot;&gt;&lt;a href=&quot;#cb7-10&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; ~/example/hello-world_0.0.1-1_amd64/DEBIAN/control&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that we’re assuming an amd64 Architecture for this tutorial, if your binary is for a different architecture, adjust accordingly. If you’re distributing a platform-independent package, you can set the architecture to &lt;code&gt;all&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;By this point you should have created two files:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;~/example/hello-world_0.0.1-1_amd64/usr/bin/hello-world
~/example/hello-world_0.0.1-1_amd64/DEBIAN/control&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;To build the .deb package, run:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb9&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb9-1&quot;&gt;&lt;a href=&quot;#cb9-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;dpkg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--build&lt;/span&gt; ~/example/hello-world_0.0.1-1_amd64&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This will output a deb package under &lt;code&gt;~/example/hello-world_0.0.1.deb&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;You can inspect the info of the deb by running:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb10&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb10-1&quot;&gt;&lt;a href=&quot;#cb10-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;dpkg-deb&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--info&lt;/span&gt; ~/example/hello-world_0.0.1.deb&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which will show:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb11&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb11-1&quot;&gt;&lt;a href=&quot;#cb11-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;new&lt;/span&gt; Debian package, version 2.0.&lt;/span&gt;
&lt;span id=&quot;cb11-2&quot;&gt;&lt;a href=&quot;#cb11-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;size&lt;/span&gt; 2832 bytes: control archive=336 bytes.&lt;/span&gt;
&lt;span id=&quot;cb11-3&quot;&gt;&lt;a href=&quot;#cb11-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;ex&quot;&gt;182&lt;/span&gt; bytes,     7 lines      control&lt;/span&gt;
&lt;span id=&quot;cb11-4&quot;&gt;&lt;a href=&quot;#cb11-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;Package:&lt;/span&gt; hello-world&lt;/span&gt;
&lt;span id=&quot;cb11-5&quot;&gt;&lt;a href=&quot;#cb11-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;Version:&lt;/span&gt; 0.0.1&lt;/span&gt;
&lt;span id=&quot;cb11-6&quot;&gt;&lt;a href=&quot;#cb11-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;Maintainer:&lt;/span&gt; example &lt;span class=&quot;op&quot;&gt;&amp;lt;&lt;/span&gt;example@example.com&lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb11-7&quot;&gt;&lt;a href=&quot;#cb11-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;Depends:&lt;/span&gt; libc6&lt;/span&gt;
&lt;span id=&quot;cb11-8&quot;&gt;&lt;a href=&quot;#cb11-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;Architecture:&lt;/span&gt; amd64&lt;/span&gt;
&lt;span id=&quot;cb11-9&quot;&gt;&lt;a href=&quot;#cb11-9&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;Homepage:&lt;/span&gt; http://example.com&lt;/span&gt;
&lt;span id=&quot;cb11-10&quot;&gt;&lt;a href=&quot;#cb11-10&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;Description:&lt;/span&gt; A program that prints hello&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You can also view the contents by running:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb12&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb12-1&quot;&gt;&lt;a href=&quot;#cb12-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;dpkg-deb&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--contents&lt;/span&gt; ~/example/hello-world_0.0.1.deb&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which will show:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;drwxrwxr-x alex/alex         0 2021-05-17 16:21 ./
drwxrwxr-x alex/alex         0 2021-05-17 16:18 ./usr/
drwxrwxr-x alex/alex         0 2021-05-17 16:18 ./usr/bin/
-rwxrwxr-x alex/alex     16696 2021-05-17 16:18 ./usr/bin/hello-world&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;It’s also possible to run &lt;code&gt;less ~/example/hello-world_0.0.1.deb&lt;/code&gt; which will output the above information, thanks to &lt;code&gt;/bin/lesspipe&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;This package can then be installed using the &lt;code&gt;-f&lt;/code&gt; option under &lt;code&gt;apt-get install&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb14&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb14-1&quot;&gt;&lt;a href=&quot;#cb14-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; apt-get install &lt;span class=&quot;at&quot;&gt;-f&lt;/span&gt; ~/example/hello-world_0.0.1-1_amd64.deb&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then once installed, you can verify it works with commands like:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb15&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb15-1&quot;&gt;&lt;a href=&quot;#cb15-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;which&lt;/span&gt; hello-world&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;hello-world&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which should output &lt;code&gt;/usr/bin/hello-world&lt;/code&gt; and &lt;code&gt;hello packaged world&lt;/code&gt; respectively.&lt;/p&gt;
&lt;p&gt;Finally, if you want to remove it, you can run:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb17&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb17-1&quot;&gt;&lt;a href=&quot;#cb17-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; apt-get remove hello-world&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This concludes the first step of building a &lt;code&gt;.deb&lt;/code&gt; package. If you have access to an existing apt repository, you could submit the deb to the repository maintainer, and call it a day.&lt;/p&gt;
&lt;h2 id=&quot;step-2-creating-an-apt-repository&quot;&gt;Step 2: Creating an apt repository&lt;/h2&gt;
&lt;p&gt;In this step, we will show how to create your own apt repository which can be used to host one or more deb packages.&lt;/p&gt;
&lt;p&gt;Let’s start with creating a directory to hold our debs:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb18&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb18-1&quot;&gt;&lt;a href=&quot;#cb18-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-p&lt;/span&gt; ~/example/apt-repo/pool/main/&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then copy our deb(s) into this directory:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb19&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb19-1&quot;&gt;&lt;a href=&quot;#cb19-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;cp&lt;/span&gt; ~/example/hello-world_0.0.1-1_amd64.deb ~/example/apt-repo/pool/main/.&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;Larger apt repositories create sub-directories for each program or project. For example, the official ubuntu apt repo stores all vim related packages under &lt;code&gt;/ubuntu/pool/main/v/vim/&lt;/code&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Once you’ve copied in all of your debs, we will create a different directory to contain a list of all available packages and corresponding metadata:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb20&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb20-1&quot;&gt;&lt;a href=&quot;#cb20-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;mkdir&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-p&lt;/span&gt; ~/example/apt-repo/dists/stable/main/binary-amd64&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;If you want to support multiple architectures, make a directory above for each type (e.g. &lt;code&gt;i386&lt;/code&gt;, &lt;code&gt;amd64&lt;/code&gt;, etc).&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Next, we will generate a &lt;code&gt;Packages&lt;/code&gt; file, which will contain a list of all availables packes in this repository. We will use the &lt;code&gt;dpkg-scanpackages&lt;/code&gt; program to generate it, by running:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb21&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb21-1&quot;&gt;&lt;a href=&quot;#cb21-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;cd&lt;/span&gt; ~/example/apt-repo&lt;/span&gt;
&lt;span id=&quot;cb21-2&quot;&gt;&lt;a href=&quot;#cb21-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;dpkg-scanpackages&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--arch&lt;/span&gt; amd64 pool/ &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; dists/stable/main/binary-amd64/Packages&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;It’s also good practice to compress the packages file, as apt will favour downloading compressed data whenever available. Let’s do this by running:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb22&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb22-1&quot;&gt;&lt;a href=&quot;#cb22-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;cat&lt;/span&gt; dists/stable/main/binary-amd64/Packages &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;gzip&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-9&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; dists/stable/main/binary-amd64/Packages.gz&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Let’s take a quick look at the contents of the Packages file:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Package: hello-world
Version: 0.0.1
Architecture: amd64
Maintainer: example &amp;lt;example@example.com&amp;gt;
Depends: libc6
Filename: pool/main/hello-world_0.0.1-1_amd64.deb
Size: 2832
MD5sum: 3eba602abba5d6ea2a924854d014f4a7
SHA1: e300cabc138ac16b64884c9c832da4f811ea40fb
SHA256: 6e314acd7e1e97e11865c11593362c65db9616345e1e34e309314528c5ef19a6
Homepage: http://example.com
Description: A program that prints hello&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;if you had multiple deb files, you would have an entry for each package&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;The contents of the Packages file is a list of all available packages along with metadata from the &lt;code&gt;DEBIAN/control&lt;/code&gt; file, and some hashes which can be used to validate the integrety of the package.&lt;/p&gt;
&lt;p&gt;Next we will create a Release file. Unfortunately &lt;code&gt;dpkg-scanpackages&lt;/code&gt; does not create Release files. Some people use programs like &lt;code&gt;apt-ftparchive&lt;/code&gt;; however in this example I’ll cover an alternative to &lt;code&gt;apt-ftparchive&lt;/code&gt; by using a small bash script.&lt;/p&gt;
&lt;p&gt;First let’s look at an example of a Release file, which can be broken up into two parts:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;&lt;p&gt;Metadata about the repository, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Origin: Example Repository
Label: Example
Suite: stable
Codename: stable
Version: 1.0
Architectures: amd64 arm64 arm7
Components: main
Description: An example software repository&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;A list of all &lt;code&gt;Packages&lt;/code&gt; files and their corresponding hashes and file size, for example:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;MD5Sum:
 9eb0c0528a0647daf18c7e225ac68f45 667 main/binary-amd64/Packages.gz
 628682afa8a0208e08b5a208a4c4c85b 1685 main/binary-amd64/Packages
 b5bef2199e86a43ae02adc0b7b38bc8a 556 main/binary-arm7/Packages.gz
 81c53db3b9c5e9de44d3ca9fc4487995 1289 main/binary-arm7/Packages
 15258b054124639f0641c399f291af17 557 main/binary-arm64/Packages.gz
 dc597a0815aebb56b25a4ad979682f49 1292 main/binary-arm64/Packages
SHA1:
 a4074284eb528e5d16c2c94e203d61dd825fa774 667 main/binary-amd64/Packages.gz
 ee86dd9061967232e6e68104a695f7d45d191b41 1685 main/binary-amd64/Packages
 a6f4897bcf6a4b068c5b8fafca01fc89761106dc 556 main/binary-arm7/Packages.gz
 43171192ce84dcb43bba99828fe7493ff23e0b0e 1289 main/binary-arm7/Packages
 9f353a909a9a3dab0a9cae1a3c7ccb879ff18d32 557 main/binary-arm64/Packages.gz
 da15c24e51a028ff591656eef0d1da0dbb85ba97 1292 main/binary-arm64/Packages
SHA256:
 dee57f6f4a2209b63301984acb4b279f694648915fd559287a414365884c1842 667 main/binary-amd64/Packages.gz
 7d82e5929d909d10d9f2d7129df3f6754946397caf1c08e9e4a65713f4ac39ff 1685 main/binary-amd64/Packages
 2b3c611305e096ef246d77d2bc5fcfa807034dd200f8f99005ab640cf2c014a4 556 main/binary-arm7/Packages.gz
 d03d5192e24e098a91465ab37d34e0a2c539f50a430eb3262a543e7bd11212a1 1289 main/binary-arm7/Packages
 f96316ff77e96d246447f0ca8383472acefc0744d9b49d2be1d214d174bba38a 557 main/binary-arm64/Packages.gz
 58120a7b5ceb57ab4faca01adac3d62009a52962e0d0a6f4b7ceb1b8faedf280 1292 main/binary-arm64/Packages&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;And that’s it for what a &lt;code&gt;Release&lt;/code&gt; file looks like. How hard could it be? let’s &lt;a href=&quot;/blog/understanding-bash&quot;&gt;write some bash&lt;/a&gt;. Just copy and paste the following in your terminal to get a copy of the script:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb26&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb26-1&quot;&gt;&lt;a href=&quot;#cb26-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;#39;#!/bin/sh&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-2&quot;&gt;&lt;a href=&quot;#cb26-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;set -e&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-3&quot;&gt;&lt;a href=&quot;#cb26-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-4&quot;&gt;&lt;a href=&quot;#cb26-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;do_hash() {&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-5&quot;&gt;&lt;a href=&quot;#cb26-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;    HASH_NAME=$1&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-6&quot;&gt;&lt;a href=&quot;#cb26-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;    HASH_CMD=$2&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-7&quot;&gt;&lt;a href=&quot;#cb26-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;    echo &amp;quot;${HASH_NAME}:&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-8&quot;&gt;&lt;a href=&quot;#cb26-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;    for f in $(find -type f); do&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-9&quot;&gt;&lt;a href=&quot;#cb26-9&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;        f=$(echo $f | cut -c3-) # remove ./ prefix&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-10&quot;&gt;&lt;a href=&quot;#cb26-10&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;        if [ &amp;quot;$f&amp;quot; = &amp;quot;Release&amp;quot; ]; then&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-11&quot;&gt;&lt;a href=&quot;#cb26-11&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;            continue&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-12&quot;&gt;&lt;a href=&quot;#cb26-12&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;        fi&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-13&quot;&gt;&lt;a href=&quot;#cb26-13&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;        echo &amp;quot; $(${HASH_CMD} ${f}  | cut -d&amp;quot; &amp;quot; -f1) $(wc -c $f)&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-14&quot;&gt;&lt;a href=&quot;#cb26-14&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;    done&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-15&quot;&gt;&lt;a href=&quot;#cb26-15&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;}&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-16&quot;&gt;&lt;a href=&quot;#cb26-16&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-17&quot;&gt;&lt;a href=&quot;#cb26-17&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;cat &amp;lt;&amp;lt; EOF&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-18&quot;&gt;&lt;a href=&quot;#cb26-18&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Origin: Example Repository&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-19&quot;&gt;&lt;a href=&quot;#cb26-19&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Label: Example&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-20&quot;&gt;&lt;a href=&quot;#cb26-20&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Suite: stable&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-21&quot;&gt;&lt;a href=&quot;#cb26-21&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Codename: stable&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-22&quot;&gt;&lt;a href=&quot;#cb26-22&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Version: 1.0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-23&quot;&gt;&lt;a href=&quot;#cb26-23&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Architectures: amd64 arm64 arm7&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-24&quot;&gt;&lt;a href=&quot;#cb26-24&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Components: main&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-25&quot;&gt;&lt;a href=&quot;#cb26-25&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Description: An example software repository&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-26&quot;&gt;&lt;a href=&quot;#cb26-26&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Date: $(date -Ru)&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-27&quot;&gt;&lt;a href=&quot;#cb26-27&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;EOF&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-28&quot;&gt;&lt;a href=&quot;#cb26-28&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;do_hash &amp;quot;MD5Sum&amp;quot; &amp;quot;md5sum&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-29&quot;&gt;&lt;a href=&quot;#cb26-29&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;do_hash &amp;quot;SHA1&amp;quot; &amp;quot;sha1sum&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-30&quot;&gt;&lt;a href=&quot;#cb26-30&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;do_hash &amp;quot;SHA256&amp;quot; &amp;quot;sha256sum&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb26-31&quot;&gt;&lt;a href=&quot;#cb26-31&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;&amp;#39;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; ~/example/generate-release.sh &lt;span class=&quot;kw&quot;&gt;&amp;amp;&amp;amp;&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;chmod&lt;/span&gt; +x ~/example/generate-release.sh&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Next let’s run the &lt;code&gt;generate-release.sh&lt;/code&gt; script with:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb27&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb27-1&quot;&gt;&lt;a href=&quot;#cb27-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;cd&lt;/span&gt; ~/example/apt-repo/dists/stable&lt;/span&gt;
&lt;span id=&quot;cb27-2&quot;&gt;&lt;a href=&quot;#cb27-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;~/example/generate-release.sh&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; Release&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;At this point, you can try hosting this repo for yourself. In this example we’ll use python’s simple http server; however in practice you’ll want to use a production-ready server. Here’s how you can start it up for testing:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb28&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb28-1&quot;&gt;&lt;a href=&quot;#cb28-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;cd&lt;/span&gt; ~/example&lt;/span&gt;
&lt;span id=&quot;cb28-2&quot;&gt;&lt;a href=&quot;#cb28-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;python3&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-m&lt;/span&gt; http.server&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then configure this apt repository:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb29&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb29-1&quot;&gt;&lt;a href=&quot;#cb29-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;deb [arch=amd64] http://127.0.0.1:8000/apt-repo stable main&amp;quot;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; tee /etc/apt/sources.list.d/example.list&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then finally update apt and install our new hello-world package:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb30&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb30-1&quot;&gt;&lt;a href=&quot;#cb30-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; apt-get update &lt;span class=&quot;at&quot;&gt;--allow-insecure-repositories&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb30-2&quot;&gt;&lt;a href=&quot;#cb30-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; apt-get install hello-world&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Note that the &lt;code&gt;--allow-insecure-repositories&lt;/code&gt; will print the following warning message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;W: The repository &amp;#39;http://127.0.0.1:8000/apt-repo stable Release&amp;#39; is not signed.
N: Data from such a repository can&amp;#39;t be authenticated and is therefore potentially dangerous to use.
N: See apt-secure(8) manpage for repository creation and user configuration details.&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That flag should never be used in a production environment. In the next section we’ll cover how to sign the repository, so it can be used in a trusted manor. Similarly when we install &lt;code&gt;hello-world&lt;/code&gt;, we are asked if we want to proceed with an un-authenticated package:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;WARNING: The following packages cannot be authenticated!
  hello-world
Install these packages without verification? [y/N]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Fortunately in the next section we’ll cover generating a PGP key, and signing our repository with it, which will allow users to verify the repository contents have not been tampered with.&lt;/p&gt;
&lt;h2 id=&quot;step-3-signing-your-apt-repository-with-gpg&quot;&gt;Step 3: Signing your apt repository with GPG&lt;/h2&gt;
&lt;p&gt;In the previous step, we generated a &lt;code&gt;Release&lt;/code&gt; file, which referenced one or more &lt;code&gt;Packages&lt;/code&gt; files along with it’s corresponding md5, sha1, and sha256 hashes. The &lt;code&gt;Packages&lt;/code&gt; file in turns references a deb package along with it’s md5, sha1, and sha256 hashes.&lt;/p&gt;
&lt;p&gt;As of 2021, md5 and sha1 hashes are no longer considered secure; however sha256 is still considered to be secure. Therefore if a user can verify that the initial Release file has not been tampered with, then they could make use of the sha256 to verify the Packages file, then use the sha256 contained in the Packages file to verify the deb file.&lt;/p&gt;
&lt;p&gt;In order to sign the apt repo, all we must do is sign the Release file.&lt;/p&gt;
&lt;h3 id=&quot;pgp-gpg-and-gnupgp&quot;&gt;PGP, GPG, and GnuPGP&lt;/h3&gt;
&lt;p&gt;&lt;em&gt;PGP, OpenPGP, GnuPG, GPG, (and careful not to typo PHP).&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Software has a lot of accronyms, and this extends into digital signatures. “Pretty Good Privacy” (PGP), was created in 1991 by Phil Zimmermann and eventually became the main product of non other than PGP Inc. To encourage adoption of PGP, the company created an open standard unsurprisingly called OpenPGP.&lt;/p&gt;
&lt;p&gt;OpenPGP is only a specification, that’s where GNU Privacy Guard (GPG) fits in: GPG is an implementation of (Open)PGP. So is it a PGP key, or a GPG key? I don’t know, I’ve seen it called both, I’m going to call it a PGP because that’s what is contained in the first line of the armoured text: &lt;code&gt;-----BEGIN PGP PUBLIC KEY BLOCK-----&lt;/code&gt;.&lt;/p&gt;
&lt;h4 id=&quot;creating-a-new-publicprivate-pgp-keypair&quot;&gt;Creating a new public/private PGP keypair&lt;/h4&gt;
&lt;p&gt;Let’s start with generating a PGP keypair. We will use the &lt;code&gt;--batch&lt;/code&gt; feature of &lt;code&gt;gpg&lt;/code&gt; rather than using the interactive prompt. This has the benefit of generating keys in a repeatible way. First create a batch template by copying and pasting the following into your terminal:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb33&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb33-1&quot;&gt;&lt;a href=&quot;#cb33-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;%echo Generating an example PGP key&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb33-2&quot;&gt;&lt;a href=&quot;#cb33-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Key-Type: RSA&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb33-3&quot;&gt;&lt;a href=&quot;#cb33-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Key-Length: 4096&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb33-4&quot;&gt;&lt;a href=&quot;#cb33-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Name-Real: example&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb33-5&quot;&gt;&lt;a href=&quot;#cb33-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Name-Email: example@example.com&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb33-6&quot;&gt;&lt;a href=&quot;#cb33-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;Expire-Date: 0&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb33-7&quot;&gt;&lt;a href=&quot;#cb33-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;%no-ask-passphrase&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb33-8&quot;&gt;&lt;a href=&quot;#cb33-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;%no-protection&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb33-9&quot;&gt;&lt;a href=&quot;#cb33-9&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;st&quot;&gt;%commit&amp;quot;&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; /tmp/example-pgp-key.batch&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;then we will generate it under a new temporary gpg keyring:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb34&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb34-1&quot;&gt;&lt;a href=&quot;#cb34-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;GNUPGHOME&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;mktemp&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-d&lt;/span&gt; ~/example/pgpkeys-XXXXXX&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb34-2&quot;&gt;&lt;a href=&quot;#cb34-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--no-tty&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--batch&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--gen-key&lt;/span&gt; /tmp/example-pgp-key.batch&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Since we overrode the GNUPGHOME to a temporary directory, we can keep this key seperate from our other keys. Let’s take a quick look at the contents of the directory:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb35&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb35-1&quot;&gt;&lt;a href=&quot;#cb35-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;ls&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$GNUPGHOME&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;/private-keys-v1.d&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;will show something along the lines of&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;A3FB218BA1929542FF110C7D1B077B6469F769C9.key&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;which contains binary data. We can also view all of our loaded keys with:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb37&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb37-1&quot;&gt;&lt;a href=&quot;#cb37-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--list-keys&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which will show something similar to&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/home/alex/example/pgpkeys-pyml86/pubring.kbx
-------------------------------
pub   rsa4096 2021-05-18 [SCEA]
      B4D5C8B003C50A38A7E85B5989376CAC59892E72
uid           [ultimate] example &amp;lt;example@example.com&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This PGP key is comprised of both a public key, and a private key. Let’s start with exporting the public key:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb39&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb39-1&quot;&gt;&lt;a href=&quot;#cb39-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--armor&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--export&lt;/span&gt; example &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; ~/example/pgp-key.public&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Alternatively, you can reference the key by the email address or even the associated hex code. This should result in a public key that looks like:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-----BEGIN PGP PUBLIC KEY BLOCK-----

mQINBGCkNmcBEADjEcDdne3ti5derY+hSPnhrBWeBba/1gb3S7lKwsysFlxeAApU
mROTk7gijH84GofOkZzQw9PJEA4u4kkF6EFfOr+VS3JDt5kYjpGorXMD8iRtJAIq
Y6hX7vqNDHpXFHSEEBIFCUF9E3yf8p7Wrohe0/6HVz1m/XAcU34zWY3a4zfgntsd
r4hj1h3E/GkZEI8UpB+/LshzbIoZMEDy+EB3EX/oCstZc9aKTUZLP9q5r3CvbrJU
s3354N+XFxCocVv4c/UFtcUI14EfQv7LVB2JRWYrit65DAHx87V4xcajqbkswvYn
4ela0DCW/Bw2jz1DaEHLGzn9me6z+YYH8VWbYqUJ/hrHHHSqjjSZ3S5E8gLVzTuf
IpoWUCSNeZlltBqoWf4ei7Q4nhzFi7AkvLABSkmx7R1+7fOH0ZIN+M2G6lOgcHEU
IiS7v6ygyj1U2h+38xn66dDH/gUhjp0zJfivMnC1c7pz7R4zNhFxyv1cyekP1nJA
wmpW+Y5ja3qSJYCHGmrtNaQIVMo2Ho1aXZiMysaTXKp4CYluoUsh97GjLtksq834
y3+FHdGMt8dGFBCRlZ9BFr1B++FZvuovbLoS+ZREmXTQPXYhN0TinpmnSFJsY6DK
5zFOU9j3Mtmf77MxUA+xsKBQrDgGM76uN7ADTc0jrUo4hECxnXQkOGyYrQARAQAB
tB1leGFtcGxlIDxleGFtcGxlQGV4YW1wbGUuY29tPokCTgQTAQoAOBYhBLTVyLAD
xQo4p+hbWYk3bKxZiS5yBQJgpDZnAhsvBQsJCAcCBhUKCQgLAgQWAgMBAh4BAheA
AAoJEIk3bKxZiS5yTUMP/1nlYpQTf8tQgSwSVUM8jhBhdOEEzmsXy/90KgpjX9WF
ABSC61SnGRonO60dn5CHT4oi0yJRKtsjJ3ZXLyxJY4Myop4ZCoJCcJw6sBOc3rvl
GN4J4O3+DZn7KRGUKFmLgeuxie2tSHdWYkonlpGPQ34xLgKT6Uf1NQOcCLZpMBim
2kxNXnnQXLEKXlbm9xmi/koub1qpko01T9DT9g9mlkv56660+sOw0XNwGmPy6HJ2
2IND53LYDNQv4qbt00ws29AUmZ6WmlUB9oP/nMx56Urgvmn6p/CLB9vbwIAb6egq
ZouUKsFAFyO5oVH3JoNBYbT84QewQv9BnJVQjuh0wK3OdCBjzT3YcBuRVwVJubKv
nSjvkJtq20tgxDSPc5ostzMpT5ZnBV+VQa6fwqBgb7VIGEPQklo6IZRwDH0rX1IA
Xpe2dZOvUICqvg17ol29uQ81BRpB7UynPDbgPDhBbELELPQN/GfaL+op8AB+cbga
JgC1JcX08nOqnT9TMpfig4TEpL/BKO+3cFy0Sttm44zMrR1f1SiyXdjZTS715LM/
nmAQWCZFMqN+5nHfT6lwJlqmtRCvjvHPdZla8Ah6B9oB+vJs1cClYJLSZuun89P/
bmQ5z+qJwCUOEVhVcVPTHAkqCTX2apQBeAszcmk54bGc/Q6UKncOgvOkELS7VuPt
=DYDE
-----END PGP PUBLIC KEY BLOCK-----&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;If the exported key is much larger than this, you may have exported multiple keys which can cause issues with some repositories.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;You can verify only a single key was exported by running:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb41&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb41-1&quot;&gt;&lt;a href=&quot;#cb41-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;cat&lt;/span&gt; ~/example/pgp-key.public &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--list-packets&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and checking that only a single &lt;code&gt;:public key packet:&lt;/code&gt; entry exists. It should look something like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;# off=0 ctb=99 tag=6 hlen=3 plen=525
:public key packet:
    version 4, algo 1, created 1621374567, expires 0
    pkey[0]: [4096 bits]
    pkey[1]: [17 bits]
    keyid: 89376CAC59892E72
# off=528 ctb=b4 tag=13 hlen=2 plen=29
:user ID packet: &amp;quot;example &amp;lt;example@example.com&amp;gt;&amp;quot;
# off=559 ctb=89 tag=2 hlen=3 plen=590
:signature packet: algo 1, keyid 89376CAC59892E72
    version 4, created 1621374567, md5len 0, sigclass 0x13
    digest algo 10, begin of digest 4d 43
    hashed subpkt 33 len 21 (issuer fpr v4 B4D5C8B003C50A38A7E85B5989376CAC59892E72)
    hashed subpkt 2 len 4 (sig created 2021-05-18)
    hashed subpkt 27 len 1 (key flags: 2F)
    hashed subpkt 11 len 4 (pref-sym-algos: 9 8 7 2)
    hashed subpkt 21 len 5 (pref-hash-algos: 10 9 8 11 2)
    hashed subpkt 22 len 3 (pref-zip-algos: 2 3 1)
    hashed subpkt 30 len 1 (features: 01)
    hashed subpkt 23 len 1 (keyserver preferences: 80)
    subpkt 16 len 8 (issuer key ID 89376CAC59892E72)
    data: [4095 bits]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next let’s export the private key so we can back it up somewhere safe.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb43&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb43-1&quot;&gt;&lt;a href=&quot;#cb43-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--armor&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--export-secret-keys&lt;/span&gt; example &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; ~/example/pgp-key.private&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;You should never share this key with anyone. If you look at the output file, it should look similar to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-----BEGIN PGP PRIVATE KEY BLOCK-----
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=+Tgf
-----END PGP PRIVATE KEY BLOCK-----&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;The above is a burner-key I created for this article. It’s never been used for anything aside from this article. You should be generating your own key, don’t use this one.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Now that we’ve generated a PGP keypair, let’s move on to signing files with them.&lt;/p&gt;
&lt;h4 id=&quot;signing-the-release-file&quot;&gt;Signing the Release file&lt;/h4&gt;
&lt;p&gt;Before we start signing with out keys, let’s make sure that we can import the backup we made. To do that, we will create a new GPG keyring location:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb45&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb45-1&quot;&gt;&lt;a href=&quot;#cb45-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;export&lt;/span&gt; &lt;span class=&quot;va&quot;&gt;GNUPGHOME&lt;/span&gt;&lt;span class=&quot;op&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$(&lt;/span&gt;&lt;span class=&quot;fu&quot;&gt;mktemp&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-d&lt;/span&gt; ~/example/pgpkeys-XXXXXX&lt;span class=&quot;va&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;&amp;quot;&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;and then verify that it is empty:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb46&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb46-1&quot;&gt;&lt;a href=&quot;#cb46-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--list-keys&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which should show something similar to:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gpg: keybox &amp;#39;/home/alex/example/pgpkeys-e7u1Ad/pubring.kbx&amp;#39; created
gpg: /home/alex/example/pgpkeys-e7u1Ad/trustdb.gpg: trustdb created&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Next we will import our backed up private key:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb48&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb48-1&quot;&gt;&lt;a href=&quot;#cb48-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;cat&lt;/span&gt; ~/example/pgp-key.private &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--import&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;which should show a similar imported message:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;gpg: key 4E793BC948F34C6F: public key &amp;quot;example &amp;lt;example@example.com&amp;gt;&amp;quot; imported
gpg: key 4E793BC948F34C6F: secret key imported
gpg: Total number processed: 1
gpg:               imported: 1
gpg:       secret keys read: 1
gpg:   secret keys imported: 1&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;and now if we run &lt;code&gt;gpg --list-keys&lt;/code&gt;, we should see it is now available:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;/home/alex/example/pgpkeys-e7u1Ad/pubring.kbx
---------------------------------------------
pub   rsa4096 2021-05-18 [SCEA]
      CFBFFC9CCD163CC7E1768BFF4E793BC948F34C6F
uid           [ unknown] example &amp;lt;example@example.com&amp;gt;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Ok, let’s get around to signing the &lt;code&gt;Release&lt;/code&gt; file now.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb51&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb51-1&quot;&gt;&lt;a href=&quot;#cb51-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;cat&lt;/span&gt; ~/example/apt-repo/dists/stable/Release &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--default-key&lt;/span&gt; example &lt;span class=&quot;at&quot;&gt;-abs&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; ~/example/apt-repo/dists/stable/Release.gpg&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The contents of &lt;code&gt;Release.gpg&lt;/code&gt; should be similar to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-----BEGIN PGP SIGNATURE-----

iQJIBAABCgAyFiEEz7/8nM0WPMfhdov/Tnk7yUjzTG8FAmCkTYYUHGV4YW1wbGVA
ZXhhbXBsZS5jb20ACgkQTnk7yUjzTG+f2g//QpVA4RP5qp2mAlolhqKCqLr6r7DX
mUC5ueSISXlRwVK7l0xFADqw4uHsl+T0DIeX7K/efHyyqIYq+t8fCA8HbB5CmWFk
2rOa9jFR4G+afJ1mdfQYUHshwEzY+NIScg3suO0ZeILFXcTW6a6AzlwqI3pVy/b8
o/FCjj4hBnaPysDS1BmPqxjWvt5ilQR3RTodsFahr2FncmgZI8zvrbCey630O/Cs
ELLp9fqBQj//FEje/JgHtG6E85qjsod0Nstu5h2yEs9iwMP1+peMB80NLpyeacpS
CWbZmFgxqKL7JNSx04T8epL23Zg6trrzhvOzOiVp2+Ilg438LBrErSVO+3puWT2e
bR3jpFSg9ej0+90QnG3IIkZW1RSkitlpNiFGFrUvlBRE9tSjZMK10EofPtzENEWN
uXYqjcWTJxp6R7d1IW/lTFzwdCPorgBPBbjmJ7Ux5YWZP7jjJmFpF9jSHVz6xDcp
oUBQcF4jHn5ewh0yKZQbqA3ZRXpPBDSNSraIDFToeFzhV94FQR2f5A5FgBR8n/Kr
Gfb76dsKabwVJlr7z8+W2C8gHmOe4dlVVUje3bxo05VNwZEBPbRldFox4GKIWT46
FbXyzB/EfRR7rzmaRfIpDfQa6hLOoivlat1no6akT7bK2mE7Y0L+Kae1dP+BpBUe
BqY84ZTkmQiOL0c=
=Dqab
-----END PGP SIGNATURE-----&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Now when an apt client performs an update, it will fetch both &lt;code&gt;Release&lt;/code&gt; and &lt;code&gt;Release.gpg&lt;/code&gt; and will verify the signature is valid; However to increase the speed, we will create a third file &lt;code&gt;InRelease&lt;/code&gt; which will combine both the contents of &lt;code&gt;Release&lt;/code&gt; and the PGP signature:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb53&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb53-1&quot;&gt;&lt;a href=&quot;#cb53-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;cat&lt;/span&gt; ~/example/apt-repo/dists/stable/Release &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;ex&quot;&gt;gpg&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--default-key&lt;/span&gt; example &lt;span class=&quot;at&quot;&gt;-abs&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;--clearsign&lt;/span&gt; &lt;span class=&quot;op&quot;&gt;&amp;gt;&lt;/span&gt; ~/example/apt-repo/dists/stable/InRelease&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The contents of &lt;code&gt;InRelease&lt;/code&gt; should be similar to this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA512

Origin: Example Repository
Label: Example
Suite: stable
Codename: stable
Version: 1.0
Architectures: amd64 arm64 arm7
Components: main
Description: An example software repository
Date: Tue, 18 May 2021 01:17:46 +0000
MD5Sum:
 d47739655e6312da85a96711f78c78db 405 main/binary-amd64/Packages
SHA1:
 d6aa46cf29cca1b01af6e9e256bf963ff5dfdaeb 405 main/binary-amd64/Packages
SHA256:
 3b888d4257fcf475fc06f74bd46045c3f1d667562fdb37e86f5bea642efa49f8 405 main/binary-amd64/Packages
-----BEGIN PGP SIGNATURE-----

iQJIBAEBCgAyFiEEz7/8nM0WPMfhdov/Tnk7yUjzTG8FAmCkT1wUHGV4YW1wbGVA
ZXhhbXBsZS5jb20ACgkQTnk7yUjzTG8w/RAAwB6HRyZWVOWT1A0OJAt+RlLREjev
gfRZVLZRDv18QRZKCcj71v0Ki1hX3xWE8WVjIR9eSXNf1wJvqza+/FBGN00NY1Bk
AFmypZP/04kjwGeUtULopLB1KrCaFdWuC9W49zUyeElIz1owX9tk+SsoLB7hGLQE
jtweFjxhaMeCHgSJIXDoR0RpmKBuydtB3UTHjCQJBvErkYfKrAJQCDYDz+XVPLh6
XPAohVb6SO4qBCxX30QcQpUVDRtMMRKbIOD5B+hjCP5cupvej1fBlzlFh4lBIywj
eUXrwBxmOiO/yrsYNoJJB+mV9u1mEpQDo7yRDCICsY2c/Io/Q0CxiEIIwoEfHCb/
WOFYYmUj1Sh9YARi74eTblMyr/Ay/9+opEr54uAixecJyC/kqsC3uptH4ZpOSwTw
hdj24Cl2veYmiCimPB4QCLOsCU5A1phwEkgADUOh4iRaszuzGkh/NZ0al0dCF0HY
/UsDuiMzEQGOP6ByILt1zoPrnwZKFDEbYjzSbjSXfkU9LKfrp5PWgeeq5iD58sQW
ZCE34ksK8W67GOtQuzy0Z8NlTJY1Mkzp7IsUt60owyv6dQVZFIPYwGEisGFSOCNk
3VZ66m1D6HtDZ60CZEJUhfu+WTC1K95cKYkhYArBR9pDecygYomLQVFO2T1ENxCA
BKaAtOSl2Jcb4eA=
=3Hft
-----END PGP SIGNATURE-----&lt;/code&gt;&lt;/pre&gt;
&lt;h4 id=&quot;testing-it-out&quot;&gt;Testing it out&lt;/h4&gt;
&lt;p&gt;We need to tell apt which public pgp key to use when verifying the apt repository. We will add a new &lt;code&gt;signed-by&lt;/code&gt; attribute to our apt config:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb55&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb55-1&quot;&gt;&lt;a href=&quot;#cb55-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;echo&lt;/span&gt; &lt;span class=&quot;st&quot;&gt;&amp;quot;deb [arch=amd64 signed-by=&lt;/span&gt;&lt;span class=&quot;va&quot;&gt;$HOME&lt;/span&gt;&lt;span class=&quot;st&quot;&gt;/example/pgp-key.public] http://127.0.0.1:8000/apt-repo stable main&amp;quot;&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt; &lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; tee /etc/apt/sources.list.d/example.list&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;div class=&quot;notice--info&quot;&gt;
&lt;p&gt;note that &lt;code&gt;$HOME&lt;/code&gt; should be expanded to the absolute path of the pgp key.&lt;/p&gt;
&lt;/div&gt;
&lt;p&gt;Next start back up your webserver:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb56&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb56-1&quot;&gt;&lt;a href=&quot;#cb56-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;bu&quot;&gt;cd&lt;/span&gt; ~/example&lt;/span&gt;
&lt;span id=&quot;cb56-2&quot;&gt;&lt;a href=&quot;#cb56-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;python3&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-m&lt;/span&gt; http.server&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Then finally try updating and re-installing our hello-world package:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb57&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb57-1&quot;&gt;&lt;a href=&quot;#cb57-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; apt-get clean&lt;/span&gt;
&lt;span id=&quot;cb57-2&quot;&gt;&lt;a href=&quot;#cb57-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; apt-get update&lt;/span&gt;
&lt;span id=&quot;cb57-3&quot;&gt;&lt;a href=&quot;#cb57-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;fu&quot;&gt;sudo&lt;/span&gt; apt-get install hello-world&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;This time you shouldn’t see any security warnings.&lt;/p&gt;
&lt;h4 id=&quot;keeping-your-private-key-secure&quot;&gt;Keeping your private key secure&lt;/h4&gt;
&lt;p&gt;If you followed this tutorial to the tee, and your webserver is still running, what happens if we try running:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb58&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb58-1&quot;&gt;&lt;a href=&quot;#cb58-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;curl&lt;/span&gt; http://127.0.0.1:8000/pgp-key.private&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Oh no! we just leaked our private key. Now’s the time to regenerate it but using a real name and email address other than &lt;code&gt;example@example.com&lt;/code&gt;. Maybe you can store it in earthly’s &lt;a href=&quot;https://docs.earthly.dev/docs/guides/cloud-secrets&quot;&gt;secret store&lt;/a&gt; instead?&lt;/p&gt;
&lt;h2 id=&quot;appendix-a-a-complete-example-using-earthly&quot;&gt;Appendix A: A complete example using Earthly&lt;/h2&gt;
&lt;p&gt;A complete example has been created under &lt;a href=&quot;https://github.com/earthly/example-apt-repo/blob/main/Earthfile&quot;&gt;github.com/earthly/example-apt-repo/Earthfile&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;This Earthfile contains all the above steps from this tutorial in a single location, which can be run directly in a single shot with:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb59&quot;&gt;&lt;pre class=&quot;sourceCode bash&quot;&gt;&lt;code class=&quot;sourceCode bash&quot;&gt;&lt;span id=&quot;cb59-1&quot;&gt;&lt;a href=&quot;#cb59-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;ex&quot;&gt;earthly&lt;/span&gt; &lt;span class=&quot;at&quot;&gt;-P&lt;/span&gt; github.com/earthly/example-apt-repo+test&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Alternatively, you can clone the repo and run &lt;code&gt;+test&lt;/code&gt; directly.&lt;/p&gt;</content><author><name>Alex Couture-Beil</name></author><category term="Tutorials" /><summary type="html">As an Ubuntu user, I find myself typing apt install ... frequently as a way to install software on my system. But what if I wanted to distribute my code to others via an apt repository? In this post I’ll cover how to 1) create a deb package, 2) create an apt repo, 3) signing that apt repo with a PGP key, and 4) putting it all together with some tests.</summary></entry><entry><title type="html">Why is JRuby Slow?</title><link href="https://earthly.dev/blog/jruby/" rel="alternate" type="text/html" title="Why is JRuby Slow?" /><published>2021-05-26T00:00:00-04:00</published><updated>2021-05-26T00:00:00-04:00</updated><id>https://earthly.dev/blog/jruby</id><content type="html" xml:base="https://earthly.dev/blog/jruby/">&lt;p&gt;Recently, I made some contributions to the continuous integration process for Jekyll. Jekyll is a static site generator created by GitHub and written in Ruby, and it uses &lt;a href=&quot;http://earthly.dev/&quot;&gt;Earthly&lt;/a&gt; and GitHub Actions to test that it works with Ruby 2.5, 2.7, 3.0, and JRuby.&lt;/p&gt;
&lt;p&gt;The build times looked like this:&lt;/p&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Ruby Version&lt;/th&gt;
&lt;th style=&quot;text-align: center;&quot;&gt;Jekyll CI Time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;2.5&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;8m 31s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;2.7&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;8m 33s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;3.0&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;7m 47s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;JRuby&lt;/td&gt;
&lt;td style=&quot;text-align: center;&quot;&gt;45m 16s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figcaption&gt;
A Representative Jekyll CI &lt;a href=&quot;https://github.com/jekyll/jekyll/runs/2048545456?check_suite_focus=true&quot;&gt;Build&lt;/a&gt;
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;p&gt;The Jekyll CI does lots of things in it that a simple Jekyll site build might not but clearly JRuby was slowing the whole process down by a significant amount, and this surprised me: Wasn’t the entire point of using JRuby, and its new brother TruffleRuby, speed? &lt;strong&gt;Why was JRuby so slow?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Even building this blog and using all the tricks I’ve found, the performance of Ruby on the JVM still looks like this:&lt;/p&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Runtime&lt;/th&gt;
&lt;th&gt;Jekyll Build Time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;MRI Ruby 2.7.0&lt;/td&gt;
&lt;td&gt;2.64 seconds&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Fastest Ruby on JVM Build&lt;/td&gt;
&lt;td&gt;25.7 seconds&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figcaption&gt;
Building This blog is 10x slower
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;p&gt;So why is Jruby slow in these examples? It turns out that the answer is complicated.&lt;/p&gt;
&lt;h2 id=&quot;what-is-jruby&quot;&gt;What is JRuby?&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;I was very happy to discover the JRuby project, my favorite programming language running on what’s probably the best virtual machine in the world. - Peter Lind&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;JRuby is an alternative Ruby interpreter that runs on the Java Virtual Machine (JVM). MRI Ruby, also known as CRuby, is written in C and is the standard interpreter and runtime for Ruby.&lt;/p&gt;
&lt;h3 id=&quot;install-jruby&quot;&gt;Install JRuby&lt;/h3&gt;
&lt;p&gt;On my mac book, I can switch from the MRI Ruby to JRuby like this.&lt;/p&gt;
&lt;p&gt;Install rbenv:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brew install rbenv&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List possible install options:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rbenv install -l     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Install:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rbenv install jruby-9.2.16.0&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Set a specific project to use JRuby:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rbenv local jruby-9.2.16.0&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;why-do-people-use-jruby&quot;&gt;Why do people use JRuby?&lt;/h2&gt;
&lt;blockquote class=&quot;twitter-tweet&quot;&gt;
&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;
OMG &lt;a href=&quot;https://twitter.com/hashtag/JRuby?src=hash&amp;amp;ref_src=twsrc%5Etfw&quot;&gt;#JRuby&lt;/a&gt; +Java.util.concurrent FTW! Doing a recursive backtrace through billion+, I've made it 30,000x faster than 1.9.3. 30 THOUSAND.
&lt;/p&gt;
— /dave/null (&lt;span class=&quot;citation&quot; data-cites=&quot;bokmann&quot;&gt;@bokmann&lt;/span&gt;) &lt;a href=&quot;https://twitter.com/bokmann/status/381422498170273792?ref_src=twsrc%5Etfw&quot;&gt;September 21, 2013&lt;/a&gt;
&lt;/blockquote&gt;
&lt;script async src=&quot;https://platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;
&lt;p&gt;There are several reasons people might choose JRuby, several of which have to do with performance.&lt;/p&gt;
&lt;h3 id=&quot;getting-past-the-gil&quot;&gt;Getting past the GIL&lt;/h3&gt;
&lt;p&gt;MRI Ruby, much like Python, has a global interpreter lock. This means that although you can have many threads in a single Ruby process, only one will ever be running at a time. If you look at &lt;a href=&quot;https://benchmarksgame-team.pages.debian.net/benchmarksgame/performance/fannkuchredux.html&quot;&gt;many&lt;/a&gt; of the benchmark shoutout results, parallel multi-core solutions dominate. JRuby lets you sidestep the GIL as a bottleneck, at the cost of having to worry about writing thread-safe code.&lt;/p&gt;
&lt;h3 id=&quot;library-access-and-environment-access&quot;&gt;Library Access and Environment Access&lt;/h3&gt;
&lt;p&gt;A common driver for JRuby usage is the need for a Java-based library or the need to target the JVM. You could be trying to write an Android app or a Swing app using JRuby, or maybe you already have an existing Ruby codebase but need it to run on the JVM. My 2 cents is that if you start from scratch and need to target the JVM, JRuby should not be the first option you consider. If you do choose JRuby, be warned that you will need a good grasp of Java, the JVM, and Ruby: if you’re coming to the JVM for java libraries and functionality, then JRuby won’t save you from having to read Java.&lt;/p&gt;
&lt;h3 id=&quot;long-running-process-performance&quot;&gt;Long-Running Process Performance&lt;/h3&gt;
&lt;p&gt;MRI Ruby is known to be slow, as compared to the JVM or even Node.js. According to &lt;a href=&quot;https://benchmarksgame-team.pages.debian.net/benchmarksgame/performance/pidigits.html&quot;&gt;The Computer Language Benchmarks Game&lt;/a&gt;, it’s often 5-10x slower than a similar Java solution. Small performance benchmarks are often not the best way to assess practical performance, but one place the JVM is known to perform very well compared to interpreted languages is in long-running server applications, where &lt;a href=&quot;https://jakubstransky.com/2018/08/28/hotspot-jvm-jit-optimisation-techniques/&quot;&gt;adaptive optimzations&lt;/a&gt; can make a big difference.&lt;/p&gt;
&lt;h2 id=&quot;why-is-my-jruby-program-slow&quot;&gt;Why is my JRuby Program Slow?&lt;/h2&gt;
&lt;p&gt;The JVM might be fast at running Java in benchmark games, but that doesn’t necessarily carry over to JRuby. The JVM makes different performance trade-offs than MRI Ruby. Notably, an untuned JVM process has a slow start-up time, and with JRuby, this can get even worse as lots of standard library code is loaded on start-up. The JVM starts by working as a byte code interpreter and compiles “hot” code as it goes but in a large Ruby project, with lots of gems, the overhead of JITing all the Ruby code to bytecode can lead to a significantly slower start-up time.&lt;/p&gt;
&lt;p&gt;If you are using JRuby at the command line or starting lots of short-lived JRuby processes, then it is likely that JRuby will be slower than MRI Ruby. However, the JVM is extensively tunable, and it’s possible to tune things to behave more like standard Ruby. If you want your JRuby to behave more like MRI Ruby, you probably want to set the &lt;code&gt;--dev&lt;/code&gt; flag. Either like this:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt; ENV JRUBY_OPTS=&amp;quot;--dev&amp;quot;&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;OR&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;jruby --dev file.rb&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;In my Jekyll use case, this change and some other small JVM parameter tweaking made a big difference. I was able to get the build time down from 45m 16s to 24m 1s.&lt;/p&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;JRuby Flags&lt;/th&gt;
&lt;th&gt;Jekyll CI Run Time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;JRuby&lt;/td&gt;
&lt;td&gt;45m 16s&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;JRuby –dev&lt;/td&gt;
&lt;td&gt;24m 1s&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figcaption&gt;
&lt;code&gt;--dev&lt;/code&gt; gets us closer to MRI Ruby
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;h3 id=&quot;inside---dev&quot;&gt;Inside &lt;code&gt;--dev&lt;/code&gt;&lt;/h3&gt;
&lt;p&gt;The &lt;code&gt;--dev&lt;/code&gt; flag indicates to JRuby that you are running it in as a developer and would prefer quick startup time over absolute performance. JRuby, in turn, tells the JVM only do a single level jit (&lt;code&gt;-J-XX:TieredStopAtLevel=1&lt;/code&gt;) and to not worry about verifying the bytecode (&lt;code&gt;-J-Xverify:none&lt;/code&gt;). More details on the flag can found &lt;a href=&quot;http://blog.headius.com/2019/09/jruby-startup-time-exploration.html&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;why-is-my-jruby-program-wrong&quot;&gt;Why is my JRuby Program Wrong?&lt;/h2&gt;
&lt;p&gt;Ruby’s built-in types were built with the GIL in mind and are not thread-safe on the JVM. If you move the JRuby to sidestep the GIL, keep in mind that you may be introducing threading bugs. If you get unexpected or non-deterministic results in your concurrent array usage, you should look at concurrent data structures for the JVM like ConcurrentHashMap or ConcurrentSkipListMap. You may find that they not only fix the threading issues but could be &lt;a href=&quot;https://gist.github.com/bokmann/6652776&quot;&gt;orders of magnitude faster&lt;/a&gt; than the idiomatic Ruby way. Jekyll is not multi-threaded, however, so this is not an issue I needed to worry about.&lt;/p&gt;
&lt;h2 id=&quot;what-is-truffleruby&quot;&gt;What is TruffleRuby?&lt;/h2&gt;
&lt;p&gt;&lt;a href=&quot;https://www.graalvm.org/&quot;&gt;GraalVM&lt;/a&gt; is a JVM with different goals than the standard Java virtual machine.&lt;br /&gt;
According to Wikipedia, these goals are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To improve the performance of Java virtual machine-based languages to match the performance of native languages.&lt;/li&gt;
&lt;li&gt;To reduce the start-up time of JVM-based applications by compiling them ahead-of-time with GraalVM Native Image technology.&lt;/li&gt;
&lt;li&gt;To allow freeform mixing of code from any programming language in a single program.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Increased performance and better start-up time sound precisely like what we need to improve on JRuby, and this fact did not go unnoticed: &lt;a href=&quot;https://github.com/oracle/truffleruby&quot;&gt;TruffleRuby&lt;/a&gt; is a fork of JRuby that runs on GraalVM. Because GraalVM supports both ahead of time compilation and JIT, it’s possible to optimize either for peak performance of a long-running service or for start-up time, which is helpful for shorter running command-line apps like Jekyll.&lt;/p&gt;
&lt;p&gt;TruffleRuby explains the trade-offs of AOT vs. JIT like this:&lt;/p&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Configuration:&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;Native (&lt;code&gt;--native&lt;/code&gt;, default)&lt;/th&gt;
&lt;th style=&quot;text-align: right;&quot;&gt;JVM (&lt;code&gt;--jvm&lt;/code&gt;)&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Time to start TruffleRuby&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;about as fast as MRI start-up&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;slower&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Time to reach peak performance&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;faster&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;slower&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;Peak performance (also considering GC)&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;good&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;best&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;Java host interoperability&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;needs reflection configuration&lt;/td&gt;
&lt;td style=&quot;text-align: right;&quot;&gt;just works&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;h3 id=&quot;install-truffleruby&quot;&gt;Install TruffleRuby&lt;/h3&gt;
&lt;p&gt;Install rbenv:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;brew install rbenv&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;List possible install options:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rbenv install -l     &lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Install:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rbenv install truffleruby+graalvm-21.0.0  
rbenv local truffleruby+graalvm-21.0.0  &lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;ruby --version
truffleruby 21.0.0, like ruby 2.7.2, GraalVM CE Native [x86_64-darwin]&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Set mode to &lt;code&gt;--native&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;ENV TRUFFLERUBYOPT=&amp;#39;--native&amp;#39;&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;performance-shoot-out&quot;&gt;Performance Shoot-out&lt;/h2&gt;
TruffleRuby is significantly better in CPU heavy performance tests than JRuby, whose performance is significantly better than MRI Ruby. &lt;a href=&quot;https://pragtob.wordpress.com/2020/08/24/the-great-rubykon-benchmark-2020-cruby-vs-jruby-vs-truffleruby/&quot;&gt;PragToby&lt;/a&gt; has a great breakdown:
&lt;div class=&quot;wide&quot;&gt;
&lt;figure&gt;
&lt;img src=&quot;/blog/assets/images/jruby/2020_relative_speedup.png&quot; alt=&quot;Performance of JVM Ruby runtimes in small tests looks good but is it too good to be true?&quot; /&gt;&lt;figcaption aria-hidden=&quot;true&quot;&gt;Performance of JVM Ruby runtimes in small tests looks good but is it too good to be true?&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;However, in my testing with Jekyll and the Jekyll CI pipeline, JRuby and TruffleRuby are significantly slower than using MRI Ruby. How can this be?&lt;/p&gt;
&lt;p&gt;I think there are two reasons for this:&lt;/p&gt;
&lt;ol type=&quot;1&quot;&gt;
&lt;li&gt;Real-World projects like Jekyll involve a lot more code, and JITing that code has a high start-up cost.&lt;/li&gt;
&lt;li&gt;Real-world code like Jekyll or Rails is optimized for MRI Ruby, and many of those optimizations don’t help or actively hinder the JVM.&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;failure-of-fork&quot;&gt;Failure Of Fork&lt;/h3&gt;
&lt;p&gt;The most obvious place where you see this difference is multi-process Ruby programs. The GIL is not an issue across processes and the comparatively fast start time of MRI Ruby is an advantage when forking a new process. On the other hand, JVM Programs are often written in a multi-threading style where code only has to be JIT’d once, and the start-up cost is shared across threads. And in fact, if you ignore language shoot-out games, where everything is a single process and instead compare an MRI multi-process approach to a TruffleRuby multi-threading approach, many advantages of the JVM seem to disappear.&lt;/p&gt;
&lt;div class=&quot;wide&quot;&gt;
&lt;figure&gt;
&lt;img src=&quot;/blog/assets/images/jruby/mri_truffle.png&quot; alt=&quot;Multi-process MRI Ruby is close in performance to multi-threaded TruffleRuby&quot; /&gt;&lt;figcaption aria-hidden=&quot;true&quot;&gt;Multi-process MRI Ruby is close in performance to multi-threaded TruffleRuby&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;This chart comes from &lt;a href=&quot;https://github.com/eregon&quot;&gt;Benoit Daloze&lt;/a&gt;&lt;a href=&quot;#fn1&quot; class=&quot;footnote-ref&quot; id=&quot;fnref1&quot; role=&quot;doc-noteref&quot;&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/a&gt;, the TruffleRuby lead. The benchmark in question is a long-running server-side application using a minimal web framework. It is in the sweet spot of the Graal and TruffleRuby, with little code to JIT and much time to make up for a slow start. But even so, MRIRuby does well.&lt;/p&gt;
&lt;p&gt;Which brings me back to my original question: Why is JRuby slow for Jekyll? I do not see similar times but significantly slower times. Jekyll is not forking processes, so that is not the issue. Hugo, the static site builder for Go, is &lt;a href=&quot;https://forestry.io/blog/hugo-and-jekyll-compared/#performance-1&quot;&gt;signifcantly&lt;/a&gt; faster than Jekyll. So we know that Jekyll is not at the limits of hardware where there is simply no more performance to squeeze out.&lt;/p&gt;
&lt;h3 id=&quot;test-with-rubyspy&quot;&gt;Test with RubySpy&lt;/h3&gt;
&lt;p&gt;To dig into this, let’s take a look at a flame-graph of the Jekyll build for this blog using RubySpy:&lt;/p&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Runtime&lt;/th&gt;
&lt;th&gt;Jekyll Build Time for this site&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;MRI Ruby 2.7.0&lt;/td&gt;
&lt;td&gt;2.64 seconds&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;TruffleRuby-dev&lt;/td&gt;
&lt;td&gt;25.7 seconds&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figcaption&gt;
This blog is 10x slower to build on TruffleRuby
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;h4 id=&quot;jekyll-test-1&quot;&gt;Jekyll Test 1&lt;/h4&gt;
&lt;pre&gt;&lt;code&gt;sudo RUBYOPT=&amp;#39;-W0&amp;#39; rbspy record -- bundle exec jekyll build --profile&lt;/code&gt;&lt;/pre&gt;
&lt;div class=&quot;wide&quot;&gt;
&lt;figure&gt;
&lt;img src=&quot;/blog/assets/images/jruby/flame-graph.png&quot; alt=&quot;A Flame Graph shows most time is File Access&quot; /&gt;&lt;figcaption aria-hidden=&quot;true&quot;&gt;A Flame Graph shows most time is File Access&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;What we see is that 50% of the wall time was spent in writing files:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb13&quot;&gt;&lt;pre class=&quot;sourceCode ruby&quot;&gt;&lt;code class=&quot;sourceCode ruby&quot;&gt;&lt;span id=&quot;cb13-1&quot;&gt;&lt;a href=&quot;#cb13-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;# Write static files, pages, and posts.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-2&quot;&gt;&lt;a href=&quot;#cb13-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;#&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-3&quot;&gt;&lt;a href=&quot;#cb13-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;# Returns nothing.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-4&quot;&gt;&lt;a href=&quot;#cb13-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;def&lt;/span&gt; write&lt;/span&gt;
&lt;span id=&quot;cb13-5&quot;&gt;&lt;a href=&quot;#cb13-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      each_site_file &lt;span class=&quot;cf&quot;&gt;do&lt;/span&gt; &lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt;item&lt;span class=&quot;kw&quot;&gt;|&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-6&quot;&gt;&lt;a href=&quot;#cb13-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;        item&lt;span class=&quot;at&quot;&gt;.write&lt;/span&gt;(dest) &lt;span class=&quot;cf&quot;&gt;if&lt;/span&gt; regenerator&lt;span class=&quot;at&quot;&gt;.regenerate?&lt;/span&gt;(item)&lt;/span&gt;
&lt;span id=&quot;cb13-7&quot;&gt;&lt;a href=&quot;#cb13-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;cf&quot;&gt;end&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-8&quot;&gt;&lt;a href=&quot;#cb13-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      regenerator&lt;span class=&quot;at&quot;&gt;.write_metadata&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-9&quot;&gt;&lt;a href=&quot;#cb13-9&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;dt&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;Hooks&lt;/span&gt;&lt;span class=&quot;at&quot;&gt;.trigger&lt;/span&gt; &lt;span class=&quot;wa&quot;&gt;:site&lt;/span&gt;, &lt;span class=&quot;wa&quot;&gt;:post_write&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;self&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb13-10&quot;&gt;&lt;a href=&quot;#cb13-10&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;end&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;And 16% of time was spent reading files.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb14&quot;&gt;&lt;pre class=&quot;sourceCode ruby&quot;&gt;&lt;code class=&quot;sourceCode ruby&quot;&gt;&lt;span id=&quot;cb14-1&quot;&gt;&lt;a href=&quot;#cb14-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;# Read Site data from disk and load it into internal data structures.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-2&quot;&gt;&lt;a href=&quot;#cb14-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;#&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-3&quot;&gt;&lt;a href=&quot;#cb14-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;# Returns nothing.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-4&quot;&gt;&lt;a href=&quot;#cb14-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;def&lt;/span&gt; read&lt;/span&gt;
&lt;span id=&quot;cb14-5&quot;&gt;&lt;a href=&quot;#cb14-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      reader&lt;span class=&quot;at&quot;&gt;.read&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-6&quot;&gt;&lt;a href=&quot;#cb14-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      limit_posts!&lt;/span&gt;
&lt;span id=&quot;cb14-7&quot;&gt;&lt;a href=&quot;#cb14-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;dt&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;Hooks&lt;/span&gt;&lt;span class=&quot;at&quot;&gt;.trigger&lt;/span&gt; &lt;span class=&quot;wa&quot;&gt;:site&lt;/span&gt;, &lt;span class=&quot;wa&quot;&gt;:post_read&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;self&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb14-8&quot;&gt;&lt;a href=&quot;#cb14-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;end&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;Overall only 22% of the time was spent doing the actual work of generating HTML:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb15&quot;&gt;&lt;pre class=&quot;sourceCode ruby&quot;&gt;&lt;code class=&quot;sourceCode ruby&quot;&gt;&lt;span id=&quot;cb15-1&quot;&gt;&lt;a href=&quot;#cb15-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;# Render the site to the destination.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-2&quot;&gt;&lt;a href=&quot;#cb15-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;#&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-3&quot;&gt;&lt;a href=&quot;#cb15-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;co&quot;&gt;# Returns nothing.&lt;/span&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-4&quot;&gt;&lt;a href=&quot;#cb15-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;def&lt;/span&gt; render&lt;/span&gt;
&lt;span id=&quot;cb15-5&quot;&gt;&lt;a href=&quot;#cb15-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      relative_permalinks_are_deprecated&lt;/span&gt;
&lt;span id=&quot;cb15-6&quot;&gt;&lt;a href=&quot;#cb15-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-7&quot;&gt;&lt;a href=&quot;#cb15-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      payload &lt;span class=&quot;kw&quot;&gt;=&lt;/span&gt; site_payload&lt;/span&gt;
&lt;span id=&quot;cb15-8&quot;&gt;&lt;a href=&quot;#cb15-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-9&quot;&gt;&lt;a href=&quot;#cb15-9&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;dt&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;Hooks&lt;/span&gt;&lt;span class=&quot;at&quot;&gt;.trigger&lt;/span&gt; &lt;span class=&quot;wa&quot;&gt;:site&lt;/span&gt;, &lt;span class=&quot;wa&quot;&gt;:pre_render&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;self&lt;/span&gt;, payload&lt;/span&gt;
&lt;span id=&quot;cb15-10&quot;&gt;&lt;a href=&quot;#cb15-10&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-11&quot;&gt;&lt;a href=&quot;#cb15-11&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      render_docs(payload)&lt;/span&gt;
&lt;span id=&quot;cb15-12&quot;&gt;&lt;a href=&quot;#cb15-12&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      render_pages(payload)&lt;/span&gt;
&lt;span id=&quot;cb15-13&quot;&gt;&lt;a href=&quot;#cb15-13&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb15-14&quot;&gt;&lt;a href=&quot;#cb15-14&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;      &lt;span class=&quot;dt&quot;&gt;Jekyll&lt;/span&gt;&lt;span class=&quot;kw&quot;&gt;::&lt;/span&gt;&lt;span class=&quot;dt&quot;&gt;Hooks&lt;/span&gt;&lt;span class=&quot;at&quot;&gt;.trigger&lt;/span&gt; &lt;span class=&quot;wa&quot;&gt;:site&lt;/span&gt;, &lt;span class=&quot;wa&quot;&gt;:post_render&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;self&lt;/span&gt;, payload&lt;/span&gt;
&lt;span id=&quot;cb15-15&quot;&gt;&lt;a href=&quot;#cb15-15&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;    &lt;span class=&quot;cf&quot;&gt;end&lt;/span&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;In other words, all the time is spent reading to and from the disk. Clearly, the hugo case shows us this could be faster: we aren’t hitting a hardware limit. Yet why does this run even slower in JRuby and TruffleRuby than it does in MRI Ruby? Let’s try another test.&lt;/p&gt;
&lt;h4 id=&quot;jekyll-test-2&quot;&gt;Jekyll Test 2&lt;/h4&gt;
&lt;p&gt;Testing on the build process for another Jekyll site gives similar results timings: TruffleRuby is significantly slower.&lt;/p&gt;
&lt;div class=&quot;center&quot;&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Runtime&lt;/th&gt;
&lt;th&gt;Jekyll CI Run Time&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;MRI Ruby 2.7.0&lt;/td&gt;
&lt;td&gt;20 seconds&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;TruffleRuby-dev&lt;/td&gt;
&lt;td&gt;116 seconds&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figcaption&gt;
A larger Jekyll Site
&lt;/figcaption&gt;
&lt;/div&gt;
&lt;div class=&quot;wide&quot;&gt;
&lt;figure&gt;
&lt;img src=&quot;/blog/assets/images/jruby/flame-graph2.png&quot; alt=&quot;This time most of the time is Liquid Template Rendering&quot; /&gt;&lt;figcaption aria-hidden=&quot;true&quot;&gt;This time most of the time is Liquid Template Rendering&lt;/figcaption&gt;
&lt;/figure&gt;
&lt;/div&gt;
&lt;p&gt;This time the flamegraph shows most time is spent with rendering liquid templates rather than IO. I wasn’t able to figure out a way to get a flamegraph out of TruffleRuby.&lt;/p&gt;
&lt;p&gt;So what does this mean? My guess is that the filesystem Ruby code or the liquid templates do not benefit from being on the JVM. On the contrary, they seem to run slower.&lt;/p&gt;
&lt;p&gt;It might be possible to reimplement &lt;code&gt;write&lt;/code&gt; and &lt;code&gt;read&lt;/code&gt; to follow JVM high-performance file access best practices, and it might be possible to reimplement liquid templates in a Java native way. That should bring a speed-up, but I’m not sure if that would make JRuby faster than MRI Ruby for Jekyll or only bring it up to a similar performance.&lt;/p&gt;
&lt;h2 id=&quot;performance-advice&quot;&gt;Performance Advice&lt;/h2&gt;
&lt;p&gt;All this leaves me with the most generic performance advice: You should test your Ruby codebase with different runtimes and see what works best for you.&lt;/p&gt;
&lt;p&gt;If your code is long-running, CPU bound, and thread-based, and if the GIL limits you, TruffleRuby will probably be a win. Also, if that is the case and you tweak your code to use Java concurrent data structures instead of Ruby defaults, you can probably achieve an order of magnitude speed-up. If the garbage collector is a bottleneck for your app, that could also be another reason for trying out a different runtime.&lt;/p&gt;
&lt;p&gt;However, if your existing ruby codebase is not CPU bound and not multi-threaded, it will probably run slower on JRuby and Truffle Ruby than with the MRIRuby runtime.&lt;/p&gt;
&lt;p&gt;Also, I could be wrong. If I missed something important, then I’d love to hear from you. Here at &lt;a href=&quot;http://earthly.dev/&quot;&gt;Earthly&lt;/a&gt; we take build performance very seriously, so if you have additional suggestions for speeding up Ruby or Jekyll, I’d love to hear them.&lt;a href=&quot;#fn2&quot; class=&quot;footnote-ref&quot; id=&quot;fnref2&quot; role=&quot;doc-noteref&quot;&gt;&lt;sup&gt;2&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;updates&quot;&gt;Updates&lt;/h2&gt;
&lt;section id=&quot;update-1&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Update #1&lt;/h3&gt;
&lt;/section&gt;
&lt;p&gt;Both &lt;span class=&quot;citation&quot; data-cites=&quot;ChrisGSeaton&quot;&gt;@ChrisGSeaton&lt;/span&gt;, the creator of TruffleRuby and &lt;span class=&quot;citation&quot; data-cites=&quot;headius&quot;&gt;@headius&lt;/span&gt;, who works on JRuby have responded on &lt;a href=&quot;https://www.reddit.com/r/programming/comments/nlhmcz/why_is_jruby_slow/&quot;&gt;reddit&lt;/a&gt; with suggestions and requests for reproduction steps. I’m going to put together an example repo to share.&lt;/p&gt;
&lt;section id=&quot;update-2&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Update #2&lt;/h3&gt;
&lt;/section&gt;
&lt;p&gt;The area where JRuby and TruffleRuby shine are long running processes that have had time to warm up. Based on suggestions I put together a repo of a simple small Jekyll build being built 20 times by the same process in a repo &lt;a href=&quot;https://github.com/agbell/jekyll-perf&quot;&gt;here&lt;/a&gt;. After 20 builds with the same running process the build times do start to converge, but even after that MRI Ruby is still fastest.&lt;/p&gt;
&lt;section id=&quot;update-3&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h3&gt;Update #3&lt;/h3&gt;
&lt;/section&gt;
&lt;p&gt;I have filed a bug with Truffle Ruby and received some performance advice that I think is worth sharing here:&lt;/p&gt;
&lt;section id=&quot;some-feedback-on-the-assumptions-of-the-article&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h4&gt;Some Feedback on The Assumptions of The Article&lt;/h4&gt;
&lt;/section&gt;
&lt;blockquote&gt;
&lt;p&gt;Hello there, here are some notes on the blog post.&lt;/p&gt;
&lt;p&gt;“TruffleRuby is a fork of JRuby”&lt;/p&gt;
&lt;p&gt;Technically true from a repository point of view, and that’s what the README says (I’ll update that), but in practice it’s like &amp;gt;90% of code is not from JRuby. It’s quite different technologies.&lt;/p&gt;
&lt;p&gt;“Hugo, the static site builder for Go, is significantly faster than Jekyll. So we know that Jekyll is not at the limits of hardware where there is simply no more performance to squeeze out.”&lt;/p&gt;
&lt;p&gt;I’d bet that’s in part due to a different design. Most likely Hugo is better optimized and might do much less work due to different constraints.&lt;/p&gt;
&lt;p&gt;“However, if your existing ruby codebase is not CPU bound and not multi-threaded, it will probably run slower on JRuby and TruffleRuby than with the MRI Ruby runtime.”&lt;/p&gt;
&lt;p&gt;I think there is no such simple rule and also there is the question of “not CPU bound” is how much time spent in the kernel. TruffleRuby can be faster on many Ruby workloads, as long as there is Ruby code to run, there is potential for optimization. Of course if 90% is spent in read/write system calls, only 10% of it can be optimized by a Ruby implementation, but I would expect that’s pretty rare.&lt;/p&gt;
&lt;p&gt;The main thing I think is if it’s not almost entirely IO-bound, then there is potential to speed up. And the only way to know for sure is to try it, as you say.&lt;/p&gt;
&lt;p&gt;“I’d especially love to hear how to get a flame graph out of TruffleRuby”&lt;/p&gt;
&lt;p&gt;Thank you for the issue at &lt;a href=&quot;https://github.com/oracle/truffleruby/issues/2363&quot;&gt;https://github.com/oracle/truffleruby/issues/2363&lt;/a&gt;. Currently TruffleRuby has multiple Ruby-level profilers (–cpusampler, VisualVM, Chrome Inspector). We’re working on having an easy way to get a flamegraph (right now we use this but one needs to clone the truffleruby repo which is less convenient). Java-level profiling is also possible via VisualVM. async-profiler needs something like JDK&amp;gt;=15 to work properly with Graal compilations IIRC.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/programming/comments/nlhmcz/why_is_jruby_slow/gzqxexa/?context=3&quot;&gt;eregontp on reddit&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;section id=&quot;some-advice-for-making-ruby-single-process&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h4&gt;Some Advice for Making Ruby Single Process&lt;/h4&gt;
&lt;/section&gt;
&lt;blockquote&gt;
&lt;p&gt;Your simplest answer for both JRuby and TruffleRuby would be to set it up to use a single process to do everything. In JRuby, it is trivial to start up a separate, isolated JRuby instance within the same process:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;my_jruby = org.jruby.Ruby.new_instance
my_jruby.eval_script(ruby_code)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;The code given will run in the same process but a completely different JRuby environment. This can be adapted to run your “subprocesses” without starting a fresh JVM every time.&lt;/p&gt;
&lt;p&gt;TruffleRuby likely has something similar based on GraalVM polyglot APIs.&lt;/p&gt;
&lt;p&gt;If you managed to get your CI run to use a single process, I would be surprised if it was not as fast or faster than standard C-based Ruby.&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/programming/comments/nlhmcz/why_is_jruby_slow/gzjh5kt/?utm_source=reddit&amp;amp;utm_medium=web2x&amp;amp;context=3&quot;&gt;headius on reddit&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Note: The article does cover &lt;code&gt;--dev&lt;/code&gt; and I did put together a single process &lt;a href=&quot;https://github.com/agbell/jekyll-perf&quot;&gt;example&lt;/a&gt; in update 2. The results are way better, but still slower.&lt;/p&gt;
&lt;section id=&quot;using-application-class-data-sharing&quot; class=&quot;no_toc_section&quot;&gt;
&lt;h4&gt;Using Application Class Data Sharing&lt;/h4&gt;
&lt;/section&gt;
&lt;blockquote&gt;
&lt;p&gt;AppCDS is a way to significantly improve startup speed without impacting total runtime performance. It’d be interesting to see if employing that helps with performance. &lt;a href=&quot;https://medium.com/@toparvion/appcds-for-spring-boot-applications-first-contact-6216db6a4194&quot; class=&quot;uri&quot;&gt;https://medium.com/@toparvion/appcds-for-spring-boot-applications-first-contact-6216db6a4194&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Finally, if you can, I’d be interested to see what happens if you work from a ramdisk rather than the HD. I imagine the IO problems you were likely seeing is due to a lot of back and forth communication between the app and the disk, what happens if you kill that off?&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://www.reddit.com/r/programming/comments/nlhmcz/why_is_jruby_slow/gzj1d3j/?utm_source=reddit&amp;amp;utm_medium=web2x&amp;amp;context=3&quot;&gt;cogman on reddit&lt;/a&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;The feedback from the JRuby and TruffleRuby people has been amazing. They have been offering suggestions and asking for tickets and reproduction steps. These are ambitious projects that keep improving and I’m excited to hear that making Jekyll run faster than it does on CRuby is very possible with some additional elbow grease.&lt;/p&gt;
&lt;h2 id=&quot;more-resources&quot;&gt;More Resources&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;https://pragtob.wordpress.com/2020/08/24/the-great-rubykon-benchmark-2020-cruby-vs-jruby-vs-truffleruby/&quot;&gt;CRUBY VS JRUBY VS TRUFFLERUBY&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://github.com/oracle/truffleruby/blob/master/README.md&quot;&gt;Truffle Ruby&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=281YdMYRAsk&quot;&gt;Running Rack and Rails Faster with TruffleRuby&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;section class=&quot;footnotes&quot; role=&quot;doc-endnotes&quot;&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id=&quot;fn1&quot; role=&quot;doc-endnote&quot;&gt;&lt;p&gt;The work behind JRuby, TruffleRuby, and especially GraalVM is terrific. The TruffleRuby benchmark numbers for CPU heavy work continue to improve year upon year. I’m not trying to dunk on the great work done, merely trying to investigate the numbers I am seeing.&lt;a href=&quot;#fnref1&quot; class=&quot;footnote-back&quot; role=&quot;doc-backlink&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li id=&quot;fn2&quot; role=&quot;doc-endnote&quot;&gt;&lt;p&gt;I’d especially love to hear how to get a flame graph out of TruffleRuby. I didn’t get anywhere getting &lt;a href=&quot;https://github.com/jvm-profiling-tools/async-profiler&quot;&gt;async-profiler&lt;/a&gt; to attach.&lt;a href=&quot;#fnref2&quot; class=&quot;footnote-back&quot; role=&quot;doc-backlink&quot;&gt;↩︎&lt;/a&gt;&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;
&lt;/section&gt;</content><author><name>Adam Gordon Bell</name></author><category term="Tutorial" /><summary type="html">Recently, I made some contributions to the continuous integration process for Jekyll. Jekyll is a static site generator created by GitHub and written in Ruby, and it uses Earthly and GitHub Actions to test that it works with Ruby 2.5, 2.7, 3.0, and JRuby.</summary></entry><entry><title type="html">Protocol Buffers Best Practices for Backward and Forward Compatibility</title><link href="https://earthly.dev/blog/backward-and-forward-compatibility/" rel="alternate" type="text/html" title="Protocol Buffers Best Practices for Backward and Forward Compatibility" /><published>2021-05-21T00:00:00-04:00</published><updated>2021-05-21T00:00:00-04:00</updated><id>https://earthly.dev/blog/backward-and-forward-compatibility</id><content type="html" xml:base="https://earthly.dev/blog/backward-and-forward-compatibility/">&lt;p&gt;&lt;a href=&quot;https://developers.google.com/protocol-buffers&quot; title=&quot;Protocol Buffers Documentation&quot;&gt;Protocol Buffers&lt;/a&gt; serialize structured data so it can be efficiently stored or shared over a network. They were designed for internal use at Google in 2001 and released to the public under an open-source license in 2008.&lt;/p&gt;
&lt;p&gt;Protocol Buffers are compiled to a series of strictly arranged bytes, so they can be transmitted very efficiently. After reconstitution, they can also be understood by a wide range of languages. Let’s examine protobufs first at a high level, then do a deep dive into best practices for working with them to see if they’re a fit for your expanding data workflow.&lt;/p&gt;
&lt;h2 id=&quot;what-exactly-are-protocol-buffers&quot;&gt;What Exactly Are Protocol Buffers?&lt;/h2&gt;
&lt;p&gt;Protocol Buffers are designed with the concept of extensibility at their core. You can add fields without a care, though you do have to be attentive when modifying or removing fields. This article will go through how you can manage your messages to maintain forward and backward compatibility.&lt;/p&gt;
&lt;p&gt;Protocol Buffers are most useful when regularly sharing small pieces of data (generally under 1 MB) between two computers on a regular basis. It’s designed for extracting and sharing that data, but it’s also very effective at storing data that will have to be shared between systems using different languages or controlled by different organizations.&lt;/p&gt;
&lt;p&gt;Protocol Buffers are also great at persisting blobs of data, particularly in languages like C++ where you can use protobuf as a data struct. If you’re communicating with lots of computers a little at a time, Protocol Buffers will save you network bandwidth.&lt;/p&gt;
&lt;h3 id=&quot;understanding-backward-and-forward-compatibility&quot;&gt;Understanding Backward and Forward Compatibility&lt;/h3&gt;
&lt;p&gt;Both backward and forward compatibility is important for any project you expect will run for a long time. There are at least two parts to any protobuf system, the sender and the receiver. If either one can be upgraded to a new message format, and the system functionality continues uninterrupted then the message protocol is both forward and backward compatible.&lt;/p&gt;
&lt;section id=&quot;backward-compatibility&quot; class=&quot;notice notice--big&quot;&gt;
&lt;h4&gt;Backward Compatibility&lt;/h4&gt;
&lt;p&gt;If a client that was updated to a new message type but is still able to understand the previous message type then the message change is backward compatible. Backward compatibility is being able to understand messages from a previous version.&lt;/p&gt;
&lt;/section&gt;
&lt;section id=&quot;forward-compatibility&quot; class=&quot;notice notice--big&quot;&gt;
&lt;h4&gt;Forward Compatibility&lt;/h4&gt;
&lt;p&gt;If a message is changed and a non-updated client can still understand and process the message then the message change is forward compatible. Forward compatibility is being able to understand messages from a future version.&lt;/p&gt;
&lt;/section&gt;
&lt;p&gt;With Protocol buffers, if a sender is upgraded, the receiver can still understand messages if it is forward compatible. It can accept input crafted by later versions of protobuf. The sender is backward compatible because it’s creating output that can be consumed by earlier versions. So long as you’re careful about when and how you change and remove fields, your protobuf will be forward and backward compatible.&lt;/p&gt;
&lt;h3 id=&quot;getting-started-with-buffers&quot;&gt;Getting Started with Buffers&lt;/h3&gt;
&lt;p&gt;The first step to making a Protocol Buffer is to define data structures in a &lt;code&gt;.proto&lt;/code&gt; file. For each data structure you want to create, you’ll make a &lt;code&gt;message&lt;/code&gt; that contains a name and data type for each field it contains.&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb1&quot;&gt;&lt;pre class=&quot;sourceCode protobuf&quot;&gt;&lt;code class=&quot;sourceCode protobuf&quot;&gt;&lt;span id=&quot;cb1-1&quot;&gt;&lt;a href=&quot;#cb1-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;syntax = &lt;span class=&quot;st&quot;&gt;&amp;quot;proto3&amp;quot;&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb1-2&quot;&gt;&lt;a href=&quot;#cb1-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;package&lt;/span&gt; tutorial;&lt;/span&gt;
&lt;span id=&quot;cb1-3&quot;&gt;&lt;a href=&quot;#cb1-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;/span&gt;
&lt;span id=&quot;cb1-4&quot;&gt;&lt;a href=&quot;#cb1-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;message&lt;/span&gt; Sample{&lt;/span&gt;
&lt;span id=&quot;cb1-5&quot;&gt;&lt;a href=&quot;#cb1-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;dt&quot;&gt;string&lt;/span&gt; content = &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb1-6&quot;&gt;&lt;a href=&quot;#cb1-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;dt&quot;&gt;int32&lt;/span&gt; id = &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb1-7&quot;&gt;&lt;a href=&quot;#cb1-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;dt&quot;&gt;string&lt;/span&gt; situation = &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb1-8&quot;&gt;&lt;a href=&quot;#cb1-8&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;These declarations in the &lt;code&gt;.proto&lt;/code&gt; file are shared with both the message sender and receiver to construct immutable getters and setters that allow data to be read into and accessed from binary using a &lt;a href=&quot;/blog/compiling-containers-dockerfiles-llvm-and-buildkit&quot;&gt;compiler&lt;/a&gt;, then accessed in a variety of programming languages.&lt;/p&gt;
&lt;h2 id=&quot;tips-for-maintaining-compatibility&quot;&gt;Tips for Maintaining Compatibility&lt;/h2&gt;
&lt;p&gt;Compatibility starts with defining the syntax and version of protobuf the sender and receiver are using. The &lt;code&gt;package&lt;/code&gt; makes sure your code is namespaced to avoid any collisions. It is possible to have a sender using &lt;code&gt;proto3&lt;/code&gt; while a receiver uses &lt;code&gt;proto2&lt;/code&gt; (or any other combination) as long as you’re careful about what fields you include. Both the sender and receiver have strict definitions of existing fields—you can make changes as long as you don’t disturb those definitions.&lt;/p&gt;
&lt;h3 id=&quot;create-numerical-order&quot;&gt;Create (Numerical) Order&lt;/h3&gt;
&lt;p&gt;From a compatibility perspective, unique field numbers are the most vital piece of the message declaration. These numbers (the &lt;code&gt;= 1&lt;/code&gt; after the name declaration) are used as identifiers for fields after they are converted to binary. When the message is decoded, a crucial step for compatibility is allowing the parser to skip fields it doesn’t recognize so it’s possible to add new fields without breaking programs that weren’t designed to look for them.&lt;/p&gt;
&lt;p&gt;The unique field number is combined with a wire type corresponding to the data type of the field. This identifier and type combination form the key of every field in a message. These fields combined give the receiver the ability to uniquely identify fields and determine the length of the field, so it knows when to start looking for the next field.&lt;/p&gt;
&lt;p&gt;This means once a unique field number or length is set, it cannot be changed. Any program consuming or serizalizing protobuf data needs the number to be fixed forever, or both the sender and all the receivers must be updated.&lt;/p&gt;
&lt;p&gt;Encoding the numbers 1 through 15 takes one byte to encode, 16 through 2047 take two bytes, and so on. In situations where the size of messages is important, the most frequently exchanged data should have the smallest field numbers. The language is designed to effectively handle new fields, but because you can’t change the identifier of fields, it may be wise to leave yourself a couple gaps in these high-efficiency identifier ranges in case a very common field pops up in the future.&lt;/p&gt;
&lt;p&gt;One of the best ways to prevent problems with overlapping or misunderstood field numbers is to use the &lt;code&gt;reserved&lt;/code&gt; keyword. If you wanted to remove the &lt;code&gt;type&lt;/code&gt; field in your &lt;code&gt;Sample&lt;/code&gt; message, any applications running the protobuf version that contained that field would break if the identifier was removed and then reused for some other field.&lt;/p&gt;
&lt;p&gt;To get around these compatibility issues, you can reserve identifiers. You can also reserve ranges of identifiers; here you’re reserving a range and the removed value of &lt;code&gt;1&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb2&quot;&gt;&lt;pre class=&quot;sourceCode protobuf&quot;&gt;&lt;code class=&quot;sourceCode protobuf&quot;&gt;&lt;span id=&quot;cb2-1&quot;&gt;&lt;a href=&quot;#cb2-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;message&lt;/span&gt; Sample{&lt;/span&gt;
&lt;span id=&quot;cb2-2&quot;&gt;&lt;a href=&quot;#cb2-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  reserved &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;dv&quot;&gt;5&lt;/span&gt; to &lt;span class=&quot;dv&quot;&gt;8&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb2-3&quot;&gt;&lt;a href=&quot;#cb2-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;dt&quot;&gt;int32&lt;/span&gt; id = &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb2-4&quot;&gt;&lt;a href=&quot;#cb2-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;dt&quot;&gt;string&lt;/span&gt; text = &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb2-5&quot;&gt;&lt;a href=&quot;#cb2-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;h3 id=&quot;beware-of-required-fields&quot;&gt;Beware of Required Fields&lt;/h3&gt;
&lt;p&gt;Another tricky part of compatibility is the required modifier preceding the data type. In the second version of protobuf, there were three modifiers to choose from: &lt;code&gt;optional&lt;/code&gt;, &lt;code&gt;repeated&lt;/code&gt;, and &lt;code&gt;required&lt;/code&gt;. The &lt;code&gt;required&lt;/code&gt; option was removed in &lt;code&gt;protobuf3&lt;/code&gt;, because it requires careful planning to ensure compatibility. If a required field is missing from a message, readers will consider the message incomplete and return an error.&lt;/p&gt;
&lt;p&gt;Instead, consider writing custom validation or use default values within your application to handle required fields. In &lt;code&gt;protobuf2&lt;/code&gt;, you were able to set &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto#optional&quot; title=&quot;Default fields in protobuf2&quot;&gt;default values&lt;/a&gt;, in &lt;code&gt;protobuf3&lt;/code&gt;, every field type has a &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#default&quot; title=&quot;Default fields in protobuf3&quot;&gt;fixed default value&lt;/a&gt;.&lt;/p&gt;
&lt;h3 id=&quot;avoid-groups&quot;&gt;Avoid Groups&lt;/h3&gt;
&lt;p&gt;Another feature of &lt;code&gt;protobuf2&lt;/code&gt; that should be avoided to ensure compatibility is Groups. These enable nesting information inside method definitions. A Group combines a nested message type and a field into a single declaration using the &lt;code&gt;group&lt;/code&gt; keyword.&lt;/p&gt;
&lt;p&gt;The recommended way to nest messages is to nest them, then call them:&lt;/p&gt;
&lt;div class=&quot;sourceCode&quot; id=&quot;cb3&quot;&gt;&lt;pre class=&quot;sourceCode protobuf&quot;&gt;&lt;code class=&quot;sourceCode protobuf&quot;&gt;&lt;span id=&quot;cb3-1&quot;&gt;&lt;a href=&quot;#cb3-1&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;message&lt;/span&gt; SampleContainer {&lt;/span&gt;
&lt;span id=&quot;cb3-2&quot;&gt;&lt;a href=&quot;#cb3-2&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;&lt;span class=&quot;kw&quot;&gt;message&lt;/span&gt; Sample{&lt;/span&gt;
&lt;span id=&quot;cb3-3&quot;&gt;&lt;a href=&quot;#cb3-3&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;kw&quot;&gt;optional&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;int32&lt;/span&gt; id = &lt;span class=&quot;dv&quot;&gt;2&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb3-4&quot;&gt;&lt;a href=&quot;#cb3-4&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;  &lt;span class=&quot;kw&quot;&gt;optional&lt;/span&gt; &lt;span class=&quot;dt&quot;&gt;string&lt;/span&gt; text = &lt;span class=&quot;dv&quot;&gt;3&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb3-5&quot;&gt;&lt;a href=&quot;#cb3-5&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;}&lt;/span&gt;
&lt;span id=&quot;cb3-6&quot;&gt;&lt;a href=&quot;#cb3-6&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;   &lt;span class=&quot;kw&quot;&gt;repeated&lt;/span&gt; Sample samples = &lt;span class=&quot;dv&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;
&lt;span id=&quot;cb3-7&quot;&gt;&lt;a href=&quot;#cb3-7&quot; aria-hidden=&quot;true&quot; tabindex=&quot;-1&quot;&gt;&lt;/a&gt;}&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;
&lt;p&gt;The difference between nested message types and Groups is the wire format they use.&lt;/p&gt;
&lt;h3 id=&quot;adding-new-fields&quot;&gt;Adding New Fields&lt;/h3&gt;
&lt;p&gt;New fields can be safely added in any version of protobuf, but there are still compatibility considerations to be aware of. Pay attention to the depreciation of the &lt;code&gt;required&lt;/code&gt; fields and transition from user-specified defaults to protobuf-specified defaults. The application receiving protobuf data has to be responsible for handling the &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#default&quot;&gt;default values&lt;/a&gt; for any new fields.&lt;/p&gt;
&lt;p&gt;You generally can freely change the name and order of fields. However, when you’re producing JSON serialized data with protobuf, the field names are also reserved by the receiver. This requires users to reserve &lt;strong&gt;field identifiers and names&lt;/strong&gt; when removing or deprecating fields.&lt;/p&gt;
&lt;h3 id=&quot;keep-an-eye-on-compatibility-when-changing-field-types&quot;&gt;Keep an Eye on Compatibility When Changing Field Types&lt;/h3&gt;
&lt;p&gt;Because field types are also used to determine when the receiver ends a field, changing field types across versions without carefully checking for compatibility can also cause problems. There are many specific &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#updating&quot; title=&quot;Rule for updating fields&quot;&gt;rules&lt;/a&gt; about how to change field types, but a good standard is to avoid ever changing the wire type of any field. If you’re in a situation where you need to change a field type, the best path forward is to deprecate the existing field and put the new information into a new field.&lt;/p&gt;
&lt;h3 id=&quot;dont-destroy-deprecate&quot;&gt;Don’t Destroy, Deprecate&lt;/h3&gt;
&lt;p&gt;Protocol Buffer compatibility problems generally start when you need to change the length of or remove existing fields. There are a whole host of rules about how fields can &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#updating&quot; title=&quot;Protobuf3 update fields&quot;&gt;change&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Largely, maintaining backward and forward compatibility comes down to maintaining a consistent wire type. You can’t change the wire type or alter the length of fields and expect old code to properly send or receive messages—the sender’s and receiver’s understanding of the exact length of each element in the transmitted messages needs to be precise.&lt;/p&gt;
&lt;table&gt;
&lt;colgroup&gt;
&lt;col style=&quot;width: 33%&quot; /&gt;
&lt;col style=&quot;width: 33%&quot; /&gt;
&lt;col style=&quot;width: 33%&quot; /&gt;
&lt;/colgroup&gt;
&lt;thead&gt;
&lt;tr class=&quot;header&quot;&gt;
&lt;th&gt;Type&lt;/th&gt;
&lt;th&gt;Meaning&lt;/th&gt;
&lt;th&gt;Used For&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;0&lt;/td&gt;
&lt;td&gt;Varint&lt;/td&gt;
&lt;td&gt;int32, int64, uint32, uint64, sint32, sint64, bool, enum&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;1&lt;/td&gt;
&lt;td&gt;64-bit&lt;/td&gt;
&lt;td&gt;fixed64, sfixed64, double&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;2&lt;/td&gt;
&lt;td&gt;Length-delimited&lt;/td&gt;
&lt;td&gt;string, bytes, embedded messages, packed repeated fields&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;3&lt;/td&gt;
&lt;td&gt;Start group&lt;/td&gt;
&lt;td&gt;groups (deprecated)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;odd&quot;&gt;
&lt;td&gt;4&lt;/td&gt;
&lt;td&gt;End group&lt;/td&gt;
&lt;td&gt;groups (deprecated)&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&quot;even&quot;&gt;
&lt;td&gt;5&lt;/td&gt;
&lt;td&gt;32-bit&lt;/td&gt;
&lt;td&gt;fixed32, sfixed32, float&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;figcaption&gt;
Protobuf Wire Types
&lt;/figcaption&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;The biggest problems when upgrading are mismatching required fields or a need to change field types. In the short term, adding other fields is a viable solution, but at a certain point, the marginal cost of that solution becomes more of a burden than auditing and upgrading your services.&lt;/p&gt;
&lt;p&gt;Protocol Buffers are a relatively young technology, so changes now will have long-lasting implications. Compatibility issues do exist between versions, but they’re possible to step around if you’re careful. As always, make life simpler by planning out your data structures in advance. Once things eventually do change, the safest method for modifying fields is to add a new one and deprecate the old field.&lt;/p&gt;
&lt;p&gt;To deprecate a field, you can change the name to something deprecated or remove it and reserve the identifier. If you really want to change a field type, and you’re able to follow the correct version of &lt;a href=&quot;https://developers.google.com/protocol-buffers/docs/proto3#updating&quot; title=&quot;Updating messages&quot;&gt;the rules&lt;/a&gt;, remember to never change the numerical identifier for that field. Plan well, and it’ll be easy to maintain backward and forward compatibility for your Protocol Buffer deployment.&lt;/p&gt;</content><author><name>John Gramila</name></author><category term="Tutorials" /><summary type="html">Protocol Buffers serialize structured data so it can be efficiently stored or shared over a network. They were designed for internal use at Google in 2001 and released to the public under an open-source license in 2008.</summary></entry><entry><title type="html">Understanding Docker Multistage Builds</title><link href="https://earthly.dev/blog/docker-multistage/" rel="alternate" type="text/html" title="Understanding Docker Multistage Builds" /><published>2021-05-20T00:00:00-04:00</published><updated>2021-05-20T00:00:00-04:00</updated><id>https://earthly.dev/blog/docker-multistage</id><content type="html" xml:base="https://earthly.dev/blog/docker-multistage/">&lt;p&gt;At first glance, writing Dockerfiles appears to be a straightforward process. After all, most basic examples reflect the same set of steps. However, not all Dockerfiles are created equal. There is an optimal way of writing these files to produce the kind of Docker images you want for your final product. If you were to pop the hood, you’d see that Docker images actually consist of file system layers that correlate to the individual build steps involved in the creation of the image.&lt;/p&gt;
&lt;p&gt;To build an efficient Docker image, you want to eliminate some of these layers from the final output. Optimizing an image can take a lot of effort as you attempt to filter out what you don’t need. Building these kinds of images has a lot to do with keeping them as small as possible, because large images lead to a host of other issues.&lt;/p&gt;
&lt;p&gt;One approach to keeping Docker images small is using multistage builds. A multistage build allows you to use multiple images to build a final product. In a multistage build, you have a single Dockerfile, but can define multiple images inside it to help build the final image.&lt;/p&gt;
&lt;p&gt;In this post, you’ll learn about the core concepts of multistage builds in Docker and how they help to create production-grade images. In addition, I will detail how you can create these types of files, as well as highlight some challenges that they present.&lt;/p&gt;
&lt;h2 id=&quot;core-concepts-of-docker-multistage-builds&quot;&gt;Core Concepts of Docker Multistage Builds&lt;/h2&gt;
&lt;p&gt;Before getting to the details of multistage builds, it’s good to have an understanding of the main idea behind them. You’re already familiar with the starting point of container images, the Dockerfile. Dockerfiles are text files that make it easy to assemble all the relevant commands required to create your container image. These commands in the Dockerfile should be combined whenever possible for the sake of optimization.&lt;/p&gt;
&lt;p&gt;When I first came across this idea of building the right kind of Docker image, I asked myself a few questions that may be crossing your mind as you read this. What are the implications of &lt;em&gt;not&lt;/em&gt; optimizing an image? Can it really have that much of a negative impact on your application? The answer to the latter question is yes.&lt;/p&gt;
&lt;p&gt;As for the implications, you typically end up with bigger images. The reason big images should be avoided is because &lt;a href=&quot;https://developers.redhat.com/blog/2016/03/09/more-about-docker-images-size/&quot; title=&quot;Keep it small: a closer look at Docker image sizing&quot;&gt;they increase both potential security vulnerabilities and the surface area for attack&lt;/a&gt;. You definitely want to keep things lean by ensuring you only have what your application needs to run successfully in a production environment.&lt;/p&gt;
&lt;p&gt;One way of reducing the size of your Docker images is through the use of what is informally known as the &lt;a href=&quot;https://en.wikipedia.org/wiki/Builder_pattern&quot; title=&quot;builder design pattern entry at Wikipedia&quot;&gt;builder pattern&lt;/a&gt;. The builder pattern uses two Docker images to create a base image for building assets and the second to run it. This pattern was previously implemented through the use of multiple Dockerfiles. It has become an uncommon practice since the introduction and support of multistage builds in &lt;a href=&quot;https://www.docker.com/blog/multi-stage-builds/&quot; title=&quot;Multi-Stage Builds&quot;&gt;Docker 17.06 CE&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;For context, it’s good to understand how this was typically done before multistage builds. The following example makes use of a basic React application that is first built and then has its static content served by an &lt;a href=&quot;https://www.nginx.com/&quot; title=&quot;Nginx web servers&quot;&gt;Nginx virtual server&lt;/a&gt;. Following are the two Dockerfiles used to create the optimized image. In addition, you’ll see a &lt;a href=&quot;/blog/understanding-bash&quot;&gt;shell script&lt;/a&gt; that demonstrates the Docker CLI commands that have to be run in order to achieve this outcome. You can find the source code for this example in &lt;a href=&quot;https://github.com/LukeMwila/builder-pattern-example&quot; title=&quot;builder pattern example in Lukonde Mwila&amp;#39;s GitHub repository&quot;&gt;this repository&lt;/a&gt;.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Dockerfile.build
FROM node:12.13.0-alpine
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Dockerfile.main
FROM nginx
EXPOSE 3000
COPY ./nginx/default.conf /etc/nginx/conf.d/default.conf
COPY /app/build /usr/share/nginx/html&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Build.sh
#!/bin/sh
echo Building lukondefmwila/react:build

docker build -t lukondefmwila:build . -f Dockerfile.build

docker create --name extract lukondefmwila:build

docker cp extract:/app/build ./app

docker rm -f extract

echo Building lukondefmwila/react:latest

docker build --no-cache -t lukondefmwila/react:latest . -f Dockerfile.main&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;While using the builder pattern does give you the desired outcome, it presents additional challenges. This process introduces the management overhead that comes with maintaining multiple Dockerfiles—not to mention the cumbersome procedure of running through several Docker CLI commands, even if this can be streamlined by a shell script.&lt;/p&gt;
&lt;h2 id=&quot;how-to-use-docker-multistage-builds&quot;&gt;How to Use Docker Multistage Builds&lt;/h2&gt;
&lt;p&gt;Now that you get the underlying concept, turn your attention to how this translates to the modern implementation of the builder pattern. What the former approach accomplishes with multiple Dockerfiles, the multistage feature does in one. You can get the same results with your builds without the added complexity.&lt;/p&gt;
&lt;p&gt;Multistage builds make use of one Dockerfile with multiple FROM instructions. Each of these FROM instructions is a new build stage that can COPY artifacts from the previous stages. By going and copying the build artifact from the build stage, you eliminate all the intermediate steps such as downloading of code, installing dependencies, and testing. All these steps create additional layers, and you want to eliminate them from the final image.&lt;/p&gt;
&lt;p&gt;The build stage is named by appending AS &lt;em&gt;name-of-build&lt;/em&gt; to the FROM instruction. The name of the build stage can be used in a subsequent FROM and COPY command by providing a convenient way to identify the source layer for files brought into the image build. The final image is produced from the last stage executed in the Dockerfile.&lt;/p&gt;
&lt;p&gt;Try taking the example from the previous section that used more than one Dockerfile for the React application and replacing the solution with one file that uses a multistage build.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Dockerfile
FROM node:12.13.0-alpine as build
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build

FROM nginx
EXPOSE 3000
COPY ./nginx/default.conf /etc/nginx/conf.d/default.conf
COPY --from=build /app/build /usr/share/nginx/html&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;This Dockerfile has two FROM commands, with each one constituting a distinct build stage. These distinct commands are numbered internally, stage 0 and stage 1 respectively. However, stage 0 is given a friendly alias of &lt;code&gt;build&lt;/code&gt;. This stage builds the application and stores it in the directory specified by the WORKDIR command. The resultant image is over 420 MB in size.&lt;/p&gt;
&lt;p&gt;The second stage starts by pulling the official Nginx image from Docker Hub. It then copies the updated virtual server configuration to replace the default Nginx configuration. Then the COPY –from command is used to copy only the production-related application code from the image built by the previous stage. The final image is approximately 127 MB.&lt;/p&gt;
&lt;h2 id=&quot;problems-that-docker-multistage-builds-might-encounter&quot;&gt;Problems That Docker Multistage Builds Might Encounter&lt;/h2&gt;
&lt;p&gt;Depending on how they are designed, multistage builds can introduce some serious issues around the speed of the build process. Since these Dockerfiles have multiple stages to produce the production-grade image, your cache will not consist of the images built in the previous steps leading to your final output. Simulating the build locally might give you the impression that it’s worth the wait. However, when you’re working with build services such as &lt;a href=&quot;https://aws.amazon.com/codebuild/&quot;&gt;AWS CodeBuild&lt;/a&gt;, &lt;a href=&quot;https://travis-ci.org/&quot;&gt;Travis CI&lt;/a&gt;, or &lt;a href=&quot;https://circleci.com/&quot;&gt;CircleCI&lt;/a&gt;, you want to keep your build time as short as possible for cost reasons, as well as streamlining application delivery.&lt;/p&gt;
&lt;p&gt;In order to make use of the cache, you will have to tag, push, and pull the images produced from the preliminary build stages. As an example, take the multistage Dockerfile from the previous section and split it into two files, Dockerfile.stage-one and Dockerfile.final. The first Dockerfile will create the image that will be pulled and used in stage 0 of the multistage Dockerfile.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;Dockerfile.stage-one
FROM node:12.13.0-alpine as build
WORKDIR /app
COPY package*.json ./
RUN npm install
COPY . .
RUN npm run build&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;Dockerfile.final
FROM lukondefmwila/react:build-stage as build

FROM nginx
EXPOSE 3000
COPY ./nginx/default.conf /etc/nginx/conf.d/default.conf
COPY --from=build /app/build /usr/share/nginx/html&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;That being said, following such an approach for every stage can create an increasingly verbose process every stage that you have. Another way of solving this issue is to make use of &lt;a href=&quot;https://earthly.dev/blog/what-is-buildkit-and-what-can-i-do-with-it/&quot;&gt;BuildKit&lt;/a&gt;. BuildKit came about to address issues and improve on the build features in the &lt;a href=&quot;https://mobyproject.org/&quot;&gt;Moby Engine&lt;/a&gt;. It allows for better cache efficiency and control when building. To enable BuildKit builds, follow the steps outlined in &lt;a href=&quot;https://docs.docker.com/develop/develop-images/build_enhancements/#to-enable-buildkit-builds&quot;&gt;Docker’s documentation&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;more-stages&quot;&gt;More Stages&lt;/h2&gt;
&lt;p&gt;As your multi-stage build grows in complexity, comprehending how each step follows from the next can become a challenge. If the number of stages extends beyond two or if caching is becoming a challenge, you may want to consider using &lt;a href=&quot;http://earthly.dev/&quot;&gt;Earthly&lt;/a&gt; to produce your docker images. Earthly mirrors the dockerfile syntax but allows for naming the stages and for more fine-grained caching.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;FROM node:12.13.0-alpine as build
WORKDIR /app

build:
  COPY package*.json ./
  RUN npm install
  COPY . .
  RUN npm run build

final:
  FROM nginx
  EXPOSE 3000
  COPY ./nginx/default.conf /etc/nginx/conf.d/default.conf
  COPY  +build/app/build /usr/share/nginx/html&lt;/code&gt;&lt;/pre&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;/h2&gt;
&lt;p&gt;While creating Docker images the right way is not a small task, the final outcome does a great deal of good for the speed and security of your application delivery. Larger images have a high number of security vulnerabilities that shouldn’t be overlooked for the sake of speed. The reality is that quality images take time and care.&lt;/p&gt;
&lt;p&gt;The builder pattern has evolved over time in its implementation, with multistage builds coming to the rescue from the tedious steps that previously had to be followed. Tools like BuildKit and Earthly further improve on this process. Though not foolproof, multistage builds have made it much easier to create optimized images that you can be more pleased and confident to have running in your production environment.&lt;/p&gt;</content><author><name>Lukonde Mwila</name></author><category term="Tutorials" /><summary type="html">At first glance, writing Dockerfiles appears to be a straightforward process. After all, most basic examples reflect the same set of steps. However, not all Dockerfiles are created equal. There is an optimal way of writing these files to produce the kind of Docker images you want for your final product. If you were to pop the hood, you’d see that Docker images actually consist of file system layers that correlate to the individual build steps involved in the creation of the image.</summary></entry></feed>