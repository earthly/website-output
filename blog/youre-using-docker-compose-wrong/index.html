<!doctype html>
<html lang="en" class="no-js">
  <head>
    <meta charset="utf-8">
<link rel="icon" type="image/png" href="/blog/assets/images/favicon.png">
<!-- begin _includes/seo.html -->





<title>You’re using docker-compose wrong - Earthly Blog</title>
<meta name="description" content="Tell me if this sounds familiar? You were introduced to docker-compose either by choice or by force. You’ve been using it for a while, but you find it clunky. I’m here to tell you, you are probably using it wrong.   Ok, that might be an exaggeration. I don’t think there’s actually a 100% right or wrong way to use it: home-grown build and dev setups tend to have all kinds of weird requirements and so the standard doesn’t always match the needs. Please take the article with the appropriate skepticism if your situation doesn’t quite fit.   I, myself, have been guilty of each of these in the past and I might be in the future as well!!   In any case, here is a rundown of some of the cardinal sins that I found myself making while using docker-compose.   In this article, I’ll be focusing on use-cases related to integration testing and using docker-compose as a development environment. For production use, I think docker-compose is usually ill-suited.   Problem #1: You’re using the host network   One of the first things new-comers find cumbersome is the use of Docker networks. It’s yet another layer of knowledge to add to your repertoire after you get used to the basics of docker build and docker run … and frankly, why do you even need to understand these Docker networks? Everything works fine via the host network, right? Wrong!   Using the host network means that you have to reserve specific ports for the various microservices that you use. If you happen to bring up two stacks that collide on ports, tough luck. If you want to bring up two versions of the same stack, tough luck. You want to test the behavior of a certain service when it has multiple replicas? Tough… luck!   By default, docker-compose spins up its containers on a separate network called &lt;project-name&gt;_default (where &lt;project-name&gt; is by default the name of the directory). So really, you don’t need to do anything special in order to take advantage of Docker networks.   This network gives you a number of benefits right off the bat:    It’s a network more isolated from your host network - so it’s less likely that the specifics of your system environment will cause the compose setup to behave differently. You have access to the internet, but any ports that you wish to be accessible from the host need to be declared with a port bind.   If a service starts listening on 0.0.0.0 (the way containers should), then a host network setup will open up that port on your WLAN. If you use a Docker network, it’ll only expose that port to that network.   You can talk between services by using their compose names as host names. So if you have a service called db and within it there’s a service listening on port 5432 , then you can access it from any other service via db:5432. This is typically more intuitive than localhost:5432. And because there is no risk of localhost port clashing, it has a greater chance to be more consistent when used across different projects.   Most ports don’t need to be opened up to the host too - which means that they are not competing on global resources, should you need to increase the replication via –scale.    Problem #2: You’re binding ports on the host’s 0.0.0.0   I’ve seen it everywhere, you’ve seen it everywhere, everybody saw it everywhere: binding ports as 8080:8080. At first glance, this looks innocuous. But the devil is in the details. This extremely common port bind is not just forwarding a container port to the localhost - it forwards it to be accessible on every network interface on your system - including whatever you use to connect to the internet.   This means that it’s very likely that your development containers are constantly listening on your WLAN - when you’re home, when you’re in the office, or when you’re at McDonald’s. It’s always accessible. This can be dangerous. Don’t do that.   “But Vlad, I use ufw , my ports aren’t accessible by default”.   That may be true - but if you use this docker-compose setup as a team, one of your teammates might not have a firewall on their laptop.   The fix is very easy: Just add 127.0.0.1: in front. So for example 127.0.0.1:8080:8080. This simply tells docker to only expose the port to the loopback network interface and nothing else.   Problem #3: You’re using sleep to coordinate service startup   I have a confession to make. I’m 100% guilty of this.   The main reason this is such a complicated issue is that there is no support from Docker or Docker Compose to address this. Version 2.1 of the docker-compose format used to have a depends_on option called condition which could be set to service_healthy. And also, each service could have a healthcheck command which could tell docker-compose what “healthy” means. Well, this is no longer available in Version 3.0 and no replacement is offered for it.   Docker’s docs basically recommend that your service is made resilient to other services not being around for a while because that’s what might happen in production anyway, if there’s a short network bleep, or if a service restarts. Can’t argue with that logic.   Where it gets a bit more cumbersome is when you run an integration test and the routines meant for initializing the test environment (for example pre-populating the database with some test data) end up not being resilient to starting before the other service is ready. So the argument about “it should be resilient in production anyway” doesn’t quite apply here, because the code to populate the DB with test data is never used in production.   For such cases, you need something that waits for services to be ready. Docker recommends using wait-for-it, Dockerize or wait-for. Note, however, that a port being ready isn’t always a sign that the service is ready to be used. For example, in an integration test using a certain SQL DB with a certain schema, the port becomes available when the DB is initialized, however, the test might only work after a certain schema migration has been applied. You may need application-specific checks on top.   Problem #4: You’re running the DB in docker-compose, but the test on the host   Here is a situation: you want to run some unit tests but those tests depend on some external services. Maybe a database, maybe a Redis, maybe another API. Easy: let’s put those dependencies in a docker-compose and have the unit test connect to those.   That’s great - but note that your tests aren’t exactly just unit tests anymore. They are now integration tests. Besides the nomenclature, there is an important distinction to take into account now: you’ll need to account for a setup of the test environment and a teardown. Usually, it’s best for the setup/teardown to be performed outside of the test code - main reason being that there may be multiple distinct packages depending on these external services. But YMMV.   If you do end up separating test setup and teardown, you could go the extra mile and containerize your integration test. Hear me out!   Containerized tests mean:    You are on the same Docker network, so the connectivity setup is the same you would use for running your service in compose anyway. Configuration becomes cleaner.   You may be able to reuse the code used to wait for other services to be ready in your setup/teardown.   The integration test does not depend on any other local system configuration or environment setup, such as say… your JFrog credentials, or any build dependencies. A container is isolated.   If another team needs to run your tests against an updated version of a service the tests depend on, you can just share the integration testing image - no need for them to compile or to set up a build toolchain.   If you end up with multiple separate integration test containers, you can typically run all of them at the same time in parallel.    A tip for using containerized integration tests is to use a separate docker-compose definition for them. For example, if most of your services exist in docker-compose.yml , you could add docker-compose.test.yml with integration test definitions. This means that docker-compose up brings up your usual services, while docker-compose -f docker-compose.yml -f docker-compose.test.yml up starts your integration tests. For a full example on how to achieve this, see this excellent docker-compose integration testing repository from Ardan Labs.   Ok, ok - calling this out as being wrong isn’t entirely fair. There are many situations where not containerizing is preferable. As a simple example, many languages have deep IDE integrations which make inserting a container between the language and the IDE pretty much impossible. There are many valid productivity reasons not to do this.   Conclusion   Docker Compose can be an amazing tool for local development purposes. Although it has a few gotchas, it usually brings a lot of productivity benefits to many engineering teams, especially when used in conjunction with integration tests.   If you’re looking for more flexibility in defining containerized tests than docker-compose alone can provide, take a look at integration test support in Earthly.">


  <meta name="author" content="Vlad A. Ionescu">
  
  <meta property="article:author" content="Vlad A. Ionescu">
  


<meta property="og:type" content="article">
<meta property="og:locale" content="en_US">
<meta property="og:site_name" content="Earthly Blog">
<meta property="og:title" content="You’re using docker-compose wrong">
<meta property="og:url" content="https://earthly.dev/blog/youre-using-docker-compose-wrong/">


  <meta property="og:description" content="Tell me if this sounds familiar? You were introduced to docker-compose either by choice or by force. You’ve been using it for a while, but you find it clunky. I’m here to tell you, you are probably using it wrong.   Ok, that might be an exaggeration. I don’t think there’s actually a 100% right or wrong way to use it: home-grown build and dev setups tend to have all kinds of weird requirements and so the standard doesn’t always match the needs. Please take the article with the appropriate skepticism if your situation doesn’t quite fit.   I, myself, have been guilty of each of these in the past and I might be in the future as well!!   In any case, here is a rundown of some of the cardinal sins that I found myself making while using docker-compose.   In this article, I’ll be focusing on use-cases related to integration testing and using docker-compose as a development environment. For production use, I think docker-compose is usually ill-suited.   Problem #1: You’re using the host network   One of the first things new-comers find cumbersome is the use of Docker networks. It’s yet another layer of knowledge to add to your repertoire after you get used to the basics of docker build and docker run … and frankly, why do you even need to understand these Docker networks? Everything works fine via the host network, right? Wrong!   Using the host network means that you have to reserve specific ports for the various microservices that you use. If you happen to bring up two stacks that collide on ports, tough luck. If you want to bring up two versions of the same stack, tough luck. You want to test the behavior of a certain service when it has multiple replicas? Tough… luck!   By default, docker-compose spins up its containers on a separate network called &lt;project-name&gt;_default (where &lt;project-name&gt; is by default the name of the directory). So really, you don’t need to do anything special in order to take advantage of Docker networks.   This network gives you a number of benefits right off the bat:    It’s a network more isolated from your host network - so it’s less likely that the specifics of your system environment will cause the compose setup to behave differently. You have access to the internet, but any ports that you wish to be accessible from the host need to be declared with a port bind.   If a service starts listening on 0.0.0.0 (the way containers should), then a host network setup will open up that port on your WLAN. If you use a Docker network, it’ll only expose that port to that network.   You can talk between services by using their compose names as host names. So if you have a service called db and within it there’s a service listening on port 5432 , then you can access it from any other service via db:5432. This is typically more intuitive than localhost:5432. And because there is no risk of localhost port clashing, it has a greater chance to be more consistent when used across different projects.   Most ports don’t need to be opened up to the host too - which means that they are not competing on global resources, should you need to increase the replication via –scale.    Problem #2: You’re binding ports on the host’s 0.0.0.0   I’ve seen it everywhere, you’ve seen it everywhere, everybody saw it everywhere: binding ports as 8080:8080. At first glance, this looks innocuous. But the devil is in the details. This extremely common port bind is not just forwarding a container port to the localhost - it forwards it to be accessible on every network interface on your system - including whatever you use to connect to the internet.   This means that it’s very likely that your development containers are constantly listening on your WLAN - when you’re home, when you’re in the office, or when you’re at McDonald’s. It’s always accessible. This can be dangerous. Don’t do that.   “But Vlad, I use ufw , my ports aren’t accessible by default”.   That may be true - but if you use this docker-compose setup as a team, one of your teammates might not have a firewall on their laptop.   The fix is very easy: Just add 127.0.0.1: in front. So for example 127.0.0.1:8080:8080. This simply tells docker to only expose the port to the loopback network interface and nothing else.   Problem #3: You’re using sleep to coordinate service startup   I have a confession to make. I’m 100% guilty of this.   The main reason this is such a complicated issue is that there is no support from Docker or Docker Compose to address this. Version 2.1 of the docker-compose format used to have a depends_on option called condition which could be set to service_healthy. And also, each service could have a healthcheck command which could tell docker-compose what “healthy” means. Well, this is no longer available in Version 3.0 and no replacement is offered for it.   Docker’s docs basically recommend that your service is made resilient to other services not being around for a while because that’s what might happen in production anyway, if there’s a short network bleep, or if a service restarts. Can’t argue with that logic.   Where it gets a bit more cumbersome is when you run an integration test and the routines meant for initializing the test environment (for example pre-populating the database with some test data) end up not being resilient to starting before the other service is ready. So the argument about “it should be resilient in production anyway” doesn’t quite apply here, because the code to populate the DB with test data is never used in production.   For such cases, you need something that waits for services to be ready. Docker recommends using wait-for-it, Dockerize or wait-for. Note, however, that a port being ready isn’t always a sign that the service is ready to be used. For example, in an integration test using a certain SQL DB with a certain schema, the port becomes available when the DB is initialized, however, the test might only work after a certain schema migration has been applied. You may need application-specific checks on top.   Problem #4: You’re running the DB in docker-compose, but the test on the host   Here is a situation: you want to run some unit tests but those tests depend on some external services. Maybe a database, maybe a Redis, maybe another API. Easy: let’s put those dependencies in a docker-compose and have the unit test connect to those.   That’s great - but note that your tests aren’t exactly just unit tests anymore. They are now integration tests. Besides the nomenclature, there is an important distinction to take into account now: you’ll need to account for a setup of the test environment and a teardown. Usually, it’s best for the setup/teardown to be performed outside of the test code - main reason being that there may be multiple distinct packages depending on these external services. But YMMV.   If you do end up separating test setup and teardown, you could go the extra mile and containerize your integration test. Hear me out!   Containerized tests mean:    You are on the same Docker network, so the connectivity setup is the same you would use for running your service in compose anyway. Configuration becomes cleaner.   You may be able to reuse the code used to wait for other services to be ready in your setup/teardown.   The integration test does not depend on any other local system configuration or environment setup, such as say… your JFrog credentials, or any build dependencies. A container is isolated.   If another team needs to run your tests against an updated version of a service the tests depend on, you can just share the integration testing image - no need for them to compile or to set up a build toolchain.   If you end up with multiple separate integration test containers, you can typically run all of them at the same time in parallel.    A tip for using containerized integration tests is to use a separate docker-compose definition for them. For example, if most of your services exist in docker-compose.yml , you could add docker-compose.test.yml with integration test definitions. This means that docker-compose up brings up your usual services, while docker-compose -f docker-compose.yml -f docker-compose.test.yml up starts your integration tests. For a full example on how to achieve this, see this excellent docker-compose integration testing repository from Ardan Labs.   Ok, ok - calling this out as being wrong isn’t entirely fair. There are many situations where not containerizing is preferable. As a simple example, many languages have deep IDE integrations which make inserting a container between the language and the IDE pretty much impossible. There are many valid productivity reasons not to do this.   Conclusion   Docker Compose can be an amazing tool for local development purposes. Although it has a few gotchas, it usually brings a lot of productivity benefits to many engineering teams, especially when used in conjunction with integration tests.   If you’re looking for more flexibility in defining containerized tests than docker-compose alone can provide, take a look at integration test support in Earthly.">



  <meta property="og:image" content="/blog/generated/assets/images/youre-using-docker-compose-wrong/header-800-29d95e4c5.jpg">



  <meta name="twitter:site" content="@EarthlyTech">
  <meta name="twitter:title" content="You’re using docker-compose wrong">
  <meta name="twitter:description" content="Tell me if this sounds familiar? You were introduced to docker-compose either by choice or by force. You’ve been using it for a while, but you find it clunky. I’m here to tell you, you are probably using it wrong.   Ok, that might be an exaggeration. I don’t think there’s actually a 100% right or wrong way to use it: home-grown build and dev setups tend to have all kinds of weird requirements and so the standard doesn’t always match the needs. Please take the article with the appropriate skepticism if your situation doesn’t quite fit.   I, myself, have been guilty of each of these in the past and I might be in the future as well!!   In any case, here is a rundown of some of the cardinal sins that I found myself making while using docker-compose.   In this article, I’ll be focusing on use-cases related to integration testing and using docker-compose as a development environment. For production use, I think docker-compose is usually ill-suited.   Problem #1: You’re using the host network   One of the first things new-comers find cumbersome is the use of Docker networks. It’s yet another layer of knowledge to add to your repertoire after you get used to the basics of docker build and docker run … and frankly, why do you even need to understand these Docker networks? Everything works fine via the host network, right? Wrong!   Using the host network means that you have to reserve specific ports for the various microservices that you use. If you happen to bring up two stacks that collide on ports, tough luck. If you want to bring up two versions of the same stack, tough luck. You want to test the behavior of a certain service when it has multiple replicas? Tough… luck!   By default, docker-compose spins up its containers on a separate network called &lt;project-name&gt;_default (where &lt;project-name&gt; is by default the name of the directory). So really, you don’t need to do anything special in order to take advantage of Docker networks.   This network gives you a number of benefits right off the bat:    It’s a network more isolated from your host network - so it’s less likely that the specifics of your system environment will cause the compose setup to behave differently. You have access to the internet, but any ports that you wish to be accessible from the host need to be declared with a port bind.   If a service starts listening on 0.0.0.0 (the way containers should), then a host network setup will open up that port on your WLAN. If you use a Docker network, it’ll only expose that port to that network.   You can talk between services by using their compose names as host names. So if you have a service called db and within it there’s a service listening on port 5432 , then you can access it from any other service via db:5432. This is typically more intuitive than localhost:5432. And because there is no risk of localhost port clashing, it has a greater chance to be more consistent when used across different projects.   Most ports don’t need to be opened up to the host too - which means that they are not competing on global resources, should you need to increase the replication via –scale.    Problem #2: You’re binding ports on the host’s 0.0.0.0   I’ve seen it everywhere, you’ve seen it everywhere, everybody saw it everywhere: binding ports as 8080:8080. At first glance, this looks innocuous. But the devil is in the details. This extremely common port bind is not just forwarding a container port to the localhost - it forwards it to be accessible on every network interface on your system - including whatever you use to connect to the internet.   This means that it’s very likely that your development containers are constantly listening on your WLAN - when you’re home, when you’re in the office, or when you’re at McDonald’s. It’s always accessible. This can be dangerous. Don’t do that.   “But Vlad, I use ufw , my ports aren’t accessible by default”.   That may be true - but if you use this docker-compose setup as a team, one of your teammates might not have a firewall on their laptop.   The fix is very easy: Just add 127.0.0.1: in front. So for example 127.0.0.1:8080:8080. This simply tells docker to only expose the port to the loopback network interface and nothing else.   Problem #3: You’re using sleep to coordinate service startup   I have a confession to make. I’m 100% guilty of this.   The main reason this is such a complicated issue is that there is no support from Docker or Docker Compose to address this. Version 2.1 of the docker-compose format used to have a depends_on option called condition which could be set to service_healthy. And also, each service could have a healthcheck command which could tell docker-compose what “healthy” means. Well, this is no longer available in Version 3.0 and no replacement is offered for it.   Docker’s docs basically recommend that your service is made resilient to other services not being around for a while because that’s what might happen in production anyway, if there’s a short network bleep, or if a service restarts. Can’t argue with that logic.   Where it gets a bit more cumbersome is when you run an integration test and the routines meant for initializing the test environment (for example pre-populating the database with some test data) end up not being resilient to starting before the other service is ready. So the argument about “it should be resilient in production anyway” doesn’t quite apply here, because the code to populate the DB with test data is never used in production.   For such cases, you need something that waits for services to be ready. Docker recommends using wait-for-it, Dockerize or wait-for. Note, however, that a port being ready isn’t always a sign that the service is ready to be used. For example, in an integration test using a certain SQL DB with a certain schema, the port becomes available when the DB is initialized, however, the test might only work after a certain schema migration has been applied. You may need application-specific checks on top.   Problem #4: You’re running the DB in docker-compose, but the test on the host   Here is a situation: you want to run some unit tests but those tests depend on some external services. Maybe a database, maybe a Redis, maybe another API. Easy: let’s put those dependencies in a docker-compose and have the unit test connect to those.   That’s great - but note that your tests aren’t exactly just unit tests anymore. They are now integration tests. Besides the nomenclature, there is an important distinction to take into account now: you’ll need to account for a setup of the test environment and a teardown. Usually, it’s best for the setup/teardown to be performed outside of the test code - main reason being that there may be multiple distinct packages depending on these external services. But YMMV.   If you do end up separating test setup and teardown, you could go the extra mile and containerize your integration test. Hear me out!   Containerized tests mean:    You are on the same Docker network, so the connectivity setup is the same you would use for running your service in compose anyway. Configuration becomes cleaner.   You may be able to reuse the code used to wait for other services to be ready in your setup/teardown.   The integration test does not depend on any other local system configuration or environment setup, such as say… your JFrog credentials, or any build dependencies. A container is isolated.   If another team needs to run your tests against an updated version of a service the tests depend on, you can just share the integration testing image - no need for them to compile or to set up a build toolchain.   If you end up with multiple separate integration test containers, you can typically run all of them at the same time in parallel.    A tip for using containerized integration tests is to use a separate docker-compose definition for them. For example, if most of your services exist in docker-compose.yml , you could add docker-compose.test.yml with integration test definitions. This means that docker-compose up brings up your usual services, while docker-compose -f docker-compose.yml -f docker-compose.test.yml up starts your integration tests. For a full example on how to achieve this, see this excellent docker-compose integration testing repository from Ardan Labs.   Ok, ok - calling this out as being wrong isn’t entirely fair. There are many situations where not containerizing is preferable. As a simple example, many languages have deep IDE integrations which make inserting a container between the language and the IDE pretty much impossible. There are many valid productivity reasons not to do this.   Conclusion   Docker Compose can be an amazing tool for local development purposes. Although it has a few gotchas, it usually brings a lot of productivity benefits to many engineering teams, especially when used in conjunction with integration tests.   If you’re looking for more flexibility in defining containerized tests than docker-compose alone can provide, take a look at integration test support in Earthly.">
  <meta name="twitter:url" content="https://earthly.dev/blog/youre-using-docker-compose-wrong/">

  
    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:image" content="https://earthly.dev/blog/generated/assets/images/youre-using-docker-compose-wrong/header-800-29d95e4c5.jpg">
  

  



  <meta property="article:published_time" content="2020-11-27T00:00:00-05:00">





  

  


<link rel="canonical" href="https://earthly.dev/blog/youre-using-docker-compose-wrong/">




<script type="application/ld+json">
  {
    "@context": "https://schema.org",
    
      "@type": "Organization",
      "url": "https://earthly.dev/blog/",
      "logo": "/assets/images/logo-header.png"
    
  }
</script>






<!-- end _includes/seo.html -->



  <link href="/blog/feed.xml" type="application/atom+xml" rel="alternate" title="Earthly Blog Feed">


<!-- https://t.co/dKP3o1e -->
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<script>
  document.documentElement.className = document.documentElement.className.replace(/\bno-js\b/g, '') + ' js ';
</script>

<!-- For all browsers -->
<link rel="stylesheet" href="/blog/assets/css/main.css">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5/css/all.min.css">

<!--[if IE]>
  <style>
    /* old IE unsupported flexbox fixes */
    .greedy-nav .site-title {
      padding-right: 3em;
    }
    .greedy-nav button {
      position: absolute;
      top: 0;
      right: 0;
      height: 100%;
    }
  </style>
<![endif]-->


  
<!-- Global site tag (gtag.js) - Google Analytics -->
<script async src="https://www.googletagmanager.com/gtag/js?id=UA-161831101-5"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'UA-161831101-5');
</script>
  <!-- Facebook Pixel Code -->
<script>
    !function(f,b,e,v,n,t,s)
    {if(f.fbq)return;n=f.fbq=function(){n.callMethod?
    n.callMethod.apply(n,arguments):n.queue.push(arguments)};
    if(!f._fbq)f._fbq=n;n.push=n;n.loaded=!0;n.version='2.0';
    n.queue=[];t=b.createElement(e);t.async=!0;
    t.src=v;s=b.getElementsByTagName(e)[0];
    s.parentNode.insertBefore(t,s)}(window, document,'script',
    'https://connect.facebook.net/en_US/fbevents.js');
    fbq('init', '259843109045285');
    fbq('track', 'PageView');
    </script>
    <noscript><img height="1" width="1" style="display:none"
    src="https://www.facebook.com/tr?id=259843109045285&ev=PageView&noscript=1"
    />
</noscript>
 <!-- End Facebook Pixel Code -->
  <!-- Twitter universal website tag code -->
<script>
  !function(e,t,n,s,u,a){e.twq||(s=e.twq=function(){s.exe?s.exe.apply(s,arguments):s.queue.push(arguments);
  },s.version='1.1',s.queue=[],u=t.createElement(n),u.async=!0,u.src='//static.ads-twitter.com/uwt.js',
  a=t.getElementsByTagName(n)[0],a.parentNode.insertBefore(u,a))}(window,document,'script');
  // Insert Twitter Pixel ID and Standard Event data below
  twq('init','o5s6p');
  twq('track','PageView');
  </script>
  <!-- End Twitter universal website tag code -->


  </head>

  <body class="layout--single">
    <nav class="skip-links">
  <h2 class="screen-reader-text">Skip links</h2>
  <ul>
    <li><a href="#site-nav" class="screen-reader-shortcut">Skip to primary navigation</a></li>
    <li><a href="#main" class="screen-reader-shortcut">Skip to content</a></li>
    <li><a href="#footer" class="screen-reader-shortcut">Skip to footer</a></li>
  </ul>
</nav>

    <!--[if lt IE 9]>
<div class="notice--danger align-center" style="margin: 0;">You are using an <strong>outdated</strong> browser. Please <a href="https://browsehappy.com/">upgrade your browser</a> to improve your experience.</div>
<![endif]-->

    

<div class="masthead">
  <div class="masthead__inner-wrap">
    <div class="masthead__menu">
      <nav id="site-nav" class="greedy-nav">
        
          <a class="site-logo" href="/"><img src="/blog/assets/images/white-logo.png" alt="Earthly"></a>
        
        <ul class="visible-links"><li class="masthead__menu-item">
              <a href="/blog/">Blog home</a>
            </li><li class="masthead__menu-item">
              <a href="/blog/categories/articles/">Articles</a>
            </li><li class="masthead__menu-item">
              <a href="/blog/categories/news/">News</a>
            </li><li class="masthead__menu-item">
              <a href="/blog/categories/tutorials/">Tutorials</a>
            </li><li class="masthead__menu-item">
              <a href="https://github.com/earthly/earthly">GitHub</a>
            </li></ul>
        
        <button class="greedy-nav__toggle hidden" type="button">
          <span class="visually-hidden">Toggle menu</span>
          <div class="navicon"></div>
        </button>
        <ul class="hidden-links hidden"></ul>
      </nav>
    </div>
  </div>
</div>


    <div class="initial-content">
      




  







<div class="page__hero"
  style=" background-image: url('');"
>
  
      <picture class="page__hero-image"><source srcset="/blog/generated/assets/images/youre-using-docker-compose-wrong/header-400-95c698357.webp 400w, /blog/generated/assets/images/youre-using-docker-compose-wrong/header-600-95c698357.webp 600w, /blog/generated/assets/images/youre-using-docker-compose-wrong/header-800-95c698357.webp 800w, /blog/generated/assets/images/youre-using-docker-compose-wrong/header-1000-95c698357.webp 1000w, /blog/generated/assets/images/youre-using-docker-compose-wrong/header-1200-95c698357.webp 1200w" type="image/webp"><source srcset="/blog/generated/assets/images/youre-using-docker-compose-wrong/header-400-95c698357.png 400w, /blog/generated/assets/images/youre-using-docker-compose-wrong/header-600-95c698357.png 600w, /blog/generated/assets/images/youre-using-docker-compose-wrong/header-800-95c698357.png 800w, /blog/generated/assets/images/youre-using-docker-compose-wrong/header-1000-95c698357.png 1000w, /blog/generated/assets/images/youre-using-docker-compose-wrong/header-1200-95c698357.png 1200w" type="image/png"><img src="/blog/generated/assets/images/youre-using-docker-compose-wrong/header-800-95c698357.jpg" alt="You’re using docker-compose wrong"></picture>

  
  
</div>





<div id="main" role="main">
  
  <div class="sidebar">
  
    
      
      
      
      
    
    
      

<nav class="nav__list">
  
  <input id="ac-toc" name="accordion-toc" type="checkbox" />
  <label for="ac-toc">Toggle menu</label>
  <ul class="nav__items">
    
      <li>
        
          <span class="nav__sub-title">Container Tutorials</span>
        

        
        <ul>
          
            <li><a href="/blog/understanding-docker-logging-and-log-files/">Docker Logging</a></li>
          
            <li><a href="/blog/docker-networking/">Docker Networking</a></li>
          
            <li><a href="/blog/how-to-setup-and-use-amazons-elastic-container-registry/">AWS ECR</a></li>
          
        </ul>
        
      </li>
    
      <li>
        
          <span class="nav__sub-title">Best Practices</span>
        

        
        <ul>
          
            <li><a href="/blog/youre-using-docker-compose-wrong/" class="active">Docker Compose</a></li>
          
            <li><a href="/blog/what-is-buildkit-and-what-can-i-do-with-it/">What Is BuildKit?</a></li>
          
            <li><a href="/blog/compiling-containers-dockerfiles-llvm-and-buildkit/">Compiling Containers</a></li>
          
        </ul>
        
      </li>
    
  </ul>
</nav>

    
  
  </div>



  <article class="page" itemscope itemtype="https://schema.org/CreativeWork">
    <meta itemprop="headline" content="You’re using docker-compose wrong">
    <meta itemprop="description" content="Tell me if this sounds familiar? You were introduced to docker-compose either by choice or by force. You’ve been using it for a while, but you find it clunky. I’m here to tell you, you are probably using it wrong.Ok, that might be an exaggeration. I don’t think there’s actually a 100% right or wrong way to use it: home-grown build and dev setups tend to have all kinds of weird requirements and so the standard doesn’t always match the needs. Please take the article with the appropriate skepticism if your situation doesn’t quite fit.I, myself, have been guilty of each of these in the past and I might be in the future as well!!In any case, here is a rundown of some of the cardinal sins that I found myself making while using docker-compose.In this article, I’ll be focusing on use-cases related to integration testing and using docker-compose as a development environment. For production use, I think docker-compose is usually ill-suited.Problem #1: You’re using the host networkOne of the first things new-comers find cumbersome is the use of Docker networks. It’s yet another layer of knowledge to add to your repertoire after you get used to the basics of docker build and docker run … and frankly, why do you even need to understand these Docker networks? Everything works fine via the host network, right? Wrong!Using the host network means that you have to reserve specific ports for the various microservices that you use. If you happen to bring up two stacks that collide on ports, tough luck. If you want to bring up two versions of the same stack, tough luck. You want to test the behavior of a certain service when it has multiple replicas? Tough… luck!By default, docker-compose spins up its containers on a separate network called &lt;project-name&gt;_default (where &lt;project-name&gt; is by default the name of the directory). So really, you don’t need to do anything special in order to take advantage of Docker networks.This network gives you a number of benefits right off the bat:It’s a network more isolated from your host network - so it’s less likely that the specifics of your system environment will cause the compose setup to behave differently. You have access to the internet, but any ports that you wish to be accessible from the host need to be declared with a port bind.If a service starts listening on 0.0.0.0 (the way containers should), then a host network setup will open up that port on your WLAN. If you use a Docker network, it’ll only expose that port to that network.You can talk between services by using their compose names as host names. So if you have a service called db and within it there’s a service listening on port 5432 , then you can access it from any other service via db:5432. This is typically more intuitive than localhost:5432. And because there is no risk of localhost port clashing, it has a greater chance to be more consistent when used across different projects.Most ports don’t need to be opened up to the host too - which means that they are not competing on global resources, should you need to increase the replication via –scale.Problem #2: You’re binding ports on the host’s 0.0.0.0I’ve seen it everywhere, you’ve seen it everywhere, everybody saw it everywhere: binding ports as 8080:8080. At first glance, this looks innocuous. But the devil is in the details. This extremely common port bind is not just forwarding a container port to the localhost - it forwards it to be accessible on every network interface on your system - including whatever you use to connect to the internet.This means that it’s very likely that your development containers are constantly listening on your WLAN - when you’re home, when you’re in the office, or when you’re at McDonald’s. It’s always accessible. This can be dangerous. Don’t do that.“But Vlad, I use ufw , my ports aren’t accessible by default”.That may be true - but if you use this docker-compose setup as a team, one of your teammates might not have a firewall on their laptop.The fix is very easy: Just add 127.0.0.1: in front. So for example 127.0.0.1:8080:8080. This simply tells docker to only expose the port to the loopback network interface and nothing else.Problem #3: You’re using sleep to coordinate service startupI have a confession to make. I’m 100% guilty of this.The main reason this is such a complicated issue is that there is no support from Docker or Docker Compose to address this. Version 2.1 of the docker-compose format used to have a depends_on option called condition which could be set to service_healthy. And also, each service could have a healthcheck command which could tell docker-compose what “healthy” means. Well, this is no longer available in Version 3.0 and no replacement is offered for it.Docker’s docs basically recommend that your service is made resilient to other services not being around for a while because that’s what might happen in production anyway, if there’s a short network bleep, or if a service restarts. Can’t argue with that logic.Where it gets a bit more cumbersome is when you run an integration test and the routines meant for initializing the test environment (for example pre-populating the database with some test data) end up not being resilient to starting before the other service is ready. So the argument about “it should be resilient in production anyway” doesn’t quite apply here, because the code to populate the DB with test data is never used in production.For such cases, you need something that waits for services to be ready. Docker recommends using wait-for-it, Dockerize or wait-for. Note, however, that a port being ready isn’t always a sign that the service is ready to be used. For example, in an integration test using a certain SQL DB with a certain schema, the port becomes available when the DB is initialized, however, the test might only work after a certain schema migration has been applied. You may need application-specific checks on top.Problem #4: You’re running the DB in docker-compose, but the test on the hostHere is a situation: you want to run some unit tests but those tests depend on some external services. Maybe a database, maybe a Redis, maybe another API. Easy: let’s put those dependencies in a docker-compose and have the unit test connect to those.That’s great - but note that your tests aren’t exactly just unit tests anymore. They are now integration tests. Besides the nomenclature, there is an important distinction to take into account now: you’ll need to account for a setup of the test environment and a teardown. Usually, it’s best for the setup/teardown to be performed outside of the test code - main reason being that there may be multiple distinct packages depending on these external services. But YMMV.If you do end up separating test setup and teardown, you could go the extra mile and containerize your integration test. Hear me out!Containerized tests mean:You are on the same Docker network, so the connectivity setup is the same you would use for running your service in compose anyway. Configuration becomes cleaner.You may be able to reuse the code used to wait for other services to be ready in your setup/teardown.The integration test does not depend on any other local system configuration or environment setup, such as say… your JFrog credentials, or any build dependencies. A container is isolated.If another team needs to run your tests against an updated version of a service the tests depend on, you can just share the integration testing image - no need for them to compile or to set up a build toolchain.If you end up with multiple separate integration test containers, you can typically run all of them at the same time in parallel.A tip for using containerized integration tests is to use a separate docker-compose definition for them. For example, if most of your services exist in docker-compose.yml , you could add docker-compose.test.yml with integration test definitions. This means that docker-compose up brings up your usual services, while docker-compose -f docker-compose.yml -f docker-compose.test.yml up starts your integration tests. For a full example on how to achieve this, see this excellent docker-compose integration testing repository from Ardan Labs.Ok, ok - calling this out as being wrong isn’t entirely fair. There are many situations where not containerizing is preferable. As a simple example, many languages have deep IDE integrations which make inserting a container between the language and the IDE pretty much impossible. There are many valid productivity reasons not to do this.ConclusionDocker Compose can be an amazing tool for local development purposes. Although it has a few gotchas, it usually brings a lot of productivity benefits to many engineering teams, especially when used in conjunction with integration tests.If you’re looking for more flexibility in defining containerized tests than docker-compose alone can provide, take a look at integration test support in Earthly. ">
    <meta itemprop="datePublished" content="2020-11-27T00:00:00-05:00">
    

    <div class="page__inner-wrap">
      

      <section class="page__content" itemprop="text">
        
        <header>
          <h1 id="page-title" class="page__title" itemprop="headline">You’re using docker-compose wrong
</h1>
          

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          7 minute read
        
        
        &nbsp;	&nbsp;<i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-11-27T00:00:00-05:00">November 27, 2020</time>
        

      </span>
    
    <span>
      
      
      
      <div class="author__avatar_top">
          <picture class="image-author"><source srcset="/blog/generated/assets/images/authors/vladaionescu-240-121d6d712.webp 240w" type="image/webp"><source srcset="/blog/generated/assets/images/authors/vladaionescu-240-89010bfcc.jpg 240w" type="image/jpeg"><img src="/blog/generated/assets/images/authors/vladaionescu-240-89010bfcc.jpg" alt="Vlad A. Ionescu %"></picture>

          &nbsp;	&nbsp;
          Vlad A. Ionescu
      </div>
      
    </span>
  </p>


        </header>
      
        
        <!-- vale HouseStyle.H2 = NO -->
<p>Tell me if this sounds familiar? You were introduced to docker-compose either by choice or by force. You’ve been using it for a while, but you find it clunky. I’m here to tell you, you are probably using it wrong.</p>
<p>Ok, that might be an exaggeration. I don’t think there’s actually a 100% right or wrong way to use it: home-grown build and dev setups tend to have all kinds of <a href="/blog/dont-be-weird">weird</a> requirements and so the standard doesn’t always match the needs. Please take the article with the appropriate skepticism if your situation doesn’t quite fit.</p>
<p>I, myself, have been guilty of each of these in the past and I might be in the future as well!!</p>
<p>In any case, here is a rundown of some of the cardinal sins that I found myself making while using docker-compose.</p>
<p>In this article, I’ll be focusing on use-cases related to <strong>integration testing</strong> and using docker-compose as a <strong>development environment</strong>. For production use, I think docker-compose is usually ill-suited.</p>
<h2 id="problem-1-youre-using-the-host-network">Problem #1: You’re using the host network</h2>
<p>One of the first things new-comers find cumbersome is the use of <a href="/blog/docker-networking">Docker networks</a>. It’s yet another layer of knowledge to add to your repertoire after you get used to the basics of <strong>docker build</strong> and <strong>docker run</strong> … and frankly, why do you even need to understand these Docker networks? Everything works fine via the host network, right? Wrong!</p>
<p>Using the host network means that you have to reserve specific ports for the various microservices that you use. If you happen to bring up two stacks that collide on ports, tough luck. If you want to bring up two versions of the same stack, tough luck. You want to test the behavior of a certain service when it has multiple replicas? Tough… luck!</p>
<p>By default, docker-compose spins up its containers on a separate network called <strong>&lt;project-name&gt;_default</strong> (where <strong>&lt;project-name&gt;</strong> is by default the name of the directory). So really, you don’t need to do anything special in order to take advantage of Docker networks.</p>
<p>This network gives you a number of benefits right off the bat:</p>
<ul>
<li>It’s a network more isolated from your host network - so it’s less likely that the specifics of your system environment will cause the compose setup to behave differently. You have access to the internet, but any ports that you wish to be accessible from the host need to be declared with a port bind.</li>
<li>If a service starts listening on 0.0.0.0 (the way containers should), then a host network setup will open up that port on your WLAN. If you use a Docker network, it’ll only expose that port to that network.</li>
<li>You can talk between services by using their compose names as host names. So if you have a service called <strong>db</strong> and within it there’s a service listening on port <strong>5432</strong> , then you can access it from any other service via <strong>db:5432</strong>. This is typically more intuitive than <strong>localhost:5432</strong>. And because there is no risk of localhost port clashing, it has a greater chance to be more consistent when used across different projects.</li>
<li>Most ports don’t need to be opened up to the host too - which means that they are not competing on global resources, should you need to increase the replication via <a href="https://docs.docker.com/compose/reference/up/"><strong>–scale</strong></a>.</li>
</ul>
<h2 id="problem-2-youre-binding-ports-on-the-hosts-0.0.0.0">Problem #2: You’re binding ports on the host’s 0.0.0.0</h2>
<p>I’ve seen it everywhere, you’ve seen it everywhere, everybody saw it everywhere: binding ports as <strong>8080:8080</strong>. At first glance, this looks innocuous. But the devil is in the details. This extremely common port bind is not just forwarding a container port to the localhost - it forwards it to be accessible on every network interface on your system - including whatever you use to connect to the internet.</p>
<p>This means that it’s very likely that your development containers are constantly listening on your WLAN - when you’re home, when you’re in the office, or when you’re at McDonald’s. It’s always accessible. This can be dangerous. Don’t do that.</p>
<p>“But Vlad, I use <strong>ufw</strong> , my ports aren’t accessible by default”.</p>
<p>That may be true - but if you use this docker-compose setup as a team, one of your teammates might not have a firewall on their laptop.</p>
<p>The fix is very easy: Just add <strong>127.0.0.1:</strong> in front. So for example <strong>127.0.0.1:8080:8080</strong>. This simply tells docker to only expose the port to the loopback network interface and nothing else.</p>
<h2 id="problem-3-youre-using-sleep-to-coordinate-service-startup">Problem #3: You’re using sleep to coordinate service startup</h2>
<p>I have a confession to make. I’m 100% guilty of this.</p>
<p>The main reason this is such a complicated issue is that there is no support from Docker or Docker Compose to address this. Version 2.1 of the docker-compose format used to have a <strong>depends_on</strong> option called <strong>condition</strong> which could be set to <strong>service_healthy</strong>. And also, each service could have a <strong>healthcheck</strong> command which could tell docker-compose what “healthy” means. Well, this is <a href="https://docs.docker.com/compose/compose-file/#depends_on">no longer available in Version 3.0</a> and <a href="https://stackoverflow.com/questions/47710767/what-is-the-alternative-to-condition-form-of-depends-on-in-docker-compose-versio">no replacement</a> is offered for it.</p>
<p>Docker’s docs basically <a href="https://docs.docker.com/compose/startup-order/">recommend</a> that your service is made resilient to other services not being around for a while because that’s what might happen in production anyway, if there’s a short network bleep, or if a service restarts. Can’t argue with that logic.</p>
<p>Where it gets a bit more cumbersome is when you run an integration test and the routines meant for initializing the test environment (for example pre-populating the database with some test data) end up not being resilient to starting before the other service is ready. So the argument about “it should be resilient in production anyway” doesn’t quite apply here, because the code to populate the DB with test data is never used in production.</p>
<p>For such cases, you need something that waits for services to be ready. Docker recommends using <a href="https://github.com/vishnubob/wait-for-it">wait-for-it</a>, <a href="https://github.com/jwilder/dockerize">Dockerize</a> or <a href="https://github.com/Eficode/wait-for">wait-for</a>. Note, however, that a port being ready isn’t always a sign that the service is ready to be used. For example, in an integration test using a certain SQL DB with a certain schema, the port becomes available when the DB is initialized, however, the test might only work after a certain schema migration has been applied. You may need application-specific checks on top.</p>
<h2 id="problem-4-youre-running-the-db-in-docker-compose-but-the-test-on-the-host">Problem #4: You’re running the DB in docker-compose, but the test on the host</h2>
<p>Here is a situation: you want to run some unit tests but those tests depend on some external services. Maybe a database, maybe a Redis, maybe another API. Easy: let’s put those dependencies in a docker-compose and have the unit test connect to those.</p>
<p>That’s great - but note that your tests aren’t exactly just unit tests anymore. They are now <a href="/blog/unit-vs-integration">integration tests</a>. Besides the nomenclature, there is an important distinction to take into account now: you’ll need to account for a setup of the test environment and a teardown. Usually, it’s best for the setup/teardown to be performed outside of the test code - main reason being that there may be multiple distinct packages depending on these external services. But YMMV.</p>
<p>If you do end up separating test setup and teardown, you could go the extra mile and containerize your integration test. Hear me out!</p>
<p>Containerized tests mean:</p>
<ul>
<li>You are on the same Docker network, so the connectivity setup is the same you would use for running your service in compose anyway. Configuration becomes cleaner.</li>
<li>You may be able to reuse the code used to wait for other services to be ready in your setup/teardown.</li>
<li>The integration test does not depend on any other local system configuration or environment setup, such as say… your JFrog credentials, or any build dependencies. A container is isolated.</li>
<li>If another team needs to run your tests against an updated version of a service the tests depend on, you can just share the integration testing image - no need for them to compile or to set up a build toolchain.</li>
<li>If you end up with multiple separate integration test containers, you can typically run all of them at the same time in parallel.</li>
</ul>
<p>A tip for using containerized integration tests is to use a separate docker-compose definition for them. For example, if most of your services exist in <strong>docker-compose.yml</strong> , you could add <strong>docker-compose.test.yml</strong> with integration test definitions. This means that <strong>docker-compose up</strong> brings up your usual services, while <strong>docker-compose -f docker-compose.yml -f docker-compose.test.yml up</strong> starts your integration tests. For a full example on how to achieve this, see this excellent <a href="https://github.com/george-e-shaw-iv/integration-tests-example">docker-compose integration testing</a> repository from Ardan Labs.</p>
<p>Ok, ok - calling this out as being wrong isn’t entirely fair. There are many situations where not containerizing is preferable. As a simple example, many languages have deep IDE integrations which make inserting a container between the language and the IDE pretty much impossible. There are many valid productivity reasons not to do this.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Docker Compose can be an amazing tool for local development purposes. Although it has a few gotchas, it usually brings a lot of productivity benefits to many engineering teams, especially when used in conjunction with integration tests.</p>
<p>If you’re looking for more flexibility in defining containerized tests than docker-compose alone can provide, take a <a href="https://github.com/earthly/earthly/blob/0f48f14/examples/integration-test/Earthfile#L38-L44">look</a> at <a href="https://docs.earthly.dev/guides/integration">integration test support</a> in <a href="https://earthly.dev/">Earthly</a>. <!-- vale HouseStyle.H2 = YES --></p>

        
      </section>

      


<div itemscope itemtype="https://schema.org/Person">

  
    <div class="author__avatar">
      
        <picture class="image-author"><source srcset="/blog/generated/assets/images/authors/vladaionescu-240-121d6d712.webp 240w" type="image/webp"><source srcset="/blog/generated/assets/images/authors/vladaionescu-240-89010bfcc.jpg 240w" type="image/jpeg"><img src="/blog/generated/assets/images/authors/vladaionescu-240-89010bfcc.jpg" alt="Vlad A. Ionescu %"></picture>

      
    </div>
  
  <div class="author__content">
    
      <h4 class="author__name" itemprop="name">
        Vlad A. Ionescu
    
    
    </h4>
    
      <div class="author__bio" itemprop="description">
        <p>Founder of Earthly. Founder of ShiftLeft. Ex Google. Ex VMware. Co-author RabbitMQ Erlang Client.</p>

      </div>
    
  </div>

  <div class="author__urls-wrapper">
    <!-- <button class="btn btn--inverse">Follow</button> -->
    <ul class="author__urls social-icons">
      

     

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      

      <!--
  <li>
    <a href="http://link-to-whatever-social-network.com/user/" itemprop="sameAs" rel="nofollow noopener noreferrer">
      <i class="fas fa-fw" aria-hidden="true"></i> Custom Social Profile Link
    </a>
  </li>
-->
    </ul>
  </div>
</div>

      <footer class="page__meta">
        
        



  


  

  <p class="page__taxonomy">
    <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i> Categories: </strong>
    <span itemprop="keywords">
    
      <a href="/blog/categories/articles" class="page__taxonomy-item" rel="tag">Articles</a>
    
    </span>
  </p>




<p class="page__taxonomy">
  <strong><i class="fas fa-fw fa-folder-open" aria-hidden="true"></i>Author:</strong>
  <span itemprop="keywords">
    <a href="/blog/authors/Vlad/" class="page__taxonomy-item" rel="tag">Vlad A. Ionescu</a>
  </span>
</p>



        
  <p class="page__date"><strong><i class="fas fa-fw fa-calendar-alt" aria-hidden="true"></i> Updated:</strong> <time datetime="2020-11-27T00:00:00-05:00">November 27, 2020</time></p>


      </footer>

      

      
  <nav class="pagination">
    
      <a href="/blog/protobufs-and-grpc/" class="pagination--pager" title="Using gRPC with Golang, Python, and Ruby
">Previous</a>
    
    
      <a href="/blog/unit-vs-integration/" class="pagination--pager" title="Unit Testing vs Integration Testing
">Next</a>
    
  </nav>

    </div>
  </article>

  
  
    <div class="page__related">
      <h4 class="page__related-title">You may also enjoy</h4>
      <div class="grid__wrapper">
        
          










<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <picture><source srcset="/blog/generated/assets/images/python-matplotlib-docker/header-600-e56f7fb32.webp 600w, /blog/generated/assets/images/python-matplotlib-docker/header-800-e56f7fb32.webp 800w" type="image/webp"><source srcset="/blog/generated/assets/images/python-matplotlib-docker/header-600-976d74d44.jpg 600w, /blog/generated/assets/images/python-matplotlib-docker/header-800-976d74d44.jpg 800w" type="image/jpeg"><img src="/blog/generated/assets/images/python-matplotlib-docker/header-800-976d74d44.jpg"></picture>

      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/blog/python-matplotlib-docker/" rel="permalink">Install <code>matplotlib</code> In A Docker Container
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          2 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">
matplotlib is an excellent library for creating graphs and visualizations in Python. For example, I used it to generate the performance graphs in my merging...</p>
  </article>
</div>

        
          










<div class="grid__item">
  <article class="archive__item" itemscope itemtype="https://schema.org/CreativeWork">
    
      <div class="archive__item-teaser">
        <picture><source srcset="/blog/generated/assets/images/golang-makefile/header-600-c2a6f06af.webp 600w, /blog/generated/assets/images/golang-makefile/header-800-c2a6f06af.webp 800w" type="image/webp"><source srcset="/blog/generated/assets/images/golang-makefile/header-600-a3886f2c1.jpg 600w, /blog/generated/assets/images/golang-makefile/header-800-a3886f2c1.jpg 800w" type="image/jpeg"><img src="/blog/generated/assets/images/golang-makefile/header-800-a3886f2c1.jpg"></picture>

      </div>
    
    <h2 class="archive__item-title no_toc" itemprop="headline">
      
        <a href="/blog/golang-makefile/" rel="permalink">Creating a Golang Makefile
</a>
      
    </h2>
    

  <p class="page__meta">
    

    

    
      
      

      <span class="page__meta-readtime">
        <i class="far fa-clock" aria-hidden="true"></i>
        
          6 minute read
        
      </span>
    
  </p>


    <p class="archive__item-excerpt" itemprop="description">

Building and testing any large codebase is time-consuming, error-prone, and repetitive. Golang supports multi-platform builds, which is excellent, but it n...</p>
  </article>
</div>

        
      </div>
    </div>
  
  
</div>

    </div>

    

    <div id="footer" class="page__footer">
      <footer>
        <div class="page__footer-follow">
  <ul class="social-icons">
    
      <li><strong>Follow:</strong></li>
    

    
      
        
          <li><a href="https://twitter.com/earthlytech" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-twitter-square" aria-hidden="true"></i> Twitter</a></li>
        
      
        
          <li><a href="https://github.com/earthly/earthly" rel="nofollow noopener noreferrer"><i class="fab fa-fw fa-github" aria-hidden="true"></i> GitHub</a></li>
        
      
        
      
    

    
      <li><a href="/blog/feed.xml"><i class="fas fa-fw fa-rss-square" aria-hidden="true"></i> Feed</a></li>
    
  </ul>
</div>

<div class="page__footer-copyright">&copy; 2021 <a href="https://earthly.dev/">Earthly</a>. </div>

      </footer>
    </div>

    <script src="/blog/assets/js/vendor/jquery/jquery-3.5.1.js"></script>
<script src="/blog/assets/js/plugins/jquery.fitvids.js"></script>
<script src="/blog/assets/js/plugins/smooth-scroll.js"></script>
<script src="/blog/assets/js/plugins/gumshoe.js"></script>
<script src="/blog/assets/js/plugins/jquery.magnific-popup.js"></script>
<script src="/blog/assets/js/main.min.js"></script>

  <script> // minified version of https://earthly.dev/assets/js/analytics.js
    function setCookie(e,t,r){var i="";if(r){var o=new Date;o.setTime(o.getTime()+24*r*60*60*1e3),i="; expires="+o.toUTCString()}document.cookie=e+"="+(t||"")+i+"; path=/"}function getCookie(e){for(var t=e+"=",r=document.cookie.split(";"),i=0;i<r.length;i++){for(var o=r[i];" "==o.charAt(0);)o=o.substring(1,o.length);if(0==o.indexOf(t))return o.substring(t.length,o.length)}return null}function uuidv4(){return([1e7]+-1e3+-4e3+-8e3+-1e11).replace(/[018]/g,e=>(e^crypto.getRandomValues(new Uint8Array(1))[0]&15>>e/4).toString(16))}function getAnalyticCookie(){cookieName="earthlyID";var e=getCookie(cookieName);return null==e&&(e=uuidv4()),setCookie(cookieName,e,36500),e}jQuery.ajax({type:"POST",url:"https://api.earthly.dev/analytics",data:JSON.stringify({key:"website",url:window.location.href,referrer:document.referrer,earthlyID:getAnalyticCookie()})});
</script>




  </body>
</html>
